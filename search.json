[{"title":"Compiler | Polyhedral Compilation-1","url":"/2024/04/09/Compiler/poly_intro/","content":"\r\n","categories":["Compiler"],"tags":["Compiler"]},{"title":"HPC | Introduction to Parallel Computation","url":"/2024/04/09/HPC/intro/","content":"Parallel Programming: Concepts and Pracitce - Chapter 1\r\n\r\n概念\r\n加速比\r\nSpeedup：衡量一个并行算法比串行算法快多少的指标。即使用单个处理器运行程序所花费的时间\r\n 与使用  个处理器运行程序所花费的时间  之比\r\n\r\n通常我们希望得到的加速比为线性加速比，即用  个处理器去运行程序，最大的加速比为\r\n\r\n效率\r\nEfficiency：定义为加速比和处理器数目之比，衡量了平均一个处理器带来的加速比。当效率为\r\n 时，此时为线性加速比\r\n\r\n可扩展性\r\nScalability：分为强可扩展性和弱可扩展性。\r\n\r\n强可扩展性 Strong\r\nScalability：测量效率时仅改变处理器的数目，输入数据的规模保持不变\r\n弱可扩展性 Weak\r\nScalability：处理器的数目随着输入数据规模共同变化（处理器数目翻倍时，测量效率时把数据规模也翻倍）\r\n\r\n计算通信比 Computation-to-communication\r\nRatio：定义为计算花费的时间和处理器间处理消息通信花费的时间之比。\r\n分布式内存系统：每个计算单元只能访问自己的本地内存，如果需要访问其它单元，需要通过一个显式的通信步骤（例如通信网络）实现。\r\n共享式内存系统：所有计算单元共享内存，除此之外，自己本身也有更小的内存（分级缓存）。\r\n并行程序设计时需要考虑划分（数据并行、任务并行、模型并行）、通信、同步和负载平衡等。\r\n求和的例子\r\n现在我们进行一组数据的加法求和操作，其中数据量为  ，处理器数量为  。设 \r\n为一次加法操作所需要的时长，  为一批数据的通信时长。则\r\n\r\n数据分发次数：\r\n每个处理器本地求和：\r\n每个处理器将结果传递给一个处理器（数据收集）：\r\n中间结果求和：\r\n\r\n总的求和运行时长为\r\n\r\n其加速比为\r\n\r\n对于固定的 ，加速比只与计算通信比 \r\n有关，并且有\r\n\r\n因此在固定数据规模和处理器数量时，要提高加速比，需要降低计算通信比。同时，加速比也可以是处理器数量的函数：\r\n\r\n令偏导为 ，解出最值条件 \r\n综上所述，有如下规律：\r\n\r\n当数据规模固定时，加速比依赖于采用的计算单元的数目和计算通信比\r\n\r\n通常情况下，加速比随着计算单元的增加达到局部最大，但使用更多计算单元时，加速比会降低\r\n最优的加速比依赖于计算通信比，通信时长占比越大，使用的计算单元数目应该越少\r\n\r\n\r\n前缀和的例子\r\n前缀和问题：现有  个数据和\r\n 个计算结点\r\n\r\n输入：一个二元可结合运算符 ； 个待运算的数据 \r\n输出： 个数据 ，其中对于 \r\n\r\n由于计算  需要依赖 ，在循环分析时带来了一定的困难，但该问题依然有并行的方式。\r\n\r\n数据划分：使用 分治 策略，将  个数据按顺序均分为  份，分别分给 \r\n个计算结点，每个结点计算本地内存的前缀和，花费的时间为 \r\n数据归并：递归\r\n合并相邻的结点数据，即左边结点将前缀和的 最后一个结果\r\n返回，传递给右边结点，右边结点接收左边的前缀和，并将其与自己结点结果求和\r\n所有线程将结果返回，计算完成\r\n\r\n\r\n\r\nperfix sum\r\n\r\n前缀和问题将在后续进行更加详细的讨论。\r\n","categories":["HPC"],"tags":["HPC"]},{"title":"HPC | Theory Backgroud","url":"/2024/04/11/HPC/theory/","content":"Parallel Programming: Concepts and Pracitce - Chapter 2\r\n\r\n首先介绍并行随机访问机器（PRAM）模型是抽象的共享内存模型，其忽略了现实计算机中的开销，但可以帮助设计一些并行算法。其次是对于分布式内存模型，会介绍一些基础图论知识。接着介绍并行程序中的两大定律：Amdahl定律和Gustafson定律，用于推断并行程序加速比能达到的上限。最后以并行算法设计的Foster方法论结束。\r\n并行随机访问机器模型\r\n事实上，PRAM (Parallel Random Access Machine)\r\n模型架构十分简单，相比于操作系统课上的一个处理器而言，PRAM拥有多个独立的处理器，每个处理器分3个阶段执行一个指令周期：\r\n\r\n读阶段：每个处理器并发地从各自的共享内存中读取单条数据并保存到本地的寄存器中。\r\n计算阶段：每个处理器对本地数据执行一个基本操作，并将结果存储在寄存器中。\r\n写阶段：每个处理器并发写一条数据到共享内存中。\r\n\r\nPRAM中的通信通过处理器在共享内存中的读写实现，该类型的内存能够以统一的方式访问，即每个处理器对内存中任意位置的访问都使用统一的常数时间实现，这和现实计算机很不一样（访问大规模共享内存时耗费的时间不一致）。\r\nPRAM的变体\r\n在相同的指令中期中，多个处理器读写多个共享内存单元会发生冲突，为解决冲突，出现了如下的几种PRAM变体：ER\r\n(exclusive read)，EW (exclusive write)，CR (concurrent read)，CW\r\n(concurrent write)。常见的组合有三种：\r\n\r\nEREW：独占读、独占写。任意周期内，不允许多个处理器在相同的共享内存单元中进行读写。\r\nCREW：并发读、独占写。\r\nCRCW：并发读、并发写。对于并发写入，有常见的数据保留形式：\r\n\r\nPriority: 处理器本身的优先级决定\r\nArbitrary: 随机选取一个处理器的值写入\r\nCommon: 若所有的值都相等则写入，否则内存位置的值不变\r\nCombining: 通过某种运算组合所有的冲突值再写入\r\n\r\n\r\nPRAM上的前缀和算法\r\n问题描述：给定 \r\n个数据，和一个该数据的二元运算符，假设为加法运算。在一台拥有  个计算结点的PRAM上，并行计算前缀和。\r\n其中数据已经存储在了共享内存 A 中，每个计算结点的寄存器用\r\nreg 表示，目标是设计一个开销最优化的PRAM算法。\r\n串行分析：使用一个计算结点求解前缀和问题\r\nfor (int i = 1; i &lt; n; i += 1) A[i] += A[i-1];\r\n计算复杂度为 \r\n。\r\n并行分析：使用  个计算结点并行求解前缀和问题\r\n当 \r\n时，计算结点的数量和数据量相等，每个计算结点上处理一个数据。\r\n可以使用分治递归的方式，将计算结点逐一合并。\r\n//-- 算法 1 --//// load data for every node@parallelfor (int i = 0; i &lt; p; i += 1) {    reg[i] = A[i];}// total iteration num, merge by 2for (int i = 0; i &lt; ceil(log(p)); i += 1) {    // the left nodes have been calculated    int node_start_idx = pow(2, i);    @parallel    for (int j = node_start_idx; j &lt; p; j += 1) {        reg[j] += A[j - node_start_idx];        A[j] = reg[j];    }}\r\n总体的计算结构类似于二叉树：每一个结点都与左边相邻结点进行计算前缀和，第\r\n 次迭代中，每  个结点视为一个 merge 的结点，\r\n因此一共需要  次递归，即花费的时间为 ， 开销为\r\n，是对数线性的。\r\n如果需要继续减小开销 ，则要么减小 ，要么减小 ，降低运行时间比较困难，因此选择减少计算结点的数量\r\n，即  方法如下\r\n\r\n我们有  个计算结点，先将\r\n\r\n个数据均分到每个计算结点上，每个结点有  个数据\r\n每个计算结点对本地内存的数据求解前缀和，花费的时间为 \r\n每个结点返回本地前缀和的最后一位结果，得到一共  个数据\r\n对上述 \r\n个数据执行算法1，花费的时间为 ，计算完成后依然得到长度为  的前缀和 A_p\r\n将第4步得到的前缀和 A_p[j]，依次加到\r\nreg[j+1] 上，A_p\r\n的最后一位不用加，由于每个结点有  个数据，因此花费的时间为 \r\n\r\n综上所述，整个算法的时间为 ，开销为 ，\r\n当 \r\n时，计算时间为对数，且开销为线性的。\r\n//-- 算法 2 --//// stage 1-3// calculate prefix sum for every node// each node contains k = n/p = log(n) datak = n/p = log(n)@parallelfor (int i = 0; i &lt; p; i += 1) {    for (int j = 1; j &lt; k; j += 1) {        // data index: i * num + offsets        A[i*k+j] += A[i*k+j-1]    }}// stage 4// calculate prefix sum for rightmost values of every nodefor (int i = 0; i &lt; log(p); i += 1) {    int node_start_idx = pow(2, i);    @parallel    for (int j = node_start_idx + 1; j &lt; p; j += 1) {        A[j*k-1] += A[(j - node_start_idx)*k-1]    }}// stage 5// add results@parallelfor (int i = 1; i &lt; p; i += 1) {    // ignore the last value    for (int j = 0; j &lt; k-1; j += 1) {        A[i*k+j] += A[i*k-1]    }}\r\nPRAM上的稀疏矩阵压缩算法\r\n稀疏矩阵压缩算法可以利用前缀和算法。\r\n问题描述：稀疏数组 A 中多个元素为 ，希望能通过并行算法压缩为非零数组\r\nV 和对应的位置数组 C。\r\n\r\n构造和 A 等长的临时数组 temp，其中若\r\ntemp[i] = 1 if A[i]!=0 else temp[i]=0， 将数组\r\nA 和临时数组 temp 均分到 \r\n个计算结点上，并行生成临时数组和计算临时数组的前缀和\r\n求完前缀和的临时数组目前可以作为稀疏数组的\r\n地址列表，接下来根据临时数组，并行索引 A\r\n中对应地址，得到非零值和位置，写入 V,C 即可\r\n\r\n分析：\r\n网络拓扑\r\n互联网络的结点可能是交换机或处理器。几个概念：\r\n\r\n度(degree)：网络的度表示所有结点中邻居数目的最大值\r\n对分宽度(bw)：将网络分为二分图，两个分图间边的最小值\r\n直径(diam)：任意两个结点之间全部最短路径的最大值\r\n\r\n在设计互联网络时，经常关注以下 理想属性：\r\n\r\n常数度：网络的度是常数，即与网络的规模无关。这个属性允许网络扩大到更大的规模而无需增加过多的连接数\r\n小直径：可以支持任意进程之间的高效通信\r\n高对分宽度：对分宽度越低，大量聚合的通信操作会变得更慢，它隐含的是网络的内部带宽\r\n\r\n经典网络拓扑结构各属性的阶：\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\ntopology\r\ndegree\r\ndiam\r\nbw\r\n\r\n\r\n\r\n\r\n线性排列\r\n\r\n\r\n\r\n\r\n\r\n2D网面/环面\r\n\r\n\r\n\r\n\r\n\r\n3D网面/环面\r\n\r\n\r\n\r\n\r\n\r\n二叉树\r\n\r\n\r\n\r\n\r\n\r\n超立方体\r\n\r\n\r\n\r\n\r\n\r\n\r\nAmdahl's Law and Gustafson's\r\nLaw\r\n如果能在设计并行算法前，能对一个问题提前分析其并行效果，将会减少不必要的工作量，也能了解到并行算法是否值得，\r\n而 Amdahl 定律和 Gustafson 定律能帮助我们进行加速比的估计。\r\n一段程序的总执行时间可以分为未被并行化部分所花费的时间（即不能被并行化或没有被并行化的部分所花的时间）\r\n和并行运行的时间，分别用符号  表示。 单个处理器运行一段程序的时间  即上述两部分的简单相加：\r\n\r\nAmdahl's Law\r\n在不考虑缓存效应的前提下，我们希望最佳加速比是线性的： 也就是说如果有\r\n\r\n个处理器并行一段程序，其并行部分能比单个处理器运行快  倍，\r\n因而可以导出一般情况下的运行时间下限：\r\n\r\n因此可以得到其加速比的上限：\r\n\r\n一般而言，在只讨论串行时间和并行时间时，我们使用百分比来表示二者的关系：\r\n\r\n其中 \r\n是一个介于0，1之间的数，此时的加速比可以表示成  的函数：\r\n\r\n这便是 Amdahl 定律。通过知道 ，我们就能预测使用多个处理器并行化程序的加速比理论上限。\r\nAmdahl定律的限制：只适用于问题规模为\r\n常数、处理器个数变化的情况，即强可扩展性。\r\nGustafson's Law\r\n如果在增加处理器个数的情况下，同时增大问题规模，花在并行部分的时间\r\n 比串行时间  增长得更快。\r\n为了同时考虑这些情况，可以按照问题的复杂性扩展两个部分的规模：\r\n\r\n：根据问题规模的复杂度，不能从并行化中获益的程序部分的\r\n尺度函数\r\n：根据问题规模的复杂度，能从并行化中获益的程序部分的尺度函数\r\n\r\n对于单个处理器的情况，程序运行时间为：\r\n\r\n因此得到可达加速比（即并行的最高加速比按照线性加速比处理）：\r\n\r\n令 ：\r\n\r\n\r\n当 \r\n时，即问题规模增加时，串行和并行的尺度增加一致，此时为Amdahl定律；\r\n（Gustafson 定律）当 \r\n时，，即可并行部分以线性  增长，不可并行部分保持常数\r\n\r\nFoster的并行算法设计方法学\r\n","categories":["HPC"],"tags":["HPC"]},{"title":"HPC | Modern Architecture-Cache","url":"/2024/04/23/HPC/modern_arch/","content":"Parallel Programming: Concepts and Pracitce - Chapter 3\r\n\r\nvon Neumann bottleneck:\r\n现代微处理器能够以远高于从主存（DRAM）中读取数据的速率处理数据。\r\n导致的结果是，很多程序受限于访存，而非计算。当然，现在也有很多访存友好的算法，\r\n例如 BLAS 库中的 GEMM\r\n缓存算法\r\n缓存算法主要解决以下问题：\r\n\r\n我们需要从主存装载哪些数据，储存在何处\r\n缓存已满时，我们需要移出哪些数据\r\n\r\n缓存算法的目的在于优化其 命中率（cache\r\nhit）。算法遵循以下两条原则：\r\n\r\n空间局部性：许多算法会从连续的内存位置访问数据，有较高的空间局部性。例如如下程序：\r\n\r\nfor (int i = 0; i &lt; size; i += 1) {    max_value = max(a[i], max_value);}\r\n起始缓存为空，访问 a[0]\r\n时缓存未命中，需要载入数据，缓存一般一次载入一个完整的 cache\r\nline。 假设 cache line\r\n大小是64B，数组的值是双精度浮点数，则连续的8个值 a[0:8]\r\n会一起被载入缓存， a[1:8] 的数据全部缓存命中。\r\n\r\n时间局部性：缓存被组织为一定数目的块，即 cache\r\nline。每个块有固定的大小。缓存映射策略可以决定主存的一个特定条目的备份在缓存中的存储位置。\r\n\r\n直接映射缓存 direct-mapping\r\ncache：主存每个特定条目在缓存中有唯一的存储位置。命中率较低。\r\n2路组相联缓存 two-way set associative\r\ncache：从主存载入的数据可以存储在2个可能的块中，具体存储的位置由\r\n最近最少使用（least-recently used, LRU）\r\n原则决定，往往会选择最近时间最少使用的那个块用来存储主存载入的数据。命中率高于直接映射。常用的还有4路、8路等。\r\n\r\n\r\n缓存一致性\r\n假设需要修改缓存中的值，则不仅需要修改缓存中的值，还需要修改主存中的值，不然会产生不一致（inconsistency），\r\n有两种策略去保证缓存和主存中的一致性（coherence）：\r\n\r\n直写式：如果主存中的数据已经缓存，则主存数据发生变动的同时也要修改缓存的值。缺点每次写主存需要一次主存访问\r\n回写式：缓存的值修改时，不会立马修改主存的值，而是会被标记为\r\ndirty，待数据移出缓存时，才写入主存\r\n\r\n多级缓存和多核处理器的情况会非常复杂，例如每个处理器有自己的本地缓存L1，同时所有的处理器又共享一个公共缓存L2，每个处理器修改L1时，如果没有约束条件，可能会导致其它处理器缓存的值与修改后不一致，L1的值与L2的值也不一样。\r\n一种方式是对于缓存且被修改的值，让其它处理器标记该数据的缓存行为失效，除非重新从主存中载入数据。常用的协议有MESI协议。\r\n虚假共享：缓存一致性协议是对于 cache line\r\n而言的，每一行能存多个值，如果修改了某个值，其所在的 cache line\r\n以及其所关联的 cache line （其它核心的 cache\r\nline）将会整体失效。一个极端情况是，多个处理器同时修改一个缓存行的不同数据，任意一个写操作都会使缓存行失效，所有处理器都需要从共享主存重新载入数据，即使数据并没有改变。这种情况就是\r\n虚假共存。\r\n对于程序员的准则：\r\n\r\n避免对存储在同一个缓存行中的条目进行过度更新\r\n尽量在寄存器而不是在缓存中存储中间结果\r\n\r\n","categories":["HPC"],"tags":["HPC"]},{"title":"致谢 | 我经历过的微风、夕阳和大海","url":"/2024/05/30/You/acknowledgement/","content":"2020级SEU本科毕业致谢篇。谨以此文，献给自己。\n很多年过去，我还是喜欢那一座城市在内心毫无波澜甚至有些许失望的情况下接受了高考的第三志愿的第二专业：SEU吴健雄学院。填写志愿时并无对任何专业有过多的了解，凭本事选择了大类培养的吴健雄学院。同样，对于未来的大学生活我也没有任何期待和了解。我从午休的床上起来，正值盛夏，在湖中心。民宿的周围有野花盛开，清澈湛蓝的水波轻拍岸沿。阳光也是懒散的。\n几周前我结束了长沙之行。长沙城是一座内陆城市，通过湘江与长江相接，在高中时便经常背诵“君住长江头，妾住长江尾。夜夜思君不见君，共饮长江水”，如今站在橘子洲头，确实能感受到四面奔腾的湘江水带来的无尽的哀愁。去逛了博物馆和美术馆，我还是觉得美术馆更适合我，不同的心情可以有不同的思考，没有答案的作品可以让我进行二次创作，我是自由而孤独的。美术馆的灯光打在红色的墙上，我拍下了黑色的影子。但随后我删了，因为我以为以后还能再见。茶颜悦色在这座城市开得到处都是，第一次被称呼“许小主”的心情还带着些许奇妙，喝了很多饮品，我还是喜欢幽兰拿铁，以至于上大学后在网易云中去搜幽兰拿铁，竟然还能搜到相关的歌曲。不过后来，南京也有了茶颜，但我已经没有了那种好奇和兴奋的感觉。当然，在彻底爱上这座城市前，也无法忘记那一天的炎热，与当时自己乘公交前往一个偏远的地方时的稚嫩与愚笨。博物馆和艺术馆的照片仍然存在手机相册里，茶颜悦色和文和友消失在夜晚的草地。热闹的街景，谁与谁又并肩牵手穿梭于夏天的夜晚与记忆的牢笼。\n牢笼仍在，我却很久没有回到长沙城。\n\n但是接到志愿通知的时候我却无法开心。我会回想起高中夏日粉色和紫色的夕阳与金色的树黑色的鸟，一声吱呀，定格了无法回去的夏天。18年的分号停留在了通知书寄到手边的那一刻。随之而来的是死寂般的沉默与一个月的暑假和三次前往同一片湖度假。\n就是我现在看着的这片湖。我试着在深夜拍摄星轨，我喜欢积雨云中倾泻的阳光。\n一个月后的南京，至今竟然已经蜗居四年之久。\n星期三，南京大雨带着大一新生独有的清澈心灵与眼眸，与父母在东南大学北门告别后，我踏入陌生的校园。只不过再次转身时，已经看不见他们了。\n仍然无法确定中学是否结束，18岁是否已过。在整理床铺的时候突然会想起在家旁边的公园里，LED灯中有人弹着吉他，我竟然有点想哭。我才明确地知道，这里是南京，是名为东南大学的校园，是桃园宿舍。在公众号中出现过的健雄书院如今就在我眼前。即使很累，我还是带着我的通知书去了各种东大的打卡地。——图书馆和大草坪，教学楼，九龙湖。坐在图书馆的台阶上，无人分享和倾诉。有时有人从图书馆出来，有时有人前往图书馆。我感到劳累和疲惫，在陌生的阳光下。\n于是车载着我没头没脑地开始往前开，蛮横地冲撞时间，我却把记忆忘在了起点，忘在了长沙南站的分别。都说被记住的才是生活，在下车时，我开始寻找自己的生活。但我撞不开时间。我回不去起点。\n要我说，大一堆砌的是中值定理与各种积分。在周围人的口算题中绞尽脑汁，在月光下一个人回寝。我很早就知道了6号和8号教学楼三四楼不锁门不关灯，于是我经常在里面宅一天。我不爱回寝室，即使在偌大的阶梯教室里望着窗外，如笼中之鸟。开始熬夜，开始享受这种没有人打扰的思考与独处，开始沉默，开始戴着耳机听歌。最常见的景色就是夕阳照到交通楼，呈现金黄，或是天空出现粉橙的脸颊，以及写满的草稿纸，和没有结果的题目。我明白我陷入了一个神秘而可怕的深渊之中，但我不能自救。我强迫自己去散步，不允许沉沦。\n当时最开心的还有梅园操场上一排金色的银杏，一周后被砍了。剩下灰色的枯叶和惨白的天空。以及即将到来的冬天。\n\n我开始记录一些自己的想法。在一些人看来，写日记就是在欺骗自己。但是我喜欢那一本小王子封面的日记本，小王子、B612和一朵玫瑰以及44次日落。有一个人对我说：\n\n压力都是自己给的，不用和别人比，朝着自己的方向走吧。时间管理是你最擅长的。大学每个人的放心都不一样，没有必要因为别人怎么样自己就怎么样。放弃一些让自己不舒服的社交圈，实在憋得喘不过气就不用我告诉你怎么做吧。\n每个人都在黑暗中探索，你前面有很多人，没有办法，你只能跟着拿蜡烛的他们。\n但是你有没有想过，你可以自己拿着蜡烛去自己想去的地方。\n\n我不管那个人懂不懂我的劳累，我的压力和孤独。但那个人听完了。\n我没有办法去草地上听乐队演奏，即使夕阳很美。悔恨吗，或许吧，一把跨越七年的刀刃插进了不成熟的内心。我没有想过我可以自己拿着蜡烛去自己想去的地方。或许想过。或许一定想过。如今却站在了四年的末尾，回望四年或七年的所有是非，有时候能看见一点光亮。\n一个人和一群人我总觉得应该去找寻或者思考一些什么，历史也好，哲学也罢。只有思考时，我才能感受到自己存在于世界，双脚真正站在陆地上，双眼看着飞鸟。一昧的自责和反思只会加剧自卑感和乏力感，但当你开始把视线投向更远的远方时，才能感受到当下的存在和历史的实体。当时自己的内心一定是烦躁不安的，我希望去改变一些什么，任何方向都行。因为最差的结果是维持现状。让我印象颇为深刻的是疫情延迟放假，我在第一次在图书馆度过夏天。喜欢那里傍晚的鸟鸣，有薄荷的味道和天空的清澈。更重要的是让我莫名其妙增加了在计算机上的兴趣和自信。这种自以为是让我选择了AI和CS作为专业。\n后来我一个人去了北京。竟然真的能在早晨的四合院中看见逗鸟的大爷。一个人爬完长城南北两段后无法忘记在烽火台上清爽的风。租一辆车骑完整条长安街。喝一碗豆汁儿。在蓝调的白塔公园感受寒冷和肃杀。南锣鼓巷不长但终于看见一点烟火气。\n\n雨，雾\n乌鸦的叫声\n马路上飞驰的车辆\n护城河，一浪接一浪\n秋也是凉的\n世事一场大梦\n红色的宫墙又在上漆\n凹凸不平的石砖有点硌脚\n五千年一晃而过\n游客还在拍照\n\n已经忘了很多事情。也忘了暑假结束后是为何来到书院并加入其中成为志愿者的。“海看多了想见人，人见多了想看海”。于是命运的齿轮开始转动。\n我很少对已经发生的事情做一些相反的设想，因为这些设想的目的往往是加强对当下的信念感，但我还是无法想象如果我当初没有来到书院，我现在在哪，后续的两年又会如何度过，或者会更优秀，或者会更差劲。唯一清楚的是，人是群居动物，至少我无法长时间忍受失去交流的生活。很多事情很多矛盾很多情绪，见一面就好了。除非累了。一个人的价值是通过“被需要”体现的，这种“被需要”在我第一次来书院时展现得淋漓尽致，因为我否定自己太多了。虽然还是不怎么回寝室，但终于不是一个人在教室最后一排看着夕阳发呆了。对于所谓大学的记忆也开始变得有迹可循。书院、校队和活动室都成为了我的大学。\n现在的故事后来的我","categories":["You"],"tags":["You"]}]