{"meta":{"title":"Andrew-Rey","subtitle":"醉后不知天在水，满船清梦压星河","description":"","author":null,"url":"https://Andrew-Rey.github.io","root":"/"},"pages":[{"title":"二十岁的自传","date":"2022-11-23T11:12:45.978Z","updated":"2022-11-23T11:12:45.978Z","comments":false,"path":"about/index.html","permalink":"https://andrew-rey.github.io/about/index.html","excerpt":"","text":"我在十九岁最后两天的时候给自己写了点东西，当时在教室，周围是考研的学长学姐。 现在是二十岁的我，自传嘛，随便写写，但是并不代表对自己的亵渎。 写点什么呢。 弱冠年，本科在读。 二零年毕业于郴州市一中。 高考延期，现在仍然记得高考时的座位靠窗，那天很热。 疫情在高三开始， 高二的回忆是关于粉橙色的夕阳和理综数学， 高一开始当了纪律委员， 夏令营的天很蓝。 初三的风，初二的她，初一的混乱和美术。 县城小学四年，与父骑车游玩， 浑身是泥，不汗不归。 一二年级在积木中度过。 宅居校内，父母为师， 门前青草针叶衫，夜晚是母亲扇风的手。 再往前，记忆只在照片中凝固。 就这样，平常地活着，安然无恙地活着。 当时怎知宇宙之大，也从不担忧人生几何； 现在知道了宇宙的度量，明白了人生几何， 目睹了活着，和死亡，目睹了一个时代的结束。 人体维护的一切，只是将熵增的速率变缓。 但那又怎样。 我欣然接受。 我已经学会了走路，奔跑；说话，呐喊；回忆，思考；见面，告别。 并且我仍然会 奔跑着，呐喊着，思考着，以及告别着。 但无论怎样，请别忘了： 走路，说话，回忆和见面， 也是你的本能。"},{"title":"categories","date":"2022-01-12T02:05:00.000Z","updated":"2022-08-29T16:15:22.683Z","comments":false,"path":"categories/index.html","permalink":"https://andrew-rey.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-01-12T01:53:09.000Z","updated":"2022-08-29T16:15:22.684Z","comments":false,"path":"tags/index.html","permalink":"https://andrew-rey.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"人智导论复习","slug":"ML/IntroductionToAI","date":"2023-01-05T07:54:09.000Z","updated":"2023-01-05T09:59:29.355Z","comments":true,"path":"2023/01/05/ML/IntroductionToAI/","link":"","permalink":"https://andrew-rey.github.io/2023/01/05/ML/IntroductionToAI/","excerpt":"\"复习课的主旨\" \"去看GZQ的PPT\"","text":"\"复习课的主旨\" \"去看GZQ的PPT\" 绪论 什么是人工智能, 给出功能模块和方法 理性的行动的系统 方法: 理性Agent方法: Agent 是某种能够行动的东西. Rational Agent 可以通过自己的行动获得 最佳的结果 或者 在不确定的情况下获得 最佳期望, 功能有 能做正确的推论, 若没有能证明正确性的事情, 但是必须 有所行动. 部分完成理性行动的方法和推论过程无关 (如反射活动) 图灵测试 好处: 比\"思维法则\"方法通用, 正确的推论只是实现理性的方法之一 比人类思维更经得起科学的考验 (可以证伪) 智能化Agent Agent架构, 理解Agent的任务, 环境, 评价标准 Agent 通过传感器感知所处的环境, 通过执行器对环境产生作用 例子 (人类, 机器人, 软件等) agent的工作原理, 记住. 里面的\"?\"表示映射函数 Agent和环境 感知信息: 任何时刻的感知输入 感知序列: 所有的输入数据的完整历史 Agent在任何时刻的行动选择, 取决于到该时刻为止的整个感知序列 Agent函数: 可以用列表表示, 也需要一些抽象的表示 性能度量 Agent成功程度的标准 理性的判断标准 PPT, 要记 Agent的类型 不同的Agent区别在于: Agent函数不一样 先画图, 再解释 简单反射型Agent 可以建造一个通用的 条件-行动 规则解释器. (不包含历史信息, 只根据当天的环境) agent-type-1 基于模型的反射型Agent 包含历史信息, 状态信息. agent-type-2 基于目标的Agent 不仅需要采用行动, 还需要规定相应的目标. agent-type-3 判断执行的动作会不会使得自己离目标更近 基于效用的Agent 单靠目标难以在多数环境中产生更好的行为, 需要更快, 更安全, 更可靠等 效用函数: 描述Agent与状态相关的偏好程度, 在目标不充分的情况下有助于理性决策 多目标: 加权 存在冲突目标: 折中 agent-type-4 学习Agent 学习元件 执行元件 评价元件 问题产生器 agent-type-5 逻辑Agent 命题逻辑的语法 推理模式, 方法 怪兽世界的推理 (\\(R_1-R_{10}\\)的证明, \\(R_{11}-R_{15}\\)将句子转化成合取范式, 然后基于归结或反证法的证明) 理解推理规则和公理, 用于命题逻辑的推理 命题逻辑的连接符及语义 命题逻辑语法 logic-1 推理模式, 推理方法 画真值表 (不推荐, 繁琐) 运用公式法则 (重要, 要记) logic-2 logic-3 归结 :star: 只能取一项进行归结, 不能同时取很多项, 只用于文字的析取式 合取范式: 文字析取式的合取形式, CNF, 如何转化 知识表示 情景演算, 情景, 流, 前提条件公理 (可能性公理), 效应公理等概念 (背) 本体论, 类别, 对象, 举例说明 (背) 讨论的是 如何表示世界的事实, 着重于在不同领域都会出现的通用概念, 如动作, 时间, 物理对象, 信念, 表示这样的抽象概念是 本体论工程(en?) 本体论工程 以高某PPT为准 类别和对象 以高某PPT为准 动作, 情景, 事件, 流 对动作结果的推理是基于知识的Agent运作的中心问题 情景演算本体论 情景演算 流 fluent 使情景从一个变换到下一个的函数和谓词, 如Agent的位置或怪兽的死活 在定义谓词或函数时, 允许不受时间影响 概率推理 贝叶斯网络的定义, 语义 给定贝叶斯网络, 写出相应的联合概率分布 针对书中的盗贼警报任务, 理解贝叶斯网络的精确推理, 并能够在给定证据的情况下进行推理 贝叶斯网络的定义和语义 独立性, 条件独立性, 不确定域中的知识表示 减少了所需定义的概率数目 有向图, 结点代表概率信息 随机变量组成的网络结点 有向边集合 每个结点有条件概率 \\(P(X_i | Parents(X_i))\\) 无环 指定简单决策 理解什么是偏好, 效用, 最大期望效用原则 (计算期望) 理解决策网络, 尤其是网络中的结点类型 给定网络, 计算不同动作的期望效用, 并选具有最大期望效用的动作 在不确定性环境下结合信度和愿望 expectation-1","categories":[],"tags":[]},{"title":"语义分析","slug":"CS/Compiler-SemanticAnalysis-zh","date":"2023-01-03T09:42:03.000Z","updated":"2023-01-03T13:55:13.716Z","comments":true,"path":"2023/01/03/CS/Compiler-SemanticAnalysis-zh/","link":"","permalink":"https://andrew-rey.github.io/2023/01/03/CS/Compiler-SemanticAnalysis-zh/","excerpt":"\"书接上文\"","text":"\"书接上文\" 概述 语义翻译: 语义分析和中间代码生成一起实现. 语法制导翻译: 在语法分析时实现语义翻译. 使用上下文无关文法(CFG)来引导对语言的翻译, 是一种面向文法的翻译技术. 基本思想 语义属性: 在CFG中为文法符号设置语义属性, 表示语法成分对应的语义信息. 如何计算: 用文法符号所在的产生式相关联的语义规则计算 语法制导定义(SDD): 将每个文法符号和一个语义属性集合相关联 将每个产生式和一组语义规则相关联, 这些规则用于计算产生式中各个文法符号的属性值 注意: 同一个产生式出现相同符号时, 需要以下标区分, 因为有不同的语义含义 注意: 语义规则可以是一些 副作用 如打印等等 例子: 产生式 语义规则 \\(D \\rightarrow T\\ L\\) \\(L.inh = T.type\\) \\(T \\rightarrow int\\) \\(T.type = int\\) \\(T \\rightarrow real\\) \\(T.type = real\\) \\(L \\rightarrow L_1, id\\) \\(L_1.inh = L.inh\\) 语法制导翻译方案(SDT) 在产生式右部嵌入程序片段 (语义动作) 例子: \\(D \\rightarrow T\\ \\{L.inh = T.type\\}\\ L\\) \\(T \\rightarrow int\\ \\{T.type = int\\}\\) \\(T \\rightarrow real\\ \\{T.type = int\\}\\) \\(L \\rightarrow \\{L_1.inh = L.inh\\}\\ L_1, id\\) 语义动作在产生式的位置决定了动作的执行时刻: 例如第一个产生式, 在分析出\\(T\\)后, 可以根据语义动作, 将后面的\\(L\\)的语义属性赋值 语法制导定义SDD 分为 综合属性 和 继承属性 综合属性(Synthesized attribute) 在分析树上的结点\\(N\\)的 非终结符 \\(A\\)的综合属性只能通过\\(N\\)的子节点或本身的属性值来定义. 综合属性例子 综合属性例子 继承属性(Inherited attribute) 在分析树上的结点\\(N\\)的 非终结符 \\(A\\)的继承属性只能通过\\(N\\)的父节点, 兄弟结点或本身结点的属性值来定义. 继承属性例子 继承属性例子 终结符只有综合属性, 原因是其综合属性指向的是符号表序号(或者说是词法分析器提供的词法值), 不论其父结点怎么变, 终结符的属性都不会变, 因此不能存在继承属性. \\(SDD\\)中也没有计算终结符属性值的语义规则. 注释分析树(Annotated parse tree) 在分析树中标明语义值. SDD的求值顺序 在对语法分析树的一个结点求属性值之前, 应该 先求出它所依赖的所有属性值 依赖图(Dependency graph) 如果\\(X.a\\)的值 依赖于 属性\\(Y.b\\)的值, 则依赖图中有一条 从Y.b指向X.a的有向边. 方便起见, 可以将 综合属性放在结点的右边, 继承属性放在左边. 注意: 如果语义规则中含有副作用 (即调用了某个函数, 函数中用到了语义属性), 则为它创建一个 虚拟结点, 如下所示 虚拟结点 可行的求值顺序: 拓扑排序, 依赖者的序号大于被依赖者的序号. 只有综合属性的SDD, 可以按照任意自底向上的顺序计算它们的值 同时具有综合属性和继承属性的SDD, 不能保证存在应该顺序对各个结点上的属性进行求值 依赖图中没有环, 则至少存在一个拓扑排序 给定一个SDD, 很难确定是否存在某个语法树, 使得依赖图无环, 但存在 \\(L\\)-属性定义 和 \\(S\\)-属性定义 保证每个语法分析树都存在求值顺序, 依赖图无环. \\(S\\)-属性定义 仅使用综合属性的SDD, 可以在 自底向上 的语法分析过程中实现 \\(L\\)-属性定义 在一个产生式所关联的各属性之间, 依赖图的边 可以从左到右, 但不能从右到左. 正式定义为: 一个SDD是\\(L\\)-属性定义, 当且仅当它的每个属性要么 是一个综合属性 要么 是满足如下条件的继承属性 假设存在一个产生式\\(A \\rightarrow X_1X_2\\cdots X_n\\), 其右部符号\\(X_i\\)的继承属性仅依赖于 \\(A\\)的继承属性 (不能依赖于父结点的综合属性, 因为父结点的综合属性可能依赖子结点的继承属性, 会导致循环依赖) 产生式中\\(X_i\\)左边的符号的属性 (包括综合属性和继承属性) \\(X_i\\)本身的属性, 但\\(X_i\\)的全部属性不能在依赖图中形成环路 每个\\(S\\)-属性定义都是\\(L\\)-属性定义 语法制导翻译方案SDT \\(LR\\)分析, \\(SDD\\)是\\(S\\)属性的 \\(LL\\)分析, \\(SDD\\)是\\(L\\)属性的","categories":[{"name":"CS","slug":"CS","permalink":"https://andrew-rey.github.io/categories/CS/"}],"tags":[]},{"title":"WinterHoliday","slug":"Life/WinterHoliday","date":"2022-12-26T02:38:46.000Z","updated":"2022-12-26T05:13:08.470Z","comments":true,"path":"2022/12/26/Life/WinterHoliday/","link":"","permalink":"https://andrew-rey.github.io/2022/12/26/Life/WinterHoliday/","excerpt":"\"计划是什么\" \"墙上的风景 (即答\"","text":"\"计划是什么\" \"墙上的风景 (即答\" 前言 首先寒假大概分成三大块吧: 学习, 写代码, 生活. 方才一想, 发现寒假要做的事情还挺多的, 比如啥 编译原理, 然后由于提前回家, 考试推迟, 就导致还要 准备下学期初的考试, 然后大作业的话, 还有操作系统和数据库的两个大作业, 还有那个所谓的SRTP要做, 甚至还要 准备TOEFL和GRE, 准备出国的一些事情, 接着毕竟已经快大四了, 还要去找一些比较好的点, 复现别人成果也好, 自己写代码也好, 都要有一些相应的积累, 另外作为一个计算机学生, 还要修一些必要的课程. 在这闲暇之余, 还希望每天能写一些文字, 整个假期要看一些电影, 要找同学玩, 要做菜. 学习 编译原理 这必然是最重要的一部分 听网课 (主要看语义分析往后的内容), 看龙书 (整体浏览一遍) 写一个半成品的编译器 (具体要求都写到某个README里面去了) 每周必做 这里的内容的话, 又多又杂 复习某些考试课程 主要是一些非计算机课程, 需要每周花一点时间来做, 包括 自动控制原理, 近代物理 (热学). 人智导论和数据库可以考前一两周的时候复习. 至少看一部电影 每天必做 这里就继续规定一下合理的每天必做的事情 写代码: 计算机学生每天写点代码不过分吧 矫情文字打卡 看书 (为啥不写看啥啊, 因为好多书要看) 计算机课程 算法 图形学 制定一些ddl 数据库最后的大作业听天由命 (毕竟我不是组长, 但我希望快点写完) 操作系统最后一个实验 (这东西你不会还想留到明年吧) 过年前把编译器写\\(\\frac{2}{3}\\) (写完语义分析, 但理论要全学完) 开学前能不能把SRTP搞出个什么东西","categories":[{"name":"Life","slug":"Life","permalink":"https://andrew-rey.github.io/categories/Life/"}],"tags":[]},{"title":"Operating System","slug":"CS/OS","date":"2022-11-23T11:12:45.949Z","updated":"2022-11-23T11:12:45.950Z","comments":true,"path":"2022/11/23/CS/OS/","link":"","permalink":"https://andrew-rey.github.io/2022/11/23/CS/OS/","excerpt":"\"This is the basic class for CS.\" \"And it is interesting. I mean if you can totally master it.\"","text":"\"This is the basic class for CS.\" \"And it is interesting. I mean if you can totally master it.\" Concept Framework of this chapter: basic concepts OS components OS services (Using components) System call (how to provide services) Structure virtual machine These contents will be detailed written in the following chapters Operating system components Process management process: A process is a program in execution. program has its own address space OS activities: Process creation and deletion using fork system call Process suspension and resumption (挂起或恢复) Provision of mechanism for: process synchronization (进程同步) such as two processes should share a variable to achieve a task or job. And synchronization mechanism helps to finish this job in a proper order. process communication (进程通信) deadlock handling (死锁处理) Main memory management memory: Memory is a large array of words or bytes, each with its own address. It is a repository of quickly accessible data shared by the CPU and I/O devices. Main memory or primary storage is a volatile storage device (掉电易失设备). OS activities: Keep track of which parts of memory are currently being used and by whom. Decide which processes to load when memory space becomes available (Job scheduling, 任务调度). Allocate and deallocate memory space as needed. Virtual memory: Virtual memory allows programs to address memory from a logical point of view. This technique allows applications regard that they have a continuous address space rather than fragmented spaces from main memory to disk memory. without regard to the limits of physical memory. File management file: A file is a collection of related information defined by its creator. Commonly, files represent programs (both source and object form) and data. this a uniform logical view of information storage provided by OS. OS activities: File creation and deletion. Directory (can be seen as a special file) creation and deletion. Support of primitive for manipulating files and directories. Mapping files onto secondary storage. for large files, how to map them onto secondary storage? File backup (备份) on stable (nonvolatile) storage media. Windows file management is related to storage, but Linux not. In Linux, every thing is file, having a unified form to access files. Mount (挂载): create a mounting point, and this file is can be accessed using mounting point. I/O system management The I/O subsystem consists of: a buffer-caching system a general device-driver interface (a driver is a part of OS, specific for devices) programmed I/O interrupt I/O DMA drivers for specific hardware devices Secondary-storage (disk) management Secondary storage is the principle on-line storage medium (线性存储介质) for both programs and data. disk Main memory is volatile and too small to accommodate all data and programs permanently, so the computer must provide secondary storage to back up main memory. OS activities; Free space management (which parts of disk are free and how to allocate these free blocks) Storage allocation Disk scheduling (磁盘调度) 磁头移动, 请求分布在不同柱面上, 相应时需要磁头在不同不同柱面上切换, 经过算法, 设计磁头移动的最短距离 (有计算题). Protection system Protection refers to a mechanism for controlling access by programs, processes, or users to both system and user resources. distinguish between authorized and unauthorized usage. specify the controls to be imposed and means for enforcement. Example: In Linux, file access control: rwx, owner, user(u), group(g), other(o) Command-interpreter system Command-interpreter system(命令行解释系统): Interact with users, users can send instructions to OS. Shell its functions is to get and execute the next command statement. Operating system services Core operating system services From the view of an user: Program execution load a program into memory and to run it process management, memory management, disk management and so on. I/O operations user programs cannot execute I/O operations directly, the OS must provide some means to perform I/O. File-system manipulation programs capability to read, write, create and delete files Communication exchange information between processes Error detection ensure correct computing in CPU, memory hardware, I/O devices, user programs Additional operating system functions From a view of system: This part is user for efficient system operations, not for helping users. Resource allocation Accounting Protection System call An user how to use system services: Normally, we write C code and define the main function, this is a system call, but has been packaged to a convenient-to-use API. System call is an interface between a running program and the OS. generally available as assembly-language instructions. (汇编语言形式呈现) user programs (in user mode, mode bit=1) send a system call to the OS (in kernel mode, mode bit=0), and the OS execute the system call, then the OS returns (and change the mode bit to 1), finally the user programs continue to execute. Common in the OS Some language like C language and C++ are defined to replace assembly-language for system programming, which allow system call to be made directly. system_call1 The implementation of system call Typically, a number (index) associated with each system call. System call interface maintains a table indexed according to these numbers The system call interface invokes intended system call in OS kernel and returns status of the system call and any return values. (系统调用的接口使用OS内核中的系统调用, 并返回系统调用状态和相应参数) The caller need to know nothing about how the system call in implemented. just need to obey API and understand what OS will do as a result call. Most details of OS interface hidden from programmer by API manage run-time support library (set of functions built into libraries included with compiler) system_call2 In this picture, open() function acts as an API, and open() gives a system call (in the function library) to OS (maybe in the library, open() function use other system functions to give a system call, because open() is just an API of system call functions). Then the OS look up this system call in its number table and then execute a specific system program (according to the index number). Finally, the OS returns the states. Parameter passing in system call Often, more information is required than simply identity of desired system call. Three types: simplest: pass the parameters in registers maybe more parameters than registers Parameters stored in a block, or table, in memory. and pass the block address to registers. taken by Linux and Solaris Parameters placed, or pushed onto the stack by program and popped off the stack by the OS. Block and stack don't limit the number and the length of parameters. Types of system call Five main types: process control file management device management information maintenance communication process management Table 1: process management for major POSIX system call description pid=fork() create a child process identical to the parent (child is same with parents process) pid=waitpid(pid, &amp;statloc, options) wait for a child to terminate s=execve(name, argv, environp) replace a process' core image, can be used with fork() to let child do another things but both from parents process exit(status) terminate process execution and return status file management Table 2: file management for major POSIX system call description fd=open(file, how, ...) open a file for reading, writing, or both, fd is 文件描述符 s=close(fd) close an open file n=read(fd, buffer, nbytes) read data from a file into a buffer n=write(fd, buffer, nbytes) write data from a buffer to file position=lseek(fd, offset, whence) move the file pointer s=stat(name, &amp;buf) get a file's status information mkdir() create a new directory rmdir() remove an empty directory link() create a new entry, name2, pointing to name2. (soft link) unlink() remove the directory entry mount() mount a file system unmount() unmount a file system miscellaneous system call call description chdir() change working dir kill() send a signal to a process chmod() change a file's protection bits time() get the elapsed time since Jan 1, 1970 System structure monolithic单体结构（一个进程）\\(\\rightarrow\\) 分层式 \\(\\rightarrow\\) 微内核结构（最核心的功能放在内核中）、模块化结构（linux） ### UNIX have no concept of structure, is Single core structure. consists of two separable parts: system programs the kernel Microkernel assign only a few essential functions to the kernel address spaces interprocess communication (IPC) basic scheduling Benefit and detriments reliable easy to extend secure communication occupies much space Modules most modern OS implement module method: kernel is divided into different modules. 层次化不明显；可以动态对内核进行装载和删除内核模块 Virtual machine treats hardware and the OS kernel as though they were all hardware (对物理资源抽象，即抽象层，在抽象层能实现虚拟机) management application: type 1: built on hardware use hardware directly usually used in data center or service type 2: built on the OS lower performance (性能) lower security usually used on PC Process Concept of process What is a process? A program in execution An instance(实例) of a program running on a computer 同样代码跑两遍，是不同的进程 The entity(实体) that can be assigned to(指派) and executed on a processor A unit of activity characterized by the execution of a sequence of in instructions, a current state, and an associated set of system resources(一系列指令执行，状态(如wait, execution, ready)，有资源) Process in memory text 代码段(addr=0) code codes are complied and stored here data 数据段 global data static data heap 堆 new() delete() stack 栈(addr=max) local function invoking local variables calling example: 12345678910int x = 1;int main()&#123; int a; static int b; f1(); int* pointer = NULL; pointer = int new(); return 0;&#125; x and b are in data sector; a and f1() are in stack; pointer points to a space of heap. HINT: there is a flexible space between heap and stack. Process elements program code (possible shared) a set of data a number of attributes describing the state of the process Trace of the process The behavior of an individual process is shown by listing the sequence of instructions the are executed. (指令按序执行) This list is called a trace. Dispatcher is a small program which switches the processor from one process to another. (进程切换) User-view of process Process creation The OS builds a data structure to manage the process. Traditionally, the OS create all processes But it can be useful to let a running process create another This action is called process spawning (进程派生) Parent process is the original, creating processes Child process is the new process Parent process create child process, and child processes create other processes, forming a tree of process. Execution (can be set manually) parent processes and child processes execute concurrently (同时执行). parents wait when children terminate HINT: the children just copy a status of parent command description fork system call creates new same process exec system call used after a fork to replace the process' memory space with a new program The differences using fork() in parents and children processes fork返回给child_pid在两个进程中不一样. 在父进程中fork()的返回值大于零, 即子进程的编号; 在子进程中fork()的返回值是0. 可以理解为父进程在fork()的初期产生了子进程, 此时子进程拿到的返回值是初始化的返回值 0, 在父进程即将结束fork()时, 父进程拿到了被赋值的返回值. 因此在子进程中不会再次执行fork(), 而执行其后面的内容. 子进程不会再次执行父进程先前的内容, 只是创建时与父进程处于相同的状态. 父子进程执行的先后顺序取决于 OS 的调度 example 1: 12345678910111213141516pid = fork();if (pid &lt; 0)&#123; fprintf(stdrr, &quot;fork failed&quot;) exit(-1);&#125;else if (pid == 0) // child process&#123; execlp(&quot;/bin/ls&quot;, &quot;ls&quot;, NULL); // replace with a new command&#125;else // parent process&#123; wait(NULL); printf(&quot;children complete&quot;); exit(0);&#125; example 2: 1234567891011121314151617181920/*in file fork.c:*/int main()&#123; pid_t child_pid; printf(&quot;the main program ID is %d\\n&quot;, (int)getpid()); child_pid = fork(); if (child != 0) &#123; printf(&quot;this is the parent process, with ID is %d\\n&quot;, (int)getpid()); printf(&quot;the child&#x27;s process ID is %d\\n&quot;, (int)child_pid); &#125; else &#123; printf(&quot;this is the child process, with ID %d\\n&quot;, (int)getpid()); &#125; return 0;&#125; And the running result is: Process termination Process executes last statement and asks the OS to delete it. (exit()) Output data from child to parents (viawait()) Process' resources are de-allocated (收回) by the OS Parents may terminate the execution of children processes. (abort()) Some situations of this: Child has executed allocated resources Task assigned to child is non longer required Parent is exiting OS does not allow child to continue if its parent terminates Cascading termination (级联终止) HINT: 父进程结束不代表子进程必须结束 Code block creating process: int fork(void); create a new process that is exact copy of current one returns process ID of new process in parent return 0 is child int waitpid(int pid, int *stat, int opt); pid: process to wait for, or -1 for any stat: will contain exit value, or signal opt: usually 0 or WNOHANG (?what's this) return: process ID or -1 if error deleting process: void exit(int status); current process ceases to exit status shows up in waitpid(shifted) by convention, status of 0 is successful, non-zero is error int kill(int pid, int sig); sends signal sig tp to process pid sig=SIGTERM: most common value, kills process by default application can catch ti for \"cleanup\" sig=SIGKILL: stronger, kills process always running programs: int execve(char *prog, char **argv, char **envp); int execlp(char *prog, char *arg, ...); Kernel view of process (using Process Control Block, PCB) Main problem: How to manage such many process? For traditional UNIX process: process is an abstraction of OS, which represents what is needed to run a program. often called a \"HeavyWeightProcess\" while a thread is called \"轻量级\" This traditional process has two parts: sequential program execution stream. (now is thread) code executed as a sequential stream of execution (thread) includes states of CPU registers protected resources main memory state IO state Process Elements identifier state priority program counter (in fact has many registers, not only the PC) memory pointers context data IO status information accounting information and so on Implementing process 内核如何实现一个进程? 管理一个进程? keep a data structure for each process process control block (PCB) called \"proc\" in Unix and \"task_struct\" in Linux track states of process ----\"Process State\" running, waiting, ready... includes information necessary to run registers, virtual memory mapping, open files... Various other data about the process such as user/groups... PCB is also a snapshot of a process, saving all status of a process. Process states new: the process is being created ready: the process is waiting to be assigned to a processor running: instructions are being executed waiting: the process is waiting for some event to occur terminated: the process has finished execution The process switching graph is shown as following: process_state The CPU switch from process to process: state_switch when to switch processes: interrupt trap current process running is wrong system call switch steps: save context of processor including program counter and other registers update the PCB that is currently in the Running state move the PCB to appropriate queue select another process for execution update the PCB of the process selected update memory-management data structures restore context of the selected process Process scheduling queues Job queue: set of all processes in the system Ready queue: set of all processes residing in main memory, ready and waiting to execute Device queue: set of processes waiting for an I/O device Process migration between the various queue. queue_switch Scheduler Long-term scheduler(Job scheduler): select which processes should be loaded into memory for execution. Short-term scheduler(CPU scheduler): selects which process should be executed next and allocates CPU Short-term scheduler is invoked very frequently (milliseconds----must be fast) Long-term scheduler is invoked very infrequently (seconds, minutes----may be slow) The long-term scheduler controls the degree of multiprogramming IO-bound process: spends more time doing IO than computations, many shout CPU bursts CPU-bound process: spends more time doing computations, few very long CPU burst We also have Medium-term scheduler Inter-process communication Cooperating process Independent process cannot affect or be affected by the execution of another process. Cooperation process can affect or be affected by the execution of another process. Advantages information sharing computation speed-up modularity convenience Communication models message model smaller data exchange inter-computer communication (跨机的通信) system call with kernel shared memory Maximum speed/memory convenience of communication protection and synchronization routine memory access without kernel intervention Producer-Consumer Problem: Paradigm for cooperating processes, producer process produces information that is consumed by a consumer process POSIX shared memory example Cmd description shmget() A process creates a shared memory segment using this function shmctl() the original owner of a shared memory segment cna assign ownership to another user with this function shmat() Once created, a shared memory segment can be attached to a process address space using this shmdt() shared segment can be detached using this Inter-process Communication(IPC) Two operations: send(message) receive(message) if P and Q wish to communicate, they need to establish a communication link between them exchange messages via send/receive Direct Communication Processes must name each other explicitly: send(P, message)----send a message to P receive(Q, message)----receive message from Q Properties of communication link: links are established automatically a link is associated with exactly one pair of communication processes between each pair processes, there exists exactly one link the link may be unidirectional, but is usually bidirectional Indirect Communication Operations: creates a new mailbox send and receive messages through mailbox destroy a mailbox Primitives are defined as: send(A, message)----send a message to mailbox A receive(A, message)----receive a message from mail box A Problems: P1, P2 and P3 share mailbox A, P1 sends, P2 and P3 receive, who get the message? Allows a link to be associated with at most two processes Allow only one process process at a time to execute s receive operation Allow the system to select arbitrarily the receiver. Sender is notified who the receiver was. Synchronization Message passing may be either blocking(阻塞), or non-blocking(非阻塞) Buffering: zero capacity bounded capacity unbounded capacity Pipe | or Pipe(), there is a read end and a write end Three communication methods shared memory pipe sockets Threads Concept A thread (lightweight process, LWP) is a basic unit of CPU execution. a sequential execution stream within process A thread has a thread ID, a program counter, a register set and a stack. A thread shares with each other threads in the same process its code section, data section, and other OS resources(e.g. files and signals) Multithreading: a single program made up of a number of different concurrent activities. Actual thread operations cmd description thread_fork(func, args) create a new thread to run func(args) thread_yield() relinquish processor voluntarily thread_join(thread) in parent, wait for forked thread to exit, then return thread_exit() quit thread and clean up, wake up joiner if any pThreads: POSIX standard for thread programming thread switching faster than process switching(100 ns) User Thread thread management done by user-level thread library: e.g. POSIX Pthread, Mach C-threads, Solaris UI-threads User thread are supported at the user-level, the kernel is not aware of user threads(kernel treat them as processes). A library provides all support for thread creation, termination, joining and scheduling. There is no kernel intervention and hence, user threads are more efficient. Unfortunately, since the kernel only recognizes the containing process (of the threads), if one thread is blocked, every other threads of the same process are also blocked because the containing process is blocked. Kernel Threads Supported by the kernel. Kernel maintains context information for the process and the threads. Kernel threads are directly supported by the kernel. THe kernel dose thread creation, termination, joining and scheduling in kernel space. Kernel threads are usually slower than the user threads. However, blocking one thread will not cause other threads of the same process to block. The kernel simply runs other threads In a multi-processor environment, the kernel can schedule threads on different processors. The kernel has a thread table that keeps track of all the threads in the system. All calls that might block a thread are implemented as system calls. When a thread blocks, the kernel can run either another thread from the same process or a thread from a different process. Multi-threading Models Many-to-one Many user-level threads mapped to single kernel thread. Used on system that do not support kernel thread. One-to-one Each user-level thread maps to kernel thread. Many-to-Many Allow many user threads to be mapped to many kernel threads. Allows the OS to create a sufficient number of kernel threads. Threading Issues Semantics of fork() and exec() Does fork() duplicate only the calling thread or all threads? (应该复制所有线程还是指定线程) if invoke exec() just after fork(), no need to duplicate all threads, since it is no meaning to duplicate all threads now that they will be replaced right after fork() if invoke exec() after fork() for a long time, it will duplicates all threads Thread Cancellation Terminating a thread before it has finished, two general approaches: Asynchronous cancellation (terminate thread immediately) Deferred cancellation (thread check itself if it should be cancelled periodically) Signal handling Signal is used to notify a process that a particular event has occurred. All signal has same patterns: generated by particular event delivered to a process signal is handled A signal handler is used to process signals options deliver the signal to the thread to which the signal applies deliver the signal to every thread in the process ~ to certain threads Assign a specific thread receive all signals for the process Thread Pools Create a number of threads in a pool where they await work. Advantages Usually slightly faster to service a request with an exiting thread than create a new thread. Allows the number of threads in the application(s) to be bound to the size of pool. Thread Specific Data Allows each thread to have its own copy of data Scheduler Activations Both M:M and Two-level models require communication to maintain the appropriate number of kernel threads allocated to the application 一种解决解决用户线程库和内核间通信的方法被称为 调度器激活. Scheduler activations provides upcalls, a communication mechanism from the kernel to the thread library. 上级调用用于告知用户程序特定的事件 CPU Scheduling (Important!) Objective: design a scheduling algorithm for CPU. (select time point, select jobs to execute) Maximum CPU utilization obtained with multiprogramming CPU-I/O Burst cycle: Process execution consists of a cycle of CPU execution and I/O wait. Process execution repeats the CPU burst and I/O burst cycle. When a process begins an I/O burst, another process can use the CPU for a CPU burst. CPU, I/O bound CPU bound: a process generates I/O requests infrequently, using more of its time doing computation I/O bound: a process spends more of its time to do I/O than doing computation CPU Scheduler: When the CPU is idle, the OS mus select another process to run. The selected process is carried out by the short-term scheduler(CPU scheduler). The CPU scheduler selects a process from the ready queue, and allocates the CPU resources to it. The ready queue does not have to be a FIFO one. There are many ways to organize the ready queue. Circumstances that scheduling may take place running -&gt; wait (e.g. doing for I/O) running -&gt; ready (e.g. interrupt occurs) wait -&gt; ready (e.g. I/O completion) terminates scheduler_time Non-preemptive scheduling (非抢占式调度): scheduling occurs when a process voluntarily enters the wait state or terminates----simple, but very inefficient Preemptive scheduling (抢占式调度): scheduling occurs in all possible cases. Dispatcher: gives control of the CPU to the process selected by the short-term scheduler, involves: switching context, switching to user mode, jumping to the proper location in the user program to restart that program. Dispatcher latency: time it takes for the dispatcher to stop one process and start another running Scheduling Criteria (调度准则) Five common ones: CPU utilization (max) want to keep CPU as busy as possible throughput (吞吐量) (max) the number of processes completed per time unit long processes: rate is low, short processes: rate is high turnaround time (周转时间) (min) the time period between job submission to completion including: waiting time before entering the system waiting time in the ready queue waiting time in all other events (e.g. I/O) time the process actually running on the CPU waiting time (min) the sum of the periods that a process spends waiting in the ready queue. (because CPU scheduling algorithm do not affect the amount of time during which a process is waiting for I/O and other events, so we consider waiting time in ready queue only) response time (min) the time from the submission of a request to the first response (in an interactive system). do not include the time that it takes to output the response Scheduling Algorithm First-Come, First-Served (FCFS) Shortest-Job-First (SJF) Priority Round-Robin Multilevel Queue Multilevel Feedback Queue FCFS description: the process that requests the CPU first is allocated the CPU first Queue Non-preemptive: once a process has the CPU, it will occupy the CPU until the process completes or voluntarily enters the wait state. Gantt Chart average waiting time: calculate convoy effect (护航效应): short processes behind long processes disadvantages convoy effect: all the processes wait for one big process to get off the CPU. CPU utilization may be low. not be fair to those short ones. troublesome for time-sharing system, where each user needs to get a share of the CPU at regular intervals. SJF use each process' CPU burst length----shortest the first: when a process must be selected from the ready queue, the process with smallest next CPU burst is selected. The processes in the ready queue are sorted in CPU burst length if non-preemptive: once the CPU is given to the process, it cannot be preempted until completes its CPU burst if preemptive: if a new process arrives with less CPU burst length than remaining time of others, it will be selected immediately. shortest-remaining-time-first(SRTF) SJF is optimal: gives minimum average waiting time for a given set of processes. some examples: pree how to know the next CPU burst? predict: using the length of previous CPU bursts, using exponential averaging \\[ \\tau_{n+1}=\\alpha t_n + (1-\\alpha)\\tau_n \\] \\(t_n=\\)actual length of \\(n^{th}\\) CPU burst \\(\\tau_{n+1}=\\)predicted value for the next CPU burst \\(\\alpha\\in[0,1]\\) this is a weighted equation for history data and current data disadvantages difficult to estimate the next burst time value accurately in favor of short jobs. some long time jobs have no chance to run. (starvation) Priority Priority may be determetered internally or externally. FCFS and SJF are the special cases of Priority. non-preemptive preemptive: if the newly arrived process has higher priority, it is selected. but indefinite block (or starvation) may occur: a low priority process may never have a chance to run method: Aging: gradually increases the priority of processes that wait in the system for a long time. It is a technique to overcome the starvation problem. Round Robin (RR) Similar to FCFS, except that each process is assigned a time quanntum All processes are in the ready queue (FIFO list). When the CPU is free and lets it run for one time quantum. If a process uses CPU for more than one time quantum, it is moved to the tial of the list. Some issues if time quantum is too large, RR reduces(退化) to FCFS if time quantum is too small, RR becomes processor sharing context switching may affect the performance of RR, shorter time quantum means more context turnaround time dependes on the size of time quantum in general, 80% of the CPU burst should shorter than the time quantum Multilevel Queue (多级队列) Ready queue is partitioned into separate queues: foreground (interactive), background (batch) [ 有些进程希望保留在系统中(交互进程)，而有些进程则是后台进程，因此可以延迟执行。] Each process is assigned permanently to one queue based on some properties of the process Each queue has its own scheduling algorithm: foreground, interactive----RR bacjground, batch----FCFS Hint scheduling must be done between the queue: fixed priority scheduling(i.e. serve all from foreground then from background); Possibility of starvation. time quantum, each queue gets a certain amount of CPU time which it can amongst its processes Multilevel Feedback Queue (多级反馈队列) allows processes to move between queues. (can be implemented by aging) if a processe uses more CPU time, it is moved to a queue of lower priority. defined my the following parameters: numbers of queues scheduling algorithm for each queue method used to determine when to upgrade a process method used to determine when to demote a process method used to determine which queue process will enter whne that process needs services Multiple-Process scheduling Symmetric multiprocessing--self scheduling for each processor Affinity(亲和性)--cost of cache: 当进程在 CPU 间切换时, 需要对 cache 进行重构. 需要避免 cache 重构所带来的开销 Hyperthreading--logical processors seen by CPU (i.e. by setting BIOS) Thread scheduling Local scheduling--how the threads library decides which thread to put onto an available LWP Global scheduling--how the kernel decides which kernel thread to run next Algorithm Evaluation no notes here. Process Synchronization 进程合作时, 几个进程之间会相互影响. 合作的进程要么会直接共享逻辑地址空间 (即代码和数据), 要么通过共享内存或信息传递的方式进行通信. 但是并发的进程对数据操作可能会导致数据的不一致, 因此需要进程间进行同步. 进程同步--抽象为临界区问题--提出三种解决方案 (软件方案, 硬件方案, 信号量方案)--经典同步问题--管程 (相对高级的同步结构)--补充例子 ## Background Concurrent access to shared data may result in data inconsisitency. Maintaining data consistency requires mechanisms to ensure the orderly execution of coorperating processes. Such as producer-consumer problem need a mechanism to ensure the order of execution. Race Condition Race condition occurs, if: 2 or more processes/threads access and manipulate the same data concurrently the outcome of the execution depends on the particular order in which the access takes place. to prevent race conditions, concurrent processes must be synchronized the critical-section problem (临界区问题) Each process has a code segment, called critical-section, in which the shared data is accessed. Problem: ensure that when one process is executing in its critical section, no other process is allowed to execute in its critical section. So it's necessary to design a protocol that processes can use to cooperate. A protocol consists of two parts: entry section and exit section. Between them is the critical section running in a mutually exclusive way. condition must be followed Mutual exclusion (互斥) If there is a process exexuting in critical section, the entry protocol should be capable of blocking processes that wish to enter. And if the process in critical exits, the entry protocol must know the fact, and allows a waiting process to enter. Progress (前进/有空让进) If no process is executing in its critical section and some processes wish to enter critical sections, then only those processes that are waiting to enter can participate in the competition; no other process can influent the decision; this decision cannot be postponed indefinitely (不可无限推迟). Bounded waiting (有限等待) After a process made a request to enter its critical section and before it is granted the permission to enter, there exits a bound on the time to wait (it means that, a process will not wait forever to enter it critical section). HINT:the solution to critical-section problem cannot depend on relative speed of processes and scheduling policy. We should design a solution to satisfy the three condition. (临界区问题需要满足以上三种条件) For two process condition: (Peterson algorithm, Important!) 12345678do &#123; flag[i] = true; turn = j; while (flag[j] == true &amp;&amp; turn == j); // critical section flag[i] = false; // remainder section&#125;while (1); ref:peterson algorithm Synchronization hardware Two types: disabling enabling interrupts close interrupt if a process in critical section; Special machine instructions. Interrupt disabling Because interrupts are disabled, no context switch will occur in a critical section. Infeasible in a multiprocessor system because all CPUs must be informed. Some features that depend on interrupts (e.g. clock) may not work properly. Using Atomaical instructions Test and modify the content of a word atomically. atomical instructions mean an instruction that can't be devided or interrupted. Test-and-Set 123456789101112131415// define the test and set functionbool TestAndSet (bool *lock) &#123; bool rt = *lock; *lock = true; return rt;&#125;// shared data:bool lock = false;// process P_ido &#123; while (TestAndSet(&amp;lock)); // critical section lock = false; // remainder section&#125;while (1); the TestAndSet() function realizes that it changes all processes' status to enter critical section, but keeps the old value of one process which is going to enter critical section. This function satisfies Mutual Exception rule. However, this mathod not satisfies Bounded Waiting rule. Change TestAndSet to satisfy Bounded Waiting: 12345678910111213141516171819// enter critical sectionwaiting[i] = true;key = true;while (waiting[i] &amp;&amp; key) &#123; key = TestAndSet(lock);&#125;waiting[i] = false;// leave critical sectionj = (i + 1) % n;while ((j != 1) &amp;&amp; !waiting[j]) &#123; j = (j + 1) % n;&#125;if (j == i) &#123; lock = false;&#125;else &#123; waiting[j] = false;&#125; Though this is a code form, but TestAndSet() is realized in hardware form. Swap 123456789101112131415161718void Swap(bool &amp;a, bool &amp;b) &#123; bool temp = a; a = b; b = temp;&#125;// shared data, initializaed by falsebool lock = false;// local databool key;// for process P_ido &#123; key = true; while (key == true) Swap (key, lock); // critical section lock = false; // remainder section&#125;while (1); The Swap() function will swap the value of lock and key, if Semaphores (信号量, Important!) Most used~ Programmer-frendly~ 信号量可以看作是对资源数量的衡量, 用于临界区问题时, 由于临界区只有一个, 因此信号量设置为1. 12345678910111213141516171819// atomic operatorvoid wait(S) &#123; while (S &lt;= 0); S--;&#125;void signal(S) &#123; S++;&#125;// algorithm// shared datasemaphore mutex = 1;// for process p_ido &#123; wait(mutex); // critical section signal(mutex); // remainder section&#125; while(1); semaphore algorithm satisfies three rules. semaphore is like a lock. wait() lock, and signal() delock. the disadvantage is semaphore makes other processes busy waiting, which do nothing while waiting. for single CPU, it waste CPU resource. this is spinlock. spinlock is usually used in multi-core system, one process can enter another CPU's critical section while one process is in now critical section. the difference waiting state: ref:WaitingState Optimization: no busy-waiting Makes one process not to busy-wait but to block itself or mounted. 123456789101112131415161718192021// define a new semaphoretypedef struct &#123; int value; struct process *L; // waiting process queue&#125; semaphore;// edit wait() and signal()void wait(S) &#123; S.value--; if (S.value &lt; 0) &#123; // add this process to S.L block; &#125;&#125;void signal(S) &#123; S.value++; if (S.value &lt;= 0) &#123; // remove a process P from S.L wakeup(P); &#125;&#125; Deadlock two or more processes are waiting indefinitely for an event that can be caused by only one of the waiting processes. Starvation indefinite blocking. A process may never be removed from the semaphore queue in which it is suspended. Classical problems of Synchronization bounded-buffer problem reader and writer problem dining philosophers problem Bounded buffer problem 生产者消费者问题: 存在若干生产者, 若干消费者以及一个缓冲区. 123456789101112131415161718192021222324252627282930313233343536373839// initialization shared datasemaphore full, empty, mutex; // full and empty relize the synchronization between consumer and producer, and also represent the resource.full = 0; // empty = n; // initial spacemutex = 1; // 当前临界区没有进程, 当缓冲区大小为 1 时, 可以不用此变量.// producer process:do &#123; // code produce an item in nextp // code wait(empty); // judge if be full wait(mutex); // buffer = 1 时, 可删 // code add nextp to buffer // detail operation: buffer[in] = nextp; in = (in + 1) % bufferSize; // buffer = 1 时, 可删 // code signal(mutex); // buffer = 1 时, 可删 signal(full); // inform&#125; while(1);// consumer processdo &#123; wait(full); wait(mutex); // code remove an item from buffer to nextc // detail operation a = buffer[out]; out = (out + 1) % bufferSize; // code signal(mutex); signal(empty); // code consume the item in nextc // code&#125; while(1); Reader-Writer Problem 以数据库为背景, 同时有若干的写者和读者对数据库进行操作. 写时不可读, 读时不可写. 如何权衡进程通信? 第一读者问题: 读者可以一直读, 除非有写者正在写. 说白了就是读者优先级高于写者. 第二读者问题: 读者优先级低于写者. 12345678910111213141516171819202122232425262728// shared datasemaphore mutex, wrt;int readcount;// initailizationmutex = 1;wrt = 1; // 表示是否可以写, 或者是写的资源readcount = 0;// writerwait(wrt);// writer is writingsignal(wrt);// readerwait(mutex); // 存在并发的读者程序readcount += 1;if (readcount == 1) &#123; wait(wrt); // 第一个读者与写者进行权限的争抢 // 若抢到权限, 则后续读者无需再次判断, 登记读者数目后, 直接进行读的操作.&#125;signal(mutex);// reader(s) are readingwait(mutex);readcount -= 1;if (readcount == 0) &#123; signal(wrt); // 最后一个读者释放对数据库操作的权限&#125;signal(mutex); Dining-Philosophers Problem 问题描述: 有多个哲学家在一个圆桌上用餐. 相邻两人间放着 一支 筷子, 哲学家只能拿与自己相邻的筷子, 若拿到了两根筷子, 则可以用餐, 用完后放回. 但若只拿到一支筷子, 则等待另一支筷子并且不放下手中的筷子, 直到有两双筷子. 若一支也没有拿到, 则进行等待. 设计进程同步, 并防止 死锁. 假设有 5 个哲学家和 5 支筷子. Method 1(exit deadlock): 12345678910// shared datasemaphore chopsticks[5] = &#123;1, 1, 1, 1, 1&#125;;// for every philosopher i:do &#123; wait(chopstick[i]); wait(chopstick[(i + 1) % 5]); eat(); signal(chopstick[i]); signal(chopstick[(i + 1) % 5]);&#125; while(1); 显然, 当每个哲学家都拿左边的筷子时, 会发生死锁现象. Solution 1: 设置一个\"房间\"作为信号量, 房间只能一次性供四个人使用 Solution 2: 将拿起左筷子和右边筷子 (拿一双筷子) 作为一个原子操作, 将其放入临界区. Solution 3: 规定奇数和偶数序号的哲学家遵守不同的拿筷子的顺序: 奇数先左后右, 偶数先右后左. 具体伪代码见操作系统习题 Monitors Synchronization example 后面半本书没有写博客 结果是最后操作系统大寄","categories":[{"name":"CS","slug":"CS","permalink":"https://andrew-rey.github.io/categories/CS/"}],"tags":[]},{"title":"今天又是码代码的一天呢","slug":"Life/Code","date":"2022-10-12T02:33:32.000Z","updated":"2022-12-26T02:57:21.831Z","comments":true,"path":"2022/10/12/Life/Code/","link":"","permalink":"https://andrew-rey.github.io/2022/10/12/Life/Code/","excerpt":"\"正如标题所言, 今天又是写代码的一天呢\" \"哈哈\"","text":"\"正如标题所言, 今天又是写代码的一天呢\" \"哈哈\" 2022年秋 Disk上的矩阵乘法 10/16 discription: 由于矩阵太大, 不能一次性load进内存, 希望研究缓存大小, 对矩阵乘法效率的影响. lang: Cpp project: 暂未完成 本来以为挺简单的一个作业, 没想到这么复杂, 10%的时间在写矩阵乘法, 自以为是地写了个指定嵌套顺序的for循环, 然后发现难点在于文件的读取和写入. 问题 1: 写入时覆盖 由于缓存大小有限, 并且对于特定的for循环顺序, 矩阵可能需要以列的方式写入, 这时候如何定位指针的顺序? 问题 2: 读取时返回 意思是我需要的矩阵的绝对坐标小于此坐标在缓存上的相对坐标(即相对坐标小于0), 这时候需要返回去读取, 但是如果从头开始读取, miss hit 的数目会陡然增加, 如果从当前位置读取, 需要知道上一次指针的位置, 然而上一次的指针已经被更新了, 并且更新的时间不在同一个生命周期. 问题 3: 以上两种情况有可能在读取和写入时都出现 问题 4: 写入时返回需要先读取再写入, 直到下标符合条件 外部快排 10/9 discription: use interval heap to realize the priority double ended queue (PDEQ); use PDEQ to do external sort. lang: Cpp project: ExternalQuickSort 说实话还是第一次写一个六百多行的代码. 虽然不知道用六百行实现一个简单的外部快速排序是否比较能令人接受, 但我还是从中学到了很多东西. 使用STL 以前一般是说说要用STL比较高效, 不过自己看了一些教程以后, 也一直没有什么用武之地, 所以很多东西经常会忘. 然后这份代码里就用了很多的诸如std::deque, std::vector等一些简单的STL, 当然, 期间还用了一些std::priority_queue, 但是发现并不能实现自己的目标 (能以\\(O(1)\\)效率返回最大值和最小值), 所以就基于std::deque做了一个interval heap. 官网DOC 以前不太习惯在这里参考资料, 但是终于对网上那些复制粘贴的, 没有思考的blog忍无可忍了, 于是转身求助官网. CMake 之前自己学了CMake, 这次终于用上了. yysy, CLion的CMake及时更新还挺好的. Main 说说主要内容. 这里主要是针对内存大小有限, 希望能对硬盘上的大量数据排序. 人为定义宏来规定当前的内存大小 (只关心待排序的数据, 不考虑中间变量) 将内存划分为 Input, Small, Large 和 Middle 四个区. Middle 相当于快排里的pivot, 然后递归对Small和Large排序, 这里使用循环+栈的方式实现递归. 文件读写, 我认为的本项目最繁琐的操作之一. 因为当缓冲区满了以后, 再次写入时, 可能需要保留上一次写入的末尾位置, 所以我新定义了一个栈用来存末尾指针.","categories":[{"name":"Life","slug":"Life","permalink":"https://andrew-rey.github.io/categories/Life/"}],"tags":[]},{"title":"Compiler-zh","slug":"CS/Compiler-zh","date":"2022-09-05T08:23:27.000Z","updated":"2023-01-03T09:43:15.192Z","comments":true,"path":"2022/09/05/CS/Compiler-zh/","link":"","permalink":"https://andrew-rey.github.io/2022/09/05/CS/Compiler-zh/","excerpt":"\"编译原理网课\" \"B站大学不用交学费!!!\"","text":"\"编译原理网课\" \"B站大学不用交学费!!!\" 引论 编译: 由高级语言转化为低级语言 解释: 接受高级语言的 一个语句输入, 进行解释并执行, 立刻得到执行结果, 然后再接受下一句. 不产生目标文件, 直观易懂, 结构简单, 易于人机对话 但效率低: 没有目标文件, 每次运行相当于要重新解释 编译的两个转换形式 编译 - 运行 先编译产生机器语言, 生成目标文件(.exe), 在运行时添加参数 编译 - 汇编 - 运行 编译后产生汇编语言, 生成目标文件(.obj), 汇编语言汇编后产生机器语言 编译过程 源程序 -&gt; Lexical analyzer -&gt; Syntax analyzer -&gt; Semmantic Analyzer -&gt; Intermediate code generation -&gt; Optimization -&gt; Code generation -&gt; Target symbol table management, error handler 词法分析 Lexical Analysis 扫描源程序, 识别一个个 单词lexeme, 并进行 分类token (包括: keyword, constant, identifier, operator, separator). 转化后的格式为 &lt;token-name, attr-value&gt;, 前者为token, 后者为 指向符号表的指针. 描述词法规则的有效工具是 正规式和有限自动机 语法分析 Syntax Analysis 把单词符号组成各类各类的语法单位, 如短语, 句子, 过程, 程序等 方法: derive: 最右推导: 每次将最右的部分按照规则进行转化 最左推导: reduce: 推导的逆过程 最左归约: 最右推导的逆过程 最右归约: 最左推导的逆过程 计算机处理方法: 语法树 语义分析 Semmantic Ananlysis 审查源程序有无语义错误, 为代码生成阶段收集类型信息. 重要的一步是 类型检查 中间代码生成 Intermediate Code Generation 中间代码设计原则 容易生成 容易翻译为目标代码 中间代码形式: 四元式, 三元式, 逆波兰式 四元式: &lt;运算符, 操作数1, 操作数2, 结果&gt; 优化 Optimization 原则: 等价变换 主要方面: 公共子表达式的提取, 合并已知量, 删除无用语句, 循环优化 目标代码生成 Code Generation 将经过优化的中间代码转化为特定机器上的低级语言 目标代码的形式: 绝对指令代码: 可立即执行的目标代码, 纯粹的0-1代码. 汇编指令代码: 汇编语言程序, 需要通过汇编程序汇编后才能运行, 能和物理机隔离. 可重定位指令代码: 先将各目标模块连接起来, 确定变量, 常数在主存中的位置, 装入主存后才能成为可以运行的绝对指令代码, 而后还需要进行 链接. 表格管理 Symbol Table Management 用来记录源程序的各种信息和编译过程中的各种状况. 与编译前三段有关的表格有: 符号表, 常数表, 标号表, 分程序入口表, 中间代码表 错误处理 Error Handler 如果源程序出错, 编译程序应该设法发现错误, 并报告给用户. 其他概念 趟/遍 pass: 将源程序从头到尾扫描一遍, 做相应的加工处理, 并生成相应的中间代码和目标代码. 多遍扫描可以节省内存空间, 提高目标代码质量, 使编译的逻辑结构更清楚, 但编译时间长, 因此 no free launch. 因此在一遍编译中: 源程序 -&gt; 编译程序 -&gt; 目标代码 编译程序的编写 直接用机器语言 用汇编语言编写, 编译程序的核心部分常用汇编语言编写 编译程序怎么生成? 编译程序是用汇编语言编写的, 汇编语言经过汇编后即可生成编译程序(可执行), 再利用这个编译程序将自己的源代码变为目标代码. 用高级语言编写, 普遍采用的方法. 例如用C语言写成的编译程序, 则先用C语言的编译器将C源程序编译为exe, 再用于分析其他语言, 也可以是C语言. 自编译 先编写一个很小的编译程序的核心, 再由这个核心逐渐去分析, 编译其他代码. 编译工具: LEX(词法分析), YACC(语法分析) 移植: 同种语言的编译程序在不同类型的机器之间移植 编译基础 高级语言是一个记号系统. 语法 语义 语法 包括 词法规则 和 语法规则 词法规则: 判断每一个\"单词\"是否正确, 规定了哪些符号是是单词符号(最基本结构; 常数, 标识符, 基本字, 算符, 界限符等); 用正规式和有限自动机描述和分析 语法规则: 结合单词是否是语言中的语法单位(表达式), 规定如何用单词形成语法单位, 包括表达式, 子句, 语句, 函数, 过程, 程序等. 语义 给出单词符号和语法符号的意义, 大多数编译程序使用基于属性文法的语法制导翻译方法来分析语义. 重点是正规文法, 上下文无关文法及其对应的有限自动机和下推自动机. 一些概念 字母表: 符号的非空有穷集合, 用\\(V, \\Sigma\\)表示. 所使用的符号均出自字符表. 符号: 语言中最基本的不可再分的单位. 符号串: 字符表中符号组成的有穷序列. 空串 用\\(\\epsilon\\)表示. 句子: 字母表上符合某种规则构成的串 语言: 字母表上句子的集合 *小写字母表示符号, 大写字母表示集合, 希腊字母表示符号串. 运算 连接(乘积)运算 \\[ \\begin{aligned} A &amp;= \\{\\alpha_1, \\alpha_2, \\cdots\\} \\\\ B &amp;= \\{\\beta_1, \\beta_2, \\cdots\\} \\\\ def:\\quad AB &amp;= \\{\\alpha \\beta | \\alpha\\in A\\ and\\ \\beta\\in B\\} \\end{aligned} \\] 其中\\(A,B\\)是串集. 规定: \\(A^0=\\{\\epsilon\\}\\). 注意该运算 非可交换. 例子: \\(\\alpha\\)表示if (), \\(\\beta\\)表示then(). 闭包 \\[ A^\\star=A^0\\cup A^1 \\cup A^2 \\cup \\cdots \\] 由A上所有符号组成的所有串的集合. 正闭包 \\[ A^{+} = A^1 \\cup A^2 \\cup A^3 \\cup \\cdots = A^\\star - {\\epsilon} \\] 文法 描述语言的语法结构规则 非终结符: 出现在规则的左部, 用\"&lt;&gt;\"括起来或用大写字母表示, 表示一定语法概念的词, 用\\(V_N\\)表示 终结符: 语言中不可以再分割的字符串, 用\\(V_T\\)表示 开始符号: 表示所定义的语法范畴的非终结符, 表示该文法中最大的一个语法成分 (?比如说一个句子) 产生式: 是用来定义符号串之间关系的一组语法规则, \\(A\\rightarrow \\alpha\\) 推导: 推导是从开始符号开始, 通过产生式的右部取代左部, 最终产生语言的一个句子的过程. 最左推导: 每次使用一个规则, 以其右部取代符号串最左的非终结符. 归约: 推导的逆过程, 从给定的源语言的一个句子开始, 通过规则的左部取代右部, 最终达到开始符号的过程. 最左归约: 最常采用 句型: 从文法的开始符号\\(S\\)开始, 每步推导(包括0步推导)所得到的字符串\\(\\alpha\\). 记作\\(S\\rightarrow^\\star \\alpha, where\\ \\alpha\\in (V_N \\cup V_T)^\\star\\) 句子: 仅含终结符的句型, 若能归约为开始符号, 则该句子是正确的 语言: 语言是由开始符号\\(S\\)通过1步或1步以上推导所得的句子的集合, 记为\\(L(G)=\\{\\alpha|S\\rightarrow^+\\alpha,\\alpha\\in V_T^*\\}\\) 文法规则的递归定义: 非终结符的定义中包含了非终结符自身 文法与语言的形式定义 Chomsky对文法的定义: 文法G是一个四元组\\((V_N, V_T, P, S)\\), 其中\\(P\\)是文法规则的集合, \\(S\\)是开始符号 0型文法 又称短语文法或者无限制文法. \\(P\\)中产生式\\(\\alpha\\rightarrow\\beta,\\alpha\\in V^+=(V_N\\cup V_T)^+\\), \\(\\alpha\\)至少含有一个非终结符,\\(\\beta\\in V^\\star\\). 对产生式限制最少 图灵机 可递归可枚举 1型文法 \\(P\\)中产生式\\(\\alpha\\rightarrow\\beta\\), 除可能有\\(S\\rightarrow \\epsilon\\)外均有\\(|\\beta|\\geq|\\alpha|\\), 若有\\(S\\rightarrow\\epsilon\\), 规定\\(S\\)不能出现在产生式的右部. 等价定义: \\(P\\)中产生式\\(\\alpha\\rightarrow\\beta\\)除了可能有\\(S\\rightarrow\\epsilon\\)外均有\\(\\alpha S \\beta \\rightarrow \\alpha \\gamma \\beta, \\alpha, \\beta \\in V^\\star, A\\in V^n, \\gamma\\in V^+\\). 对非终结符进行替换时, 必须考虑上下文, 并且一般不允许替换为\\(\\epsilon\\), 除非是开始符号产生\\(\\epsilon\\). 2型文法 \\(P\\)中产生式具有形式\\(A\\rightarrow\\beta, A\\in V_N, \\beta\\in V^\\star\\). 要求产生式左边只有一个非终结符. 不必考虑上下文, 上下文无关文法. 识别2型文法的自动机称为下推自动机 3型文法 \\(P\\)中产生式具有形式\\(A\\rightarrow \\alpha B, A\\rightarrow \\alpha\\)或者\\(A \\rightarrow B\\alpha, A\\rightarrow \\alpha, A,B\\in V_N, \\alpha\\in V_T^\\star\\). 也称为正规文法, (左|右)线性文法, 识别3型文法的自动机称为有限自动机. 词法分析和语法分析中对产生式的限制: 1)不产生\\(P\\rightarrow P\\), 2)产生式中出现的任何非终结符必须有用, 能经过若干步推导出终结符 一些例子 例1 语言\\(L=\\{\\omega|\\omega\\in(a,b)^\\star\\)且\\(\\omega\\)中含有个数相同的\\(a,b\\}\\), 构造生成该语言的文法: \\[ \\begin{align*} S&amp;\\rightarrow\\epsilon \\\\ S&amp;\\rightarrow aA\\\\ S&amp;\\rightarrow bB\\\\ A&amp;\\rightarrow aAA | bS\\\\ B&amp;\\rightarrow aS | bBB \\end{align*} \\] 解释: 要么以\\(a\\)开头, 要么以\\(b\\)开头, 后面跟着符号串. 对于符号串\\(A\\), 如果以\\(b\\)开头, 则后面跟着\\(ab\\)个数相等的符号串, 如果仍然以\\(a\\)开头, 此时后面必须还要至少出现两次\\(b\\). 或者 \\[ \\begin{align*} S&amp;\\rightarrow\\epsilon\\\\ S&amp;\\rightarrow aSbS\\\\ S&amp;\\rightarrow bSaS \\end{align*} \\] 解释: 若以\\(a\\)开头, 则在字符串的某个位置必然出现一个\\(b\\), 而这两个\\(a,b\\)中间是\\(ab\\)个数相等的的字符串, b后面也是\\(ab\\)个数相等的符号串. 例2 设\\(L=\\{\\omega | \\omega\\in(0,1)^\\star\\)且\\(1\\)的个数为偶数个\\(\\}\\), 构造生成该语言的文法: 可以先列出看一下: \\[ \\omega\\in\\{\\epsilon, 0, 11, 011, 101, 110,\\cdots\\} \\] 然后: \\[ \\begin{align*} S&amp;\\rightarrow\\epsilon\\\\ S&amp;\\rightarrow 0S\\\\ S&amp;\\rightarrow 1A\\\\ A&amp;\\rightarrow 1S | 0A \\end{align*} \\] 文法的构造与简化 简化 同一语言可以产生不同的文法, 选择产生式最少, 最符合语言特征的文法来描述; 有些产生式对推导不起作用, 包括: 推导中永远用不到, 永远导不出终结符的, 形如\\(P\\rightarrow P\\)的... 一些例子 例1 简化文法: \\[ \\begin{align*} S&amp;\\rightarrow Be\\\\ S&amp;\\rightarrow Ee\\\\ A&amp;\\rightarrow Ae\\\\ A&amp;\\rightarrow e\\\\ A&amp;\\rightarrow A\\\\ B&amp;\\rightarrow Ce\\\\ B&amp;\\rightarrow Af\\\\ C&amp;\\rightarrow Cf\\\\ D&amp;\\rightarrow f \\end{align*} \\] 显然应该保留0236. 构造 构造无\\(\\epsilon\\)产生式的上下文无关文法 满足: \\(P\\)中要么不含有\\(\\epsilon\\)产生式, 要么只有\\(S\\rightarrow\\epsilon\\), 且若\\(S\\rightarrow\\epsilon\\), 则\\(S\\)不出现在任何产生式右部. 语义分析与中间代码生成 在语法分析的过程中边分析边翻译, 翻译的结果是生成中间代码 语法制导翻译 在语法分析中调用语义翻译程序生成相应的中间代码, 使用CFG来引导对语言的翻译, 面向文法 根据产生式右部符号进行翻译 依据语义子程序 语义子程序: 用于改变变量的值, 查填符号表, 发现源程序错误, 产生中间代码 \\[ X \\rightarrow \\alpha \\{语义子程序\\} \\] 具体做法: 为每一个产生式配置一个语义子程序, 当语法分析进行归约或推导时调用相应的语义子程序 注意: 产生式中同一个符号出现多次, 需要区分, 加上角标 \\[ E \\rightarrow E_1 + E_2 \\] 语义值: 需要为每个文法符号赋予不同的语义值, 如类型, (符号表) 地址, 代码值 (不是数字), 并且 只有非终结符才有语义值 语义栈: 各个符号的语义值放在语义栈中. 产生式进行归约时, 需对右部符号的语义值进行综合, 结果作为左部符号的语义值保存在语义栈中. 语义栈, 符号栈, 状态栈同步变化 中间代码 转化为目标代码的中间生成的代码, 容易翻译 形式 四元式: \\(Operator, Op_1, Op_2, Result\\), 两个操作数和结果可以是用户自定义, 也可以是编译时变量. 变量采用的是符号表入口地址. 三元式: \\(Operator, Op_1, Op_2\\), 三元式本身就是结果, 以三元式的编号区别 逆波兰式 (后缀表示): \\(Op_1, Op_2, Operator\\), 无括号, 从左到右扫描一遍 树形表示 赋值语句 (简单变量无数组) 的翻译 文法: $$ A i = E \\ E E + E | E * E | -E | (E) | i $$ 内置函数: 123NEWTEMP # 产生临时变量ENRTY(i) # 获取变量i的符号表地址GEN(operator, op1, op2, result) # 生成四元式中间代码 语义变量: \\[ E.PLACE \\] 值是某个变量的符号表地址或临时变量的序号 分析过程需要就建立, 不需要就消亡 建立语法制导定义 (SDD): 产生式 语义规则 (子程序) \\(A \\rightarrow i = E\\) {\\(GEN(=, E.PLACE, NULL, ENTRY(i))\\)} \\(E \\rightarrow -E_1\\) {\\(T = NEWTEMP; GEN(@, E_1.PLACE, NULL, T); E.PLACE = T;\\)} \\(E \\rightarrow E_1 * E_2\\) {\\(T = NEWTEMP; GEN(*, E_1.PLACE, E_2.PLACE, T); E.PLACE = T;\\)} \\(E \\rightarrow E_1 + E_2\\) {\\(T = NEWTEMP; GEN(+, E_1.PLACE, E_2.PLACE, T); E.PLACE = T;\\)} \\(E \\rightarrow (E_1)\\) {\\(E.PLACE = E_1.PLACE\\)} \\(E \\rightarrow i\\) {\\(E.PLACE = ENTRY(i)\\)} 类型转换 处理混合运算, 如整型与实型运算, 最后的结果为实型 语义变量: \\[ E.MODE \\] 建立语法制导定义 (SDD): 产生式 语义规则 \\(E \\rightarrow E_1\\ op\\ E_2\\) {\\(IF\\ E_1.MODE = int\\ AND\\ E_2.MODE = int\\ THEN\\ E.MODE = int\\ ELSE\\ E.MODE = real\\)} 例如 \\(X = Y + I * J\\), 其中\\(X, Y\\)是实型的, \\(I, J\\)是整型的, 四元式为: \\[ (*_i, I, J, T_1) \\\\ (itr, T_1, NULL, T_2) \\\\ (+_r, Y, T_2, T_3) \\\\ (=, T_3, NULL, X) \\] 对运算符也要指出相应的类型. 布尔表达式的翻译","categories":[{"name":"CS","slug":"CS","permalink":"https://andrew-rey.github.io/categories/CS/"}],"tags":[]},{"title":"AndroidBasic","slug":"Android/AndroidBasic","date":"2022-09-01T07:59:05.000Z","updated":"2022-11-23T11:12:45.947Z","comments":true,"path":"2022/09/01/Android/AndroidBasic/","link":"","permalink":"https://andrew-rey.github.io/2022/09/01/Android/AndroidBasic/","excerpt":"\"我只是想学kotlin而已\" \"我不理解\"","text":"\"我只是想学kotlin而已\" \"我不理解\" Android Studio 一开始用的是Intelij IDEA, 后来觉得Android Studio挺香的. 当然前提是有JDK, Studio的话, 下载很快, 然后安装路径自选, 但是 注意在提示没有安装SDK的时候, 选择CANCEL, 安装完成后直接启动它. 这时候会提示你没有安装SDK, 并且会告诉你安装哪些东西, 只要选择安装路径即可, 等待片刻. 在create device里面, 可以新建device, 然后我新建了一个和我手机屏幕一样大的安卓虚拟机, 内存之类的看情况选, 没什么感觉. 组件 Activity 用于显示用户界面, 用户通过Activity交互完成相关操作, 一个APP可以有多个Activity 布局 Linear Layout 比较常用的属性: 123456789android:idandroid:layout_widthandroid:layout_heightandroid:backgroundandroid:layout_marginandroid:layout_paddingandroid:layout_orientationandroid:gravity &lt;!--相对位置--&gt;android:layout_weight &lt;!--将剩余内容平分--&gt; Relative Layout 比较常用的属性: 12345android:layout_toLeftOfandroidLlayout_toRightOfandroid:alignBottomandroid:alignParentBottomandroid:layout_below 控件 Text View 可以实现 文字大小, 颜色; 显示不下时使用...; 文字加icon; 中划线, 下划线; 跑马灯 kotlin实现中划线要重写扩展方法apply() 123my_text_view.apply &#123; paintFlags = paintFlags or Paint.STRIKE_THRU_TEXT_FLAGS or Paint.ANTI_ALIAS_FLAG&#125; Material Button 谷歌给的Button控件, 继承了之前的Button 需要在app/build.gradle中添加依赖: 1implementation group: &#x27;com.google.android.material&#x27;, name: &#x27;material&#x27;, version: &#x27;1.4.0&#x27; 还需要更换谷歌它指定的样式主题, 在values/theme.xml中将主题改为 1Theme.MaterialComponents.Light.NoActionBar 同步后便可以使用谷歌的MaterialButton, 不过为了修改属性, 用到了app和tool, 因此在相应的activity文件头添加: 12xmlns:app=&quot;http://schemas.android.com/apk/res-auto&quot;xmlns:tools=&quot;http://schemas.android.com/tools&quot; 以示礼貌 重点 按钮又不是摆设, 所以要设计相应的页面跳转, 也就是需要实现相应的clickListener 12345678910class ... private lateinit var mBtn: MaterialButton override fun onCreate ... mBtn = findViewById(R.id.button_name) mBtn.setOnClickListener() &#123; startActivity(Intent(this, OtherActivity::class.java)) &#125; 接着是颜值比较高的选择栏设计:","categories":[{"name":"Android","slug":"Android","permalink":"https://andrew-rey.github.io/categories/Android/"}],"tags":[]},{"title":"Image Semantic Segmentation based on UNet","slug":"ML/UNet","date":"2022-08-21T02:50:30.000Z","updated":"2022-11-23T11:12:45.977Z","comments":true,"path":"2022/08/21/ML/UNet/","link":"","permalink":"https://andrew-rey.github.io/2022/08/21/ML/UNet/","excerpt":"\"Semantic segmentation of images, use UNet model.\"","text":"\"Semantic segmentation of images, use UNet model.\" Abstract In this project, we realize an basic UNet model and UNet++ model, then we apply them on image semantic segmentation. We show our basic theory of UNet and an improvement of it, and we provide main code of this program. Finally, we give the result of segmentation images, loss-curve and accuracy-curve on both training and validation set. The copyright of this program is owned by our team mentioned on the end of this blog. UNet Structure The paper published in 2015 propose a noval network structure, whose shape is similar with the captal \"U\". The idea comes from FCNN. U-Net is one of the classes of \"Encoder-Decoder\" structure. U-Net Structure The front half of the network is \"encoder\". The input image passes covolutional kernel, and then passes the pooling layer (or other dimension-decreasing layer). The opposite of that is the back part of UNet, the \"decoder\". The input of decoder is a sequence of feature maps with highly contracted pixels. The output of the decoder (or the whole network) is an image with the same shape of input image, where each pixel has its own class. In this project, we decrease the number of convolutional layers so that there are only two convolutional layers in each convolutional kernel as the dataset includes images with shape \\(128\\times 256\\). Operator Definitions Convolutional Kernel: We define the basic convolutional kernel as follow: 123456789101112self.layer = nn.Sequential( # in_channel, out_channel, kernel_size, stride, padding # batch size * channel * height * weight nn.Conv2d(C_in, C_out, kernel_size=(3, 3), stride=(1, 1), padding=1), # 64 64 128 256 nn.BatchNorm2d(C_out), nn.Dropout(0.2), nn.LeakyReLU(), nn.Conv2d(C_out, C_out, kernel_size=(3, 3), stride=(1, 1), padding=1), # 64 64 128 256 nn.BatchNorm2d(C_out), nn.Dropout(0.5), nn.LeakyReLU(), It includes two convolution operations. Down Sampling Kernel: As for downsampling kernel, we replace conditional pooling layer to convolutional layer with stride equaling to 2, which means the shape will be shrunk to \\(\\frac{1}{2}\\) while remaining the same channels. 1234self.Down = nn.Sequential( nn.Conv2d(C, C, kernel_size=(3, 3), stride=(2, 2), padding=1), # 64 64 64 128 nn.LeakyReLU() ) Up Sampling Kernel: The basic structure of up-sampling contains only one convolutional layer with \\(1\\times 1\\) convolutional kernel size and half out-channel. The feature map should pass an interpolation layer before getting into the convolutional layer. 12345678910111213def __init__(self, C): super(UpSampling, self).__init__() # out-channel = 1/2 in-channel self.Up = nn.Conv2d(C, C // 2, kernel_size=(1, 1), stride=(1, 1)) def forward(self, x, r): # neighbor interpolation up = F.interpolate(x, scale_factor=2, mode=&quot;nearest&quot;) x = self.Up(up) # concatenate the feature map in encoder and # the feature map in corrsponding decoder layer, in channel dimension res = torch.cat((x, r), 1) return res The interpolation mode we choose is \"nearest\". The function torch.cat(dim=1) is used to concatenate two feature maps in channel dimension. Network Definition Based on the operators defined above, we link these blocks together like UNet structure. 123456789101112131415161718192021222324252627def __init__(self): super(UNet, self).__init__() # down sampling self.C1 = Conv(3, 64) self.D1 = DownSampling(64) self.C2 = Conv(64, 128) self.D2 = DownSampling(128) self.C3 = Conv(128, 256) self.D3 = DownSampling(256) self.C4 = Conv(256, 512) self.D4 = DownSampling(512) self.C5 = Conv(512, 1024) # up sampling self.U1 = UpSampling(1024) self.C6 = Conv(1024, 512) self.U2 = UpSampling(512) self.C7 = Conv(512, 256) self.U3 = UpSampling(256) self.C8 = Conv(256, 128) self.U4 = UpSampling(128) self.C9 = Conv(128, 64) self.C10 = torch.nn.Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=1) self.pred = torch.nn.Conv2d(3, 34, kernel_size=(1, 1), stride=(1, 1)) self.Th = torch.nn.Sigmoid() Like U-Net mentioned in that paper, we designed 4 layer deep network. 12345678910111213141516def forward(self, x): # part 1: down sampling, decreasing dimension R1 = self.C1(x) R2 = self.C2(self.D1(R1)) R3 = self.C3(self.D2(R2)) R4 = self.C4(self.D3(R3)) Y1 = self.C5(self.D4(R4)) # part 2: up sampling, connect priori knowledge O1 = self.C6(self.U1(Y1, R4)) O2 = self.C7(self.U2(O1, R3)) O3 = self.C8(self.U3(O2, R2)) O4 = self.C9(self.U4(O3, R1)) # part 3: active function return self.Th(self.pred(self.C10(O4))) As you can see, the difference between U-Net and other networks before U-Net is that U-Net conbines the former information from encoder and current information from decoder. Code During the training process, we want to keep some information of loss values and accuracy values on training set and validation set so that we can analyze the variance. In the function named train(), we take optimizer and loss as two parameters used in training process. The outputs of this function are loss and accuracy on both training set and validation set. If we get the data about training set and validation set, we can draw the curves. If both training and validation loss values decrease during training process, we can conclude that our model converges and does not overfit on training set. The training code is shown as follow: 1234567891011self.model.train()for batch in self.train_loader: batch_num += 1 optimizer.zero_grad() rgbs, segs = batch s, _, m, n = segs.shape segs = torch.reshape(segs, (s, m, n)) pred_segs = self.model(rgbs).to(self.device) loss_val = loss(pred_segs, segs) loss_val.backward() optimizer.step() The data collecting code can be written as follow: Statistic data of training set 1234567891011121314for ... : with torch.no_grad(): if batch_num % 5 == 0: logging.info(f&quot;batch num &#123;batch_num&#125;, loss &#123;loss_val&#125;&quot;) # delete or add comments when needed train_loss += loss_val # statistic valid classified samples total_pix += s * m * n idx = torch.argmax(pred_segs, dim=1) train_valid_pix += torch.eq(idx, segs).sum().float().item()torch.cuda.empty_cache()epoch_acc = train_valid_pix / total_pixtrain_epoch_loss.append(train_loss / batch_num)train_epoch_acc.append(epoch_acc) Statistic data of validation set 12345678910111213141516self.model.eval()with torch.no_grad(): for valid_batch in self.valid_loader: valid_batch_num += 1 rgbs, segs = valid_batch s, _, m, n = segs.shape segs = torch.reshape(segs, (s, m, n)) pred_segs = self.model(rgbs).to(self.device) loss_val = loss(pred_segs, segs) valid_loss += loss_val valid_total_pix += s * m * n idx = torch.argmax(pred_segs, dim=1) valid_valid_pix += torch.eq(idx, segs).sum().float().item()epoch_acc = valid_valid_pix / valid_total_pixvalid_epoch_loss.append(valid_loss / valid_batch_num)valid_epoch_acc.append(epoch_acc) The point you should pay attention to is that you should use with torch.no_grad() before you do some work that have no relation with training process, otherwise your GPU memory will be full or even overflow. Result After a long time training, we get the satisfying result with U-Net model. Former Model The \"former model\" infers the U-Net model, and you will see we use other upgraded model named \"UNet++\" which will be introduced later. We output the segmentation results and their uncertainties. picture 1 result-UNet Model Upgrade For some reasons, we try another U-Net-like model, Nested UNet, namely UNet++. It has a nested convolutional blocks like a pyramid and there is a chain passing connectivity between each convolutional block every layer. Neseted UNet The black nodes are the same with U-Net model. The green nodes are what Nested UNet newly added. Both green and blue lines are skip pathways that pass connectivities from encoder to decoder. The use of Nested UNet gives us a little improvement on final results. pictrue 1 result-Nested UNet Analysis U-Net We analyze the loss value and accuracy on both training and validation set: unet loss We find that after 100 epochs, the model has not convergenced yet, but the loss on validation decreases to the bottom. unet accuracy From the accuracy curves, we find that both training set and validation set have increasing accuracy, which means our model does not overfit. Nested UNet Meanwhile, we analyze the loss and accuracy of Nested UNet model on both training and validation set. nested loss We find that Nested UNet has a faster convergency speed than UNet. It uses only about 60 epochs. But to our surprise, we find that Neseted UNet overfit after about only 20 epochs because the validation loss does not decrease anymore. nested accuracy The performance on validation accuracy stays the same with UNet model.","categories":[{"name":"ML","slug":"ML","permalink":"https://andrew-rey.github.io/categories/ML/"}],"tags":[]},{"title":"CMakeTutorial","slug":"CS/CMakeTutorial","date":"2022-08-10T04:56:16.000Z","updated":"2022-12-26T02:55:01.943Z","comments":true,"path":"2022/08/10/CS/CMakeTutorial/","link":"","permalink":"https://andrew-rey.github.io/2022/08/10/CS/CMakeTutorial/","excerpt":"CMake version: 3.x","text":"CMake version: 3.x Command Line 123456789101112131415161718# (configure step) create build dir, and generate build/Makefile -&gt; generate Makefilecmake -B build# (build step) invoke building system and build the project in different OS -&gt; generate executable filecmake --build build -j4# invoke building system to execute target &quot;install&quot;cmake --build build --target install# define configure variables, only use in configure step# use -D# set build type in configure step, the value will remain when invoked the second time unless delete build dircmake -B build -DCMAKE_BUILD_TYPE=Release# Specify generator (generator: generate build system build rule from CMakeLists.txt)# use -G# generator Ninja, faster than Unix Makefile, generate *.ninjacmake -B build -G Ninja CMakeLists.txt add source file (1). single file: main.cpp 1add_executable(main main.cpp) or 12add_executable(main)target_sources(main PUBLIC main.cpp) (2). multiple files: main.cpp | other.cpp | other.h 12add_executable(main)target_sources(main PUBLIC main.cpp other.cpp) or set a new variable 123add_executable(main)set(sources main.cpp other.cpp other.h) # other.h can deletetarget_sources(main PUBLIC $&#123;sources&#125;) or use GLOB to search all files in current dir 123add_executable(main)file(GLOB sources CONFIGURE_DEPENDS *.cpp *.h) # add CONFIGURE_DEPENDS to detect any change when next buildtarget_sources(main PUBLIC $&#123;sources&#125;) when we have a dir structure: 12345mylib +----*.cpp +----*.h*.cpp*.h no need to write all files: 12345# add all file in current dir and mylib diradd_executable(main)aux_source_directory(. sources)aux_source_directory(mylib sources)target_sources(main PUBLIC $&#123;sources&#125;) or use GLOB_RECURSE to find all files recursely: 123add_executable(main)file(GLOB_RECURSE sources CONFIGURE_DEPENDS *.cpp *.h)target_sources(main PUBLIC $&#123;sources&#125;) ERROR: use GLOB_RECURSE will include *.cpp files in build dir. solution: Add all source files in a dir named src Configure variables CMAKE_BUILD_TYPE: type of build, Release, Debug, MinSizeRel and RelWithDebInfo, defualt: none (debug). 1set(CMAKE_BUILD_TYPE Release) set default build type as Release to reach high performance: in the first three lines: 123if (NOT CMAKE_BUILD_TYPE) set(CMAKE_BUILD_TYPE Release)endif() 123456789101112131415# Specify version of cmakecmake_minimum_required(VERSION 3.22)# set c++ standard# don&#x27;t modify CMAKE_CXX_FLAGS to add -std=c++17set(CMAKE_CXX_STANDARD 17)# if use the needed CXX standard defined.set(CMAKE_CXX_STANDARD_REQUIRED ON) # OFF default# prevent features GCC onlyset(CMAKE_CXX_EXTENSIONS OFF)# set project infoproject(project_name LANGUAGES language_list(such as C CXX ASM...)) Linkable library 1add_executable(main mian.cpp mylib.cpp) or generate a static library 12345add_library(mylib STATIC mylib.cpp) # create libmylib.aadd_executable(main main.cpp)target_link_libraries(main PUBLIC mylib) or generate dynamic lib 12345add_library(mylib SHARED mylib.cpp)add_executable(main main.cpp)target_link_libraries(main PUBLIC mylib) or use object lib, no *.a file, let CMake remember which objects files are created 12345add_library(mylib OBJECT mylib.cpp)add_executable(main main.cpp)target_link_libraries(main PUBLIC mylib) 静态库问题: GCC会自行剔除没有引用符号的对象, 此时使用对象库避免, 从而不会自动剔除没引用到的对象文件, 绕开编译器不统一问题. 动态库也可以避免剔除没引用的对象文件, 但引入了运行时链接的麻烦. 1234# no specify variable in add_library()set(BUILD_SHARED_LIBS ON) # default OFFadd_library(mylib mylib.cpp) HINT 静态库常常被认为直接链接到可执行文件上. 因此在动态库中不要链接静态库. 很呆. 地址会变. 当然解决方法是: 要么转化为对象库, 要么让静态库变成地址无关的代码PIC 12345678910# set global propertyset(CMAKE_POSITION_INDEPENDENT_CODE ON)add_library(otherlib STATIC otherlib.cpp)add_library(mylib SHARED mylib.cpp)target_link_libraries(mylib PUBLIC otherlib)add_executable(main main.cpp)target_link_libraries(main PUBLIC mylib) or set local property 123456789# set local propertyadd_library(otherlib STATIC otherlib.cpp)set_property(TARGET otherlib PROPERTY POSITION_INDEPENDENT_CODE ON)add_library(mylib SHARED mylib.cpp)target_link_libraries(mylib PUBLIC otherlib)add_execuable(main main.cpp)target_link_libraries(main PUBLIC mylib) Attributes of objects 设置单属性: set_property(TARGET ... PROPERTY ...); 设置多属性: set_target_properties(file_name PROPERTIES properties_list) HINT: 以上命令在add_executable后有效. 设置全局属性 (改变属性的默认值): set(CMAKE_XXX), 在add_executable前设置. 如果需要在Windows下面使用动态库 (Windows对动态链接不友好), 则需要在定义和声明添加: Deffinition: 123456#include &lt;cstdio&gt;#ifdef _MSC_VER__declspec(dllexport)#endifvoid sayy_hello()&#123;&#125; Declaration: 123456#pragma once#ifdef _MSC_VER__declspec(dllimport)#endifvoid say_hello(); 然后CMakeLists.txt这样写: 12345678# In Main dircmake_minimum_required(VERSION 3.22)add_subdirectory(mylib) # add sub moduleadd_executable(main main.cpp)target_link_libraries(main PUBLIC mylib)# In sub module diradd_library(mylib SHARED mylib.cpp mylib.h) 然后Windows极有可能会报错: 运行时找不到dll; 原因是dll和exe不在同一目录 (Windows只会查找exe所在目录和PATH). - 把dll添加到PATH环境变量 - 或者dll和dll其他的所有依赖dll, 全部拷贝到exe同一目录 这是因为CMake把main放在build下, 而mylib放在build/mylib/mylib.dll 因此重定向输出路径, 改变mylib属性, 让.dll文件输出到 PROJECT_BINARY_DIR 里面. 1set_property(TARGET mylib PROPERTY RUNTIME_OUTPUT_DIRECTORY_(DEBUG | RELEASE | NONE) | ARCHIVE_OUTPUT_DIRECTORY | LIBRARY_OUTPUT_DIRECTORY $&#123;PROJECT_BINARY_DIR&#125;) Externel library In Linux: feel free to link externel libraries. (/usr/lib/...) But Windows can't. Linux can also include head file directly (/usr/include/...). HINT: CMake 的分隔符永远是 \"/\", 即使是Windows, CMake会自动转化. More general method: 1find_package(package_name REQUIRED) 没听懂, 以后补, 以后也不想补. Variables and Outputs output some log infomation when running cmake -B build, used for debugging. 1message(&quot;log info&quot;) 1message(STATUS &quot;status info&quot;) # -- prefix 1message(WARNING &quot;warning info&quot;) # yellow 123message(SEND_ERROR &quot;error info&quot;) # send error log but continue to runmessage(FATAL_ERROR &quot;error info&quot;) # print error and stop running Variable and Cache 重复执行cmake -B build: 第一次较慢, 将环境的检测存入缓存, 第二次以及以后直接查看缓存内容. 因此某些错误可以通过删除 ./build/CMakeCache.txt解决. 当然也可以删了整个build文件夹重新编译, 慢一点而已.","categories":[{"name":"CS","slug":"CS","permalink":"https://andrew-rey.github.io/categories/CS/"}],"tags":[]},{"title":"GAMES101","slug":"CS/GAMES101","date":"2022-07-09T02:35:39.000Z","updated":"2022-11-23T11:12:45.948Z","comments":true,"path":"2022/07/09/CS/GAMES101/","link":"","permalink":"https://andrew-rey.github.io/2022/07/09/CS/GAMES101/","excerpt":"\"From GAMES101\"","text":"\"From GAMES101\" Transformation Basic Scale \\[ \\left [ \\begin{aligned} x^{\\prime} \\\\ y^{\\prime} \\end{aligned} \\right ] = \\left [ \\begin{aligned} &amp;s_x\\ \\ &amp;0 \\\\ &amp;0\\ \\ &amp;s_y \\end{aligned} \\right ] \\left [ \\begin{aligned} x \\\\ y \\end{aligned} \\right ] \\] Rotation Rotation: \\[ R_{\\theta} = \\left [ \\begin{aligned} x^{\\prime} \\\\ y^{\\prime} \\end{aligned} \\right ] = \\left [ \\begin{matrix} &amp;cos\\theta\\ \\ &amp;-sin\\theta \\\\ &amp;sin\\theta\\ \\ &amp;cos\\theta \\end{matrix} \\right ] \\left [ \\begin{aligned} x \\\\ y \\end{aligned} \\right ] \\] inverse rotation: \\[ R_{-\\theta} = \\left [ \\begin{aligned} x^{\\prime} \\\\ y^{\\prime} \\end{aligned} \\right ] = \\left [ \\begin{matrix} &amp;cos\\theta\\ \\ &amp;sin\\theta \\\\ &amp;-sin\\theta\\ \\ &amp;cos\\theta \\end{matrix} \\right ] \\left [ \\begin{aligned} x \\\\ y \\end{aligned} \\right ] = R_{\\theta}^{-1} = R^T \\] 3-D: Eular angle: rotation around axises. The rotation is similar to 2-D, but inverse for axis y. For a general rotation around an axis vector \\(n\\), Rodrigues' Rotation Formula: \\[ R(n, \\alpha) = cos\\alpha I + (1 - cos\\alpha)n n^T + sin\\alpha \\left [ \\begin{matrix} &amp;0 &amp;-n_z &amp;n_y \\\\ &amp;n_z &amp;0 &amp;-n_x \\\\ &amp;-n_y &amp;n_x &amp;0 \\end{matrix} \\right ] \\] 其中 \\[ \\left [ \\begin{matrix} &amp;0\\ \\ &amp;-n_z\\ \\ &amp;n_y \\\\ &amp;n_z\\ \\ &amp;0\\ \\ &amp;-n_x \\\\ &amp;-n_y\\ \\ &amp;n_x\\ \\ &amp;0 \\end{matrix} \\right ] \\] 是叉积算子, 物理含义为角速度 For an arbitrary axis, do a translation (following). Homogeneous coordinates \\[ x_1 = x + t_x \\\\ y_1 = y + t_y \\] solution: point: \\((x, y, 1)^T\\) vector: \\((x, y, 0)^T\\) \\[ \\left [ \\begin{aligned} x^{\\prime} \\\\ y^{\\prime} \\\\ w \\end{aligned} \\right ] = \\left [ \\begin{aligned} &amp;1\\ &amp;0\\ &amp;t_x \\\\ &amp;0\\ &amp;1\\ &amp;t_y \\\\ &amp;0\\ &amp;0\\ &amp;1 \\end{aligned} \\right ] \\left [ \\begin{aligned} x \\\\ y \\\\ 1 \\end{aligned} \\right ] = \\left [ \\begin{aligned} x + t_x \\\\ y + t_y \\\\ 1 \\end{aligned} \\right ] \\] for a general form: \\[ \\left [ \\begin{aligned} x \\\\ y \\\\ w \\end{aligned} \\right ] \\] is the same with (\\(w\\neq 0\\)) \\[ \\left [ \\begin{aligned} x / w \\\\ y / w \\\\ 1 \\end{aligned} \\right ] \\] Affine \\[ \\left [ \\begin{aligned} x^{\\prime} \\\\ y^{\\prime} \\end{aligned} \\right ] = \\left [ \\begin{matrix} &amp;a\\ \\ &amp;b \\\\ &amp;c\\ \\ &amp;d \\end{matrix} \\right ] \\left [ \\begin{aligned} x \\\\ y \\end{aligned} \\right ] + \\left [ \\begin{aligned} t_x \\\\ t_y \\end{aligned} \\right ] \\] is the same with \\[ \\left [ \\begin{aligned} x^{\\prime} \\\\ y^{\\prime} \\\\ w \\end{aligned} \\right ] = \\left [ \\begin{matrix} &amp;a\\ &amp;b\\ &amp;t_x \\\\ &amp;c\\ &amp;d\\ &amp;t_y \\\\ &amp;0\\ &amp;0\\ &amp;1 \\end{matrix} \\right ] \\left [ \\begin{aligned} x \\\\ y \\\\ 1 \\end{aligned} \\right ] \\] Viewing MVP transformation (Model, View, Projection) view Define the camera: position \\(e\\) gaze direction (look-at): \\(g\\) up direction: \\(t\\) Method: Fix the camera: origin, look-at axis -z, look-up axis y (将相机移动到一个规定位置上) view 对应的变换, 先做平移, 再做旋转: \\[ M_{view} = R_{view}T_{view} \\] 其中平移: \\[ T_{view} = \\left [ \\begin{matrix} &amp;1\\ &amp;0\\ &amp;0\\ &amp;x_e \\\\ &amp;0\\ &amp;1\\ &amp;0\\ &amp;y_e \\\\ &amp;0\\ &amp;0\\ &amp;1\\ &amp;z_e \\\\ &amp;0\\ &amp;0\\ &amp;0\\ &amp;1 \\end{matrix} \\right ]; \\] 旋转: \\[ R_{view}^{-1} = \\left [ \\begin{matrix} &amp;x_{g\\times t}\\ &amp;x_t\\ &amp;x_{-g}\\ &amp;0 \\\\ &amp;y_{g\\times t}\\ &amp;y_t\\ &amp;y_{-g}\\ &amp;0 \\\\ &amp;z_{g\\times t}\\ &amp;z_t\\ &amp;z_{-g}\\ &amp;0 \\\\ &amp;0\\ &amp;0\\ &amp;0\\ &amp;1 \\end{matrix} \\right ], R_{view} = \\left [ \\begin{matrix} &amp;x_{g\\times t}\\ &amp;y_{g\\times t}\\ &amp;z_{g\\times t}\\ &amp;0 \\\\ &amp;x_t\\ &amp;y_t\\ &amp;z_t\\ &amp;0 \\\\ &amp;x_{-g}\\ &amp;y_{-g}\\ &amp;z_{-g}\\ &amp;0 \\\\ &amp;0\\ &amp;0\\ &amp;0\\ &amp;1 \\end{matrix} \\right ] \\] 注意对所有物体变换. projection projection orthographic projection 将模型 \\([r, l]\\times[b, t]\\times[f, n]\\) 转化为 \\([-1, 1]\\times[-1, 1]\\times[-1, 1]\\) \\[ M_{ortho} = \\left [ \\begin{matrix} &amp;\\frac{2}{r-l}\\ &amp;0\\ &amp;0\\ &amp;0 \\\\ &amp;0\\ &amp;\\frac{2}{t-f}\\ &amp;0\\ &amp;0 \\\\ &amp;0\\ &amp;0\\ &amp;\\frac{2}{n-f}\\ &amp;0 \\\\ &amp;0\\ &amp;0\\ &amp;0\\ &amp;1 \\end{matrix} \\right ] \\left [ \\begin{matrix} &amp;1\\ &amp;0\\ &amp;0\\ &amp;-\\frac{r+l}{2} \\\\ &amp;0\\ &amp;1\\ &amp;0\\ &amp;-\\frac{b+t}{2} \\\\ &amp;0\\ &amp;0\\ &amp;1\\ &amp;-\\frac{n+f}{2} \\\\ &amp;0\\ &amp;0\\ &amp;0\\ &amp;1 \\end{matrix} \\right ] \\] perspective projection 分两步进行: 先将棱锥变换为长方体; 再将长方体做正交投影. 第一步: 保证远平面的中心不变, 远平面的 z 坐标不变, 近平面不变. 三角形相似: \\[ y^{\\prime}=\\frac{n}{z}y;\\ x^{\\prime}=\\frac{n}{z}x \\] 设棱锥内任意一点 \\(P=(x_0,y_0,z_0,1)^T\\), 经过挤压后变换为 \\(P^{\\prime}=(x_0^{\\prime},y_0^{\\prime},z_0^{\\prime},1)^T=(\\frac{n}{z_0}x_0,\\frac{n}{z_0}y_0,z_0^{\\prime},1)^T=(nx_0,ny_0,z_0z_0^{\\prime},z_0)^T\\). 接下来确定 \\(z_0^{\\prime}\\). 取近平面的中心点 \\(O_1=(0,0,n,1)\\) 和远平面的中心点 \\(O_2=(0,0,f,1)\\), 变换后位置不变. \\[ O_1\\Rightarrow O_1^{\\prime}=(0,0,n^2,n)^T;\\ O_2\\Rightarrow O_2^{\\prime}=(0,0,f^2,f) \\] 从而确定矩阵: \\[ M_{perp\\rightarrow ortho} \\left [ \\begin{matrix} &amp;n\\ &amp;0\\ &amp;0\\ &amp;0 \\\\ &amp;0\\ &amp;n\\ &amp;0\\ &amp;0 \\\\ &amp;0\\ &amp;0\\ &amp;n+f\\ &amp;-nf \\\\ &amp;0\\ &amp;0\\ &amp;1\\ &amp;0 \\end{matrix} \\right ] \\] 第二步: 将变换后的长方体做正交投影 \\(M_{ortho}\\) 因此透视投影为 \\[ M_{perp} = M_{ortho}M_{perp\\rightarrow ortho} \\] 可以代入一些特殊点发现一些现象: 例如将中轴的中点 \\(P=(0,0,\\frac{n+f}{2}, 1)\\) 经过上述变换得 \\(P^{\\prime}=(0,0,\\frac{n^2+f^2}{n+f}, 1)\\), 与此时的中轴中点 \\(Q^{\\prime}=(0,0,\\frac{n+f}{2},1)\\) 比较发现, \\(\\frac{n^2+f^2}{n+f} &gt; \\frac{n+f}{2}\\), 即原来的中点应该更加 靠近 相机. Resterization Triangles Some definition aspect ratio: width / height FOV, field of view: def screen (raster) an array of pixels size of the pixels: resolution (分辨率) a typical kind of raster display 将raster放置在坐标系中, 并以像素的 左下角 作为坐标, 其像素中心则需要再加上0.5. (虎书里以中心作为坐标) 假设显示区域为 \\(width\\times height\\), 则将 viewing 后的 \\([-1,1]^3\\) 变换为显示区域大小 \\(width\\times height\\), 即 视口变换 (view port): \\[ M_{viewport} \\left [ \\begin{matrix} &amp;\\frac{width}{2}\\ &amp;0\\ &amp;0\\ &amp;\\frac{width}{2} \\\\ &amp;0\\ &amp;\\frac{height}{2}\\ &amp;0\\ &amp;\\frac{height}{2} \\\\ &amp;0\\ &amp;0\\ &amp;1\\ &amp;0 \\\\ &amp;0\\ &amp;0\\ &amp;0\\ &amp;1 \\end{matrix} \\right ] \\] Triangles 将图像用三角形光栅 为什么是三角形? 最基本多边形, 任意多边形可以拆成三角形 保证三角形是一个平面 内部和外部可以定义 内部插值 Samlping 连续函数离散化 \\[ Sampling (x) = \\left\\{ \\begin{matrix} 1,\\quad x\\in triangle, \\\\ 0,\\quad x\\notin triangle \\end{matrix} \\right. \\] 其中 \\(x\\) 是像素中心 判断某个点是否在三角形内部: 设点 \\(P\\), 三角形 \\(\\triangle XYZ\\), 分别用 \\(\\vec{XY}, \\vec{YZ}, \\vec{ZX}\\) 与 \\(\\vec{XP}, \\vec{YP}, \\vec{ZP}\\) 做外积, 若外积的结果方向一致, 则说明 \\(P\\) 在三角形内部, 反之外部. Bounding Box: 最小的包围所考虑图形的长方体. 遍历时只遍历 Bounding Box 即可. 又称轴向包围盒 (AABB) 此外, 还可以找三角形内部的, 每一行的最小和最大坐标进行遍历. jaggies (锯齿) Antialiasing and Z-Buffering Aliasing: artifacts to sampling Jagging (锯齿), sampling in space Moire (摩尔纹), undersampling image Wagon Wheel effect, sampling in time Reason: 信号变化太快, 采样慢 Antialiasing Idea: Blurring (Pre-Filtering) before sampling (模糊处理) blur Aliasing 的来源: 相同采样频率采样不同函数, 得到的采样点相同. aliasing 大部分自然图像信号的信息集中在低频, 在变化剧烈处形成边界, 高频所代表的信息大部分是边界. 低通滤波器: 大面积色块 高通滤波器: 边界 带通滤波器: 不明所以的东西 注: 现实情况是非理想滤波. 另一个角度: 滤波 相当于 卷积 或 平均 Antialiasing 背景: 一般而言, 直接对原始图像进行三角形光栅化会出现明显的锯齿 减少锯齿的方法: 先对原始图像进行模糊处理, 再进行采样. 步骤: 1. 模糊: 用某个低通滤波器 (卷积核) 对原始图像进行卷积, 例如可以选择 \\(1\\times 1\\) 的低通滤波器, 卷积结果就是在每个像素的灰度平均值; 2. 采样: 将模糊后的图像的每一个像素对像素中心进行采样 antialiasing 新的问题: 如何计算光栅三角形在每一个像素里覆盖的区域 MSAA, Antialiasing by Supersampling: 将像素再进行划分, 划分为多个像素, 最后以子像素在父像素的百分比作为结果. 近似 模糊 这一步 代价是更大计算量 其他抗锯齿方法: FXAA (fast approximete AA) 先得到带锯齿的图像, 再进行图像比对找到边界, 并将锯齿去掉 TAA (temperal AA) 复用上一帧提供的信息 其他概念: super resolution / super sampling 将低分辨率的图像恢复为高分辨率, 依然解决的是样本不够的问题 DLSS (Deep Learning Super Sampling) Z-Buffering 深度缓存: 解决可见性和遮挡. Painter's Algorithm: 将场景物品的深度由远及近排序, 先画最远的物品, 再画较近物品. 其中排序所需要的时间为 \\(O(n log n)\\) 问题: 深度如何定义, 相互覆盖如何处理, 深度关系有时候难定义. 因此画家算法一般不用 Z-Buffering Algorithm: 在每个像素中记录当前的最小深度 frame buffer stores color value z-buffer stores depth (e.i. \\(|z|\\)) z-buffer 时间复杂度为 \\(O(n)\\), 但浮点数判断相等比较复杂 Summarize sum Shading Def: darkening or coloring of an illustration or diagram with parallel lines or a block of color. The process of applying a material to an object, considering the interaction with light. 目前只考虑shading, 不考虑Shadow Other terminologies: specular light 高光 diffuse reflection 漫反射 ambient light 间接光照: 简化为常量 Blin-Phong Reflection Model 简单漫反射模型: 设物体表面法向量 \\(\\vec{n}\\) 与光照的 反方向 \\(\\vec{l}\\) 夹角为 \\(\\theta\\) 且为单位向量, 则 \\[ cos \\theta = \\vec{l} \\cdot \\vec{n} \\] 物体表面接收的光强与 \\(cos \\theta\\) 成正比. 设光源为点光源, 传播过程不损失能量, 球面波传播. 则由能量守恒, 距离点光源 \\(r\\) 的球面上一点的强度为 \\(I/r^2\\), 其中 \\(I\\) 表示单位球壳上的能量. 因此物体的不同点的光照强度可以表示为 \\[ I_p = k_d\\frac{I}{r^2}max\\{0,\\vec{l} \\cdot \\vec{n}\\} \\] 其中取最大是考虑: 当光线逆向射过来后不考虑折射. 其中 \\(k_d\\) 表示整体的颜色影响, 当 \\(k_d=0\\) 时表示强度为 \\(0\\), 此时全黑. 此外, 若是RGB, \\(k_d\\) 分别取值. kd Geometry Ray Tracing Animation / Simulation","categories":[{"name":"CS","slug":"CS","permalink":"https://andrew-rey.github.io/categories/CS/"}],"tags":[]},{"title":"操作系统练习","slug":"CS/OSPractice","date":"2022-05-09T08:35:18.000Z","updated":"2022-11-23T11:12:45.974Z","comments":true,"path":"2022/05/09/CS/OSPractice/","link":"","permalink":"https://andrew-rey.github.io/2022/05/09/CS/OSPractice/","excerpt":"\"操作系统习题, 包括进程同步, CPU调度等内容.\" \"还在更新...也有可能不在更新...\"","text":"\"操作系统习题, 包括进程同步, CPU调度等内容.\" \"还在更新...也有可能不在更新...\" 进程同步与互斥 习题1 哲学家进餐问题: 问题描述见操作系统笔记. 解法1: 最多允许 4 个哲学家同时进餐, 以保证至少有一个哲学家可以正常用餐, 并且最终可以释放出其使用的筷子, 从而使给多的哲学家用餐. 123456789101112131415semaphore choopsticks[5] = &#123;1, 1, 1, 1, 1&#125;;semaphore room = 4;void philosopher(int i) &#123; do &#123; think(); wait(room); wait(chopsticks[i]); wait(chopsticks[(i + 1) % 5]); eat(); signal(chopsticks[(i + 1) % 5]); signal(chopsticks[i]); signal(room); &#125; while(1);&#125; 解法2: 将拿一双筷子作为一个 原子操作. 123456789101112131415semaphore mutex = 1; // 将一双筷子视作资源, 表示当前是否有人在拿筷子semaphore chopsticks[5] = &#123;1, 1, 1, 1, 1&#125;;void philosopher(int i) &#123; do &#123; think(); wait(mutex); // 申请拿筷子的权限 wait(chopsticks[(i + 1) % 5]); wait(chopsticks[i]); signal(mutex); eat(); signal(chopsticks[(i + 1) % 5]); signal(chopsticks[i]); &#125; while(1);&#125; 解法3: 规定奇数的哲学家先拿左边的筷子, 再拿右边的筷子; 偶数的哲学家先拿右边的筷子再拿左边的筷子. 1234567891011121314151617181920semaphore chopsticks[5] = &#123;1, 1, 1, 1, 1&#125;;void philosopher(int i) &#123; do &#123; think(); if (i % 2 == 0) &#123; wait(chopsticks[(i + 1) % 5]); wait(chopsticks[i]); eat(); signal(chopsticks[(i + 1) % 5]); signal(chopsticks[i]); &#125; else &#123; wait(chopsticks[i]); wait(chopsticks[(i + 1) % 5]); eat(); signal(chopsticks[i]); signal(chopsticks[(i + 1) % 5]); &#125; &#125; while(1);&#125; 习题2 生产者消费者问题的变式: 4 个进程 R1, R2, W1, W2 共享大小为 1 的缓冲器 B. R1 将输入的数放入 B 并且 只给 W1 使用 R2 将输入的数放入 B 并且 只给 W2 使用 分析: 生产者: R1, R2; 消费者: W1, W2 R1, R2互斥, R1&amp;W1, R2&amp;W2同步 只有一个空间大小: 用 empty 代替 mutex 1234567891011121314151617181920semaphore empty = 1, full1 = 0, full2 = 0;buffer B;process R1() &#123; do &#123; int x = input(); wait(empty); // R1, R2 竞争权限 B = x; signal(full1); // 如果是 R2, 则改为 full2 &#125; while(1);&#125;process W1() &#123; do &#123; int i; wait(full1); // 如果是 W2, 则改为 full2 i = B; signal(full); // 释放资源 &#125; while(1);&#125;","categories":[{"name":"CS","slug":"CS","permalink":"https://andrew-rey.github.io/categories/CS/"}],"tags":[]},{"title":"SVM","slug":"ML/SVM","date":"2022-05-03T13:26:05.000Z","updated":"2022-11-23T11:12:45.977Z","comments":true,"path":"2022/05/03/ML/SVM/","link":"","permalink":"https://andrew-rey.github.io/2022/05/03/ML/SVM/","excerpt":"\"很明显, 内容是抄来的.\" \"你是瞧不起李航还是瞧不起我?\"","text":"\"很明显, 内容是抄来的.\" \"你是瞧不起李航还是瞧不起我?\" 引言 没什么引言, 姑且谈谈什么是 函数间隔, 什么是 几何间隔 吧. 其实大部分来自于直觉和观察吧. 比如你看下面这幅图, 好看不? 我画的. 假设蓝色点为正例, 显然直线代表的是分界面, 并且从直观上感受: 对于某个蓝色点而言, 离分界面越远, 它是正例的可能性越高, 而 某个蓝色点离分界面越近, 它是正例可能性越小 (即被误判的可能性越高). 因此, 能不能使用一种方法, 或者是表达方式来展示这种直觉呢? 答案是 距离. 一般而言, 一个点距离分离超平面的远近可以表示分类预测的确信程度. 设分离超平面为 \\(w^Tx+b=0\\), 则 \\(|w^Tx+b|\\) 表示了某个样本点 \\(x\\) 与超平面的距离. 而 \\(|w^Tx+b|\\) 的符号与类标签 \\(y\\in{-1,1}\\) 是否一致能够表示分类是否正确. 所以, 用 \\[ y(w^Tx+b) \\] 可以表示分类的正确性和确信度. 这便是所谓的函数间隔. 函数间隔 训练集 \\(T\\), 超平面 \\((w, b)\\), \\((w, b)\\) 关于某样本点 \\((x_i, y_i)\\) 的函数间隔定义为 \\[ \\hat{\\gamma}_i=y_i(w^Tx_i+b) \\] 而超平面 \\((w, b)\\) 关于 \\(T\\) 的函数间隔定义为 \\[ \\hat{\\gamma}=min_{i=1,\\cdots,n}\\hat{\\gamma}_i \\] 考虑到 \\(\\omega\\) 和 \\(b\\) 是齐次的, 同时增大或减小时会影响到函数间隔, 因此引出几何间隔的概念: 几何间隔 训练集 \\(T\\), 超平面 \\((w, b)\\), \\((w, b)\\) 关于某样本点 \\((x_i, y_i)\\) 的函数间隔定义为 \\[ \\gamma_i=y_i(\\frac{w^T}{||w||}x_i+\\frac{b}{||w||}) \\] 而超平面 \\((w, b)\\) 关于 \\(T\\) 的函数间隔定义为 \\[ \\gamma=min_{i=1,\\cdots,n}\\hat{\\gamma} \\] 正题 硬间隔线性SVM SVM要求最大化几何间隔, 能使超平面以最大的置信度将样本分类 \\[ \\begin{aligned} max_{w,b}\\ \\ &amp;\\gamma \\\\ s.t.\\ \\ &amp;y_i(\\frac{w^T}{||w||}x_i+\\frac{b}{||w||}) \\geq \\gamma,\\ \\ i=1,\\cdots,n \\end{aligned} \\] 将几何间隔化为函数间隔, \\(\\gamma=\\frac{\\hat{\\gamma}}{||w||}\\), 并考虑到函数间隔与 \\((w,b)\\) 无关, 取 \\(\\hat{\\gamma}=1\\), 得到如下二次规划: \\[ \\begin{aligned} min_{w,b}\\ \\ &amp;\\frac{1}{2}||w||^2 \\\\ s.t.\\ \\ &amp;y_i(w^Tx_i+b) \\geq 1,\\ \\ i=1,\\cdots,n \\end{aligned} \\] 优化该问题: \\(Lagrange\\) 函数: \\[ L(w,b,\\lambda)=\\frac{1}{2}w^Tw+\\sum_i\\lambda-\\sum_i\\lambda_i y_i(w^Tx_i + b) \\] 对参数求梯度: \\[ \\begin{aligned} \\frac{\\partial}{\\partial w}L&amp;=w-\\sum_i\\lambda_i y_i x_i = 0 &amp;\\qquad(1)\\\\ \\frac{\\partial}{\\partial b}L&amp;=-\\sum_i\\lambda_i y_i = 0 &amp;\\qquad(2) \\end{aligned} \\] 带入 \\(Lagrange\\) 函数得对偶函数 (即拉格朗日函数关于参数的极小值): \\[ -\\frac{1}{2}\\sum_{i,j}\\lambda_i\\lambda_j y_i y_j x_i^Tx_j + \\sum_i\\lambda_i \\] 得原问题的对偶问题: \\[ \\begin{aligned} max_{\\lambda}\\ \\ &amp;-\\frac{1}{2}\\sum_{i,j}\\lambda_i\\lambda_j y_i y_j x_i^Tx_j + \\sum_i\\lambda_i \\\\ s.t.\\ \\ &amp;\\sum_i\\lambda_i y_i = 0 \\\\ &amp;\\lambda\\geq 0 \\end{aligned} \\] 或: \\[ \\begin{aligned} min_{\\lambda}\\ \\ &amp;\\frac{1}{2}\\sum_{i,j}\\lambda_i\\lambda_j y_i y_j x_i^Tx_j - \\sum_i\\lambda_i \\\\ s.t.\\ \\ &amp;\\sum_i\\lambda_i y_i = 0 \\\\ &amp;\\lambda\\geq 0 \\end{aligned} \\] 由 \\(KKT\\) 条件: \\[ \\begin{aligned} \\nabla_{w;b}L&amp;=0 \\\\ \\lambda_i&amp;\\geq 0 \\\\ y_i(w^Tx_i+b) &amp;\\geq 1,\\ \\ i=1,\\cdots,n \\\\ \\lambda_i(y_i(w_*^Tx_i + b_*) - 1) &amp;= 0 \\end{aligned} \\] 考虑到 \\(y_i^2=1\\) 得: \\[ \\begin{aligned} w_*&amp;=\\sum_i\\lambda_i y_i x_i \\\\ b_*&amp;=y_i-\\sum_i \\lambda_i y_i x_i^Tx_j \\end{aligned} \\] 此处的 \\(\\lambda_i\\) 表示最优的 \\(\\lambda_*\\). 因此得到分离超平面: \\[ y(x) = (\\sum_i\\lambda_i y_i x_i)^Tx + y_i-\\sum_i \\lambda_i y_i x_i^Tx_j \\] 此处的 \\(\\lambda_i\\) 表示最优的 \\(\\lambda_*\\). 最后的决策函数可以定义为: \\[ f(x) = sgn (y(x)) \\] 来个例题: 用二次规划和对偶问题两种方式求解. 答案: \\[ \\frac{1}{2}x^{(1)}+\\frac{1}{2}x^{(2)}-2=0 \\] 软间隔线性SVM 数据集线性不可分, 设置松弛变量 \\(\\xi\\). 线性不可分表示部分数据不能满足函数间隔大于等于1. 但我们希望添加松弛变量后可以满足. \\[ y_i(w^Tx_i+b)\\geq 1-\\xi_i \\] 但我们不允许无限制地引入松弛变量, 因此需要设置一定的代价: \\[ C\\sum_i\\xi_i,\\ \\ C &gt; 0 \\] 因此原问题等价于下述二次规划: \\[ \\begin{aligned} min_{w,b}\\ \\ &amp;\\frac{1}{2}||w||^2 + C\\sum_i\\xi_i \\\\ s.t.\\ \\ &amp;y_i(w^Tx_i+b) \\geq 1 - \\xi_i,\\ \\ i=1,\\cdots,n \\\\ &amp;\\xi_i \\geq 0 \\end{aligned} \\] 对偶问题: \\[ \\begin{aligned} max_{\\lambda}\\ \\ &amp;-\\frac{1}{2}\\sum_{i,j}\\lambda_i\\lambda_j y_i y_j x_i^Tx_j + \\sum_i\\lambda_i \\\\ s.t.\\ \\ &amp;\\sum_i\\lambda_i y_i = 0 \\\\ &amp;C-\\lambda_i-\\mu_i = 0 \\\\ &amp;\\lambda_i, \\mu_i \\geq 0 \\end{aligned} \\] 其中 \\(\\lambda_i\\) 是对间隔引入的乘子, \\(\\mu_i\\) 是对松弛变量引入的乘子. 解出最优解: \\[ \\begin{aligned} w_*&amp;=\\sum_i\\lambda_i y_i x_i \\\\ b_*&amp;=y_i-\\sum_i \\lambda_i y_i x_i^Tx_j \\end{aligned} \\] 此处的 \\(\\lambda_i\\) 表示最优的 \\(\\lambda_*\\). 支持向量 对于硬间隔, 支持向量是使 \\(\\lambda &gt; 0\\) 的样本, 由互补松弛性, 它们满足 \\(y_i(w^Tx_i+b) = 1\\), 因此这些样本落在间隔边界, 将分离超平面\"支持\"起来. 对于软间隔, 支持向量是 使 \\(0 &lt; \\lambda &lt; C\\) 的样本, 由互补松弛性, 此时 \\(y_i(w^Tx_i+b) = 1\\) 且 \\(\\xi_i = 0\\); 同时, 若 \\(\\lambda = C\\) 即 \\(\\mu = 0\\), 即 \\(\\xi_i \\neq 0\\): \\(0 &lt; \\xi_i &lt; 1\\): 分类正确 \\(\\xi_i = 1\\): 在分离超平面上; \\(\\xi_i &gt; 1\\): 误分 合页损失 (hinge loss) 线性支持向量机的原始优化问题 \\[ \\begin{aligned} min_{w,b}\\ \\ &amp;\\frac{1}{2}||w||^2 + C\\sum_i\\xi_i \\\\ s.t.\\ \\ &amp;y_i(w^Tx_i+b) \\geq 1 - \\xi_i,\\ \\ i=1,\\cdots,n \\\\ &amp;\\xi_i \\geq 0 \\end{aligned} \\] 等价于问题 \\[ min_{w, b}\\ \\ \\sum_i[(1-y_i(w^Tx_i+b))]_++\\lambda||w||_2^2 \\] 其中 \\[ [z]_+= \\left \\{ \\begin{aligned} z&amp;,\\quad z&gt;0 \\\\ 0&amp;,\\quad z\\leq 0 \\end{aligned} \\right . \\] 称为合页损失. 后面的问题可以理解为: 当间隔大于1时, 无损失; 当间隔小于1时给损失; 同时第二项是参数的正则项. 对比感知机, 线性SVM要求分类大于一定的置信度后, 才能将损失设置为0, 而感知机无置信度, 见下图 Kernel Trick 从线性SVM不能解决非线性问题的角度出发, 引入了核技巧, 从而得到非线性SVM. 核技巧的思想是将原特征空间经过 非线性映射, 映射至一个特征空间, 使得原特征空间中的超曲面对应与映射后特征空间的的超平面. 记非线性映射为 \\(\\phi\\). 事实上, 该非线性映射将输入空间 (欧式空间或离散空间) 映射至一个特征空间 (Hilbert空间). 即: \\[ \\phi(x):X \\rightarrow H \\] 但是, 由于 \\(\\phi\\) 不好构造, 而直接计算内积 \\(\\phi(x)^T\\phi(y)\\) 比先计算 \\(\\phi(x)\\) 再计算内积容易, 因此引入 核函数 的概念: 核函数 称 \\(K(x,z)\\) 为核函数, 如果满足: \\(\\forall x,z\\in X, \\exists \\phi(x):X \\rightarrow H,\\ s.t.\\ K(x,z)=\\phi(x)\\cdot\\phi(z)\\) 这时, 可以将 \\[ \\begin{aligned} max_{\\lambda}\\ \\ &amp;-\\frac{1}{2}\\sum_{i,j}\\lambda_i\\lambda_j y_i y_j x_i^Tx_j + \\sum_i\\lambda_i \\\\ s.t.\\ \\ &amp;\\sum_i\\lambda_i y_i = 0 \\\\ &amp;C-\\lambda_i-\\mu_i = 0 \\\\ &amp;\\lambda_i, \\mu_i \\geq 0 \\end{aligned} \\] 中的 \\[ \\frac{1}{2}\\sum_{i,j}\\lambda_i\\lambda_j y_i y_j x_i^Tx_j - \\sum_i\\lambda_i \\] 改为 \\[ W(\\lambda)=\\frac{1}{2}\\sum_{i,j}\\lambda_i\\lambda_j y_i y_j K(x_i,x_j) - \\sum_i\\lambda_i \\] 正定核 能否不用构造 \\(\\phi\\) 就可以判断某个函数是否是核函数? 一般, 核函数指正定核函数. Thm \\(K(x,z):X\\times X\\rightarrow R\\) 是对称函数, 则 \\(K\\) 为正定核的充要条件为 \\(K\\) 对应的 \\(Gram\\) 矩阵半正定. *扩展: \\(Mercer\\) 核 常用核函数 多项式核: \\[ K(x,z)=(x^Tz+1)^p \\] 高斯核: \\[ K(x,z)=exp(-\\frac{||x-z||^2}{2\\sigma^2}) \\] 拉普拉斯核: \\[ K(x,z)=exp(-\\frac{||x-z||}{\\sigma}) \\] sigmoid核: \\[ K(x,z)=tanh(x^Tz+1) \\] SMO算法 SMO: 序列最小最优算法 思想是将原问题不断分解为二次规划的子问题, 每次从优化变量中取两个, 其中一个严重违背 KKT 条件, 另一个满足; 直到所有的变量都满足 KKT 条件.","categories":[{"name":"ML","slug":"ML","permalink":"https://andrew-rey.github.io/categories/ML/"}],"tags":[]},{"title":"2022年4月15日-夜","slug":"Life/2022年4月15日-夜","date":"2022-04-15T15:59:27.000Z","updated":"2022-11-23T11:12:45.974Z","comments":true,"path":"2022/04/15/Life/2022年4月15日-夜/","link":"","permalink":"https://andrew-rey.github.io/2022/04/15/Life/2022%E5%B9%B44%E6%9C%8815%E6%97%A5-%E5%A4%9C/","excerpt":"\"别看, 这是日记.\" \"日记? 那我更要看看了!\"","text":"\"别看, 这是日记.\" \"日记? 那我更要看看了!\" 随便写写 从某种意义上确实是一篇日记, 但是既然敢发表在博客上, 那和朋友圈应该差不多, 不过是记录一下这忙碌的一周. 早三周就收到了要中期答辩的通知了, 啥也没做 (当然, 自己在家还是读了一些论文的, 还顺便玩了 python 中和安全相关的几个库). 一开始还是停留在寒假导师给我们要求: 可以学学 Nmap, 甚至开学以后还在用. 每次使用不过是随便指定一个倒霉的 ip, 然后去对方日志里面踩上一脚. 虽然有时候识别一下操作系统 (说实话, 这个从端口扫描到识别操作系统的一系列操作都被包含在了 Nmap 里面是我没想到的), 但主要还是没事干拿来用用. 最后做项目当然是没有用它: - 它好像不能读取流量数据? - 不知道怎么用 python 系统调用 Nmap? - 效率比较低? (当然, 最后用 python + wireshark 的组合也不见得有多高效率) 当然, 我体验最深的必须是这一周. 两个组员去写综述了. 代码和数据都在我这边做. 目前对中期也没什么把握, 毕竟确实什么都没有做. 没做也要硬着头皮去做啊. 这是你的项目, 你是负责人啊. 是啊, 这是我的项目啊. 为什么会从某一刻开始觉得无所谓了? 至少要完成这一件事吧? 那从最开始的数据集建立: 我们买了点物联网设备, 毕竟实验室那边去不了, 万幸的是刚好给我发了几个不同标记的设备过来, 后面还有一些因为疫情没送了. 这样我也可以做分类啊. 接下来是数据集的收集, 我就让这些设备连到电脑热点里, 然后连续抓了 24 小时包, 最后拿到了 54 万条流量数据. 那截下来就是用 python 读取这些流量, 然后统计个特征, 画几个图, 也就希望中期通过了. 但是问题就在于读取这些数据, 然后写入 csv 里面, 我惊呆了, 花我最长时间的事情不是统计, 不是训练模型, 不是写中期报告, 而是读文件?! 最初我还挺开心, 哦你 python 竟然还提供了读取这种文件的接口, 那我当然是毫不吝啬地用呗. 但是, 跑个程序, 内存占用直接飙到 6 个 Gib, 这是干嘛呢? 然后就听电脑风扇哗啦啦地响. 第一版程序还是非常暴力的, 在 github 找到了使用这个库的一些实例, 然后就照着来用, 不就是先判断再读取特征, 写入文件吗? 这不简单吗! 那我不过是多遍历几遍就行了啊, 现在的算力又不是盖的. 但是, 你这是要内存啊. 我绷不住了, 那天晚上跑了俩小时没出来, 又不敢关电脑, 那就让它一直跑吧. 结果第二天早上去看, 还在哗啦啦地读数据. ??? 这是干嘛, 我马上中期了啊哥. 重新想了想, 翻了一下代码, 我真傻, 为啥用这么多循环呢? 是吧, 我只遍历一遍不行吗. 接着一边用另一台电脑改了一份代码出来. 然后把之前那份停了 (毕竟没有输出什么日志信息, 心里也没啥底, 干脆一刀切吧). 停了以后, 我担心它内存会不会出事, 于是重启了一下, 刚好看见有系统更新, 那就重启并更新吧! 然后我看着九点半的太阳, 去外面逛了一圈, 感觉这次的 beta 版代码应该会好很多. 但是回来后, 我发现为什么我的电脑是关机状态? 难道我刚刚点成了关机? 开机看看呗. 理所应当地, 锁屏上出现了我可爱的薇尔莉特. 然后它哔地一声, 寄了. ??????????????????????? 我要中期的啊哥, 你别搞我. 我又小心翼翼地开了一次机, 直接给我跳到了 windows 系统保护程序, 我看了一下选项, \"退出并继续使用 win10\". 可是您是 win11 啊哥. 所以我乖乖地选择了关机. 当然, 我算了一下, 反正还在保修期, 于是就再次按下开机, 于是薇尔莉特有一次出现在了锁屏上. 接下来我需要按下一个恐怖的键: 这个键可能会在莫名其妙的时候给你确认什么东西, 然后你的电脑就会发生一些不可名状的物理变化; 当然更多时候, 按下这个键的时候会带来一种快感, 因为它确实很好按. 没错啊, 就是回车键. 按了以后, 过了一会儿, 我的登录界面它出来了!!! 我的贝尔头像! 然后我输了密码, 把 beta 版的代码跑起来了. 在它跑的时候, 我干嘛呢? 哦, 中期报告和文献综述. 当然文献综述大部分还是交给了队友去写. 然后就巴拉巴拉写了一堆 (可能是写了综述吧, 我现在记忆十分混乱) 反正从上午十点, 一直跑到了下午五点半, 七个小时. 我是眼睁睁看着它的计数器跑到了 54 万, 然后, 我发现, 它为什么还在跑??? 甚至, 已经超过了 55 万, 不是, 这是在干嘛? 我是在做梦吗. 我是. 我的意思是, 我打开错了一个文件, 这个文件里面有 166 万数据, 其中 2/3 的数据是空包... 赶紧到处问, 我跑到一半能不能保存数据啊各位, 我这个 beta 版把文件写入放到了读取的最后, 因此如果没有读完, 你休想写入. 停吧停吧. 而这时已经是星期一晚上了. 星期五晚上答辩. 那这代码必须改啊. 我学聪明了, 我一开始我就写入, 还测试了许多小 demo, 看看循环写入文件会不会覆盖. 然后, 换了一个文件! 继续写中期报告... 到了一点钟, 只跑了 30 万个数据. 不管了, 赶紧先存下来了, 并且先发到群里去了. 要是后面又出事, 就...开摆吧. 第二天早上, 电脑是睡着的, 像我一样睡眼朦胧的. 不过我看见它是睡着的, 我立马变得十分清醒----是不是又要寄了? 好吧, 不知道是什么牛马更新, 把我之前设置的永不睡眠给改回去了. 然后去看了看文件, 啊! 满满当当的 54 万数据, 以及我其他提取特征的数据! 我的天啊! 你们真可爱. 而控制台输出了我设置的输出: 用时 7.72 小时. 不错. 现在是星期二, 我觉得我又行了. 当然, 我在它第一次没读出来的时候, 我还认为是它库的源码错了, 我就跑它的实现去看. 好家伙? 您搁着开心地递归呢? 本来 python 就比 C 慢, 你还疯狂递归. 不管了, 毕竟这个库不是主打读文件的. 星期三是文件提交的 ddl, 早上交的. 星期二改了改报告, 画了几张图用来镇场子, 然后做完了就开始在 push 导师给我们签字, 系统审核, 不知道他那边怎么想的, 感觉不想理我们. 反正你得给我签. 星期三毕竟没课, 就开始做 PPT, 晚上做完了. 觉得没啥事了. 就一边欣赏自己的 PPT, 一边感概自己真菜. 我一定要放一个看起来我们做了事的结果上去, 因为到时候老师问你: \"啊半年就做了个统计吗?\" 于是我尝试用 SVM 浅浅地分了一个类. 之前还是了解过一些东西的. 所以参数哗啦啦就输进去了. 难就难在, 可视化. 星期四, 看着大家都在对卡时间背稿, 我要不要也做个稿子呢? 做吧, 毕竟开题答辩的时候脱稿是真的拉垮. 然后稿也写完了. 晚上给学长看了一下. \"就是, 听你讲完, 我不知道你在干嘛.\" ???!!!寄 听了他的建议啊, 我重新分配了讲稿的安排时间, 稍微改了 PPT. 晚上熬大夜, 到了三点多, 还是没能看懂多分类的 3 特征决策面怎么画 (我这句话说这么清楚当然就是希望有没有 hxd 告诉我咋搞, model.decision_function.reshape 为什么不是说我特征维度不对, 就是说我不能 reshape). 反正我三点多的脑袋已经 reshape 了. 星期五, 早上上课差点迟到, 中午太困了. 和 Jerry 去搞了个泡面. 一点半回来的, 下午满课, 上完课和答辩前的半小时之间解决了晚餐. 之后就是紧张局促地等答辩开始. 总之不管怎么样吧. 还是答完了. 还挺流畅的, 老师问的问题也特别友好 (这种情况下, 一般没什么好结果, 因为极大可能性是老师不知道你在干嘛). 不管了, 睡觉! 还是写了写后记 当然, 正文和后记的写作时间没有间隔 1 秒. 主要是想说, 这一周见了很多很厉害的人, 很厉害的项目, 很团结的组员. 看了汤老师雷打不动每天调代码, pc 隔离后出来多了欢乐的气息, 还有 Jerry 时常带来一些地狱笑话, 鸡哥偶尔也过来\"嘘寒问暖\"... 虽然我不是和他们一起做项目, 但是我觉得很快乐. 就是这样. 2022 年 4 月 16 日凌晨","categories":[{"name":"Life","slug":"Life","permalink":"https://andrew-rey.github.io/categories/Life/"}],"tags":[]},{"title":"Algorithm-FFT","slug":"Algorithm/Algorithm-FFT","date":"2022-04-06T08:08:39.000Z","updated":"2022-12-26T02:54:28.248Z","comments":true,"path":"2022/04/06/Algorithm/Algorithm-FFT/","link":"","permalink":"https://andrew-rey.github.io/2022/04/06/Algorithm/Algorithm-FFT/","excerpt":"\"FFT是我见过最美的算法.\" \"说的好像你见过很多算法似的.\"","text":"\"FFT是我见过最美的算法.\" \"说的好像你见过很多算法似的.\" 多项式乘积问题 首先来思考这样的一个问题: Question 1 你有两个多项式函数: \\[p(x)=2x^3+x+1\\] \\[q(x)=x^2+4x+5\\] 应该如何计算它们的乘积? 当然, 我不是说要用笔算的方式, 而是用计算机. 显然这个问题我们在小学二年级就写过的, 当初正在学习\"数据结构\"这门课, 如果没记错, 应该是用链表实现的. 但是, 就算是用链表实现, 那不也是和手算一样的原理吗? 将二者相乘 分配律 合并同类项 例如上面那个例子: solution 1 \\[ \\begin{align*} r(x) &amp;= (2x^3+x+1)(x^2+4x+5) \\\\ &amp;= 2x^5+8x^4+10x^3+x^3+4x^2+5x+x^2+4x+5 \\\\ &amp;= 2x^5+8x^4+11x^3+5x^2+5x+5 \\end{align*} \\] (???是什么动力让我深夜在这里口算多项式乘法???) 显然, 如果一个 n 次多项式乘上一个 m 次多项式, 在合并同类项前应该有 \\(n\\times m\\) 次多项式, 这谁顶得住? 对于正常人类而言显然顶不住, 对于计算机而言, 时间复杂度是\\(O(n^2)\\), 也是算比较大的开销了吧. 咋办? 点表示法 开始 有谁规定, 我多项式一定是用系数表示的? 好家伙, 你这样说我就摸不着头脑了, 难道除了系数表示还有其他表示方法吗? 首先, 多项式集合其实是构成了一个线性空间, 也就是说, 任意两个多项式进行线性运算 (加法和数乘) 后, 结果仍然是多项式. 事实上 \\[ {1, x, x^2, \\dots, x^n, \\dots} \\] 构成了该空间的一组基, 将函数展开成 Taylor 级数便用了这组基作为基底, 基前面的系数也就是坐标. 其次, 对于一个 n 次多项式而言, 只要我们确定了它的坐标, 就能唯一确定这个多项式. 现在的问题是不知道坐标, 如何确定多项式. 这里的巧妙之处就在于, 多项式函数是一个映射, 对于一个特定的 x, 总是能给出唯一一个值与之对应, 这不就是一个方程吗? 我给你一个 x, 你输出一个值, 同时由于多项式系数全部未知, 这就是一个关于 \\(n+1\\) 个系数的方程 显然, 我需要 \\(n+1\\) 个不同的点来唯一确定我的系数. 这就是所谓的点表示法. 这样一来, 我们将这 \\(n+1\\) 个方程写成矩阵形式: \\[ \\begin{bmatrix} p_0 \\\\ p_1 \\\\ \\vdots \\\\ p_n \\end{bmatrix} = \\begin{bmatrix} 1\\quad &amp; x_0\\quad &amp; \\dots\\quad &amp; x_0^n \\\\ 1\\quad &amp; x_1\\quad &amp; \\dots\\quad &amp; x_1^n \\\\ \\vdots\\quad &amp; \\vdots\\quad &amp; \\quad &amp; \\vdots \\\\ 1\\quad &amp; x_n\\quad &amp; \\dots\\quad &amp; x_n^n \\end{bmatrix} \\begin{bmatrix} c_0 \\\\ c_1 \\\\ \\vdots \\\\ c_n \\end{bmatrix} \\] 看到这里我终于理解了为什么在学高等代数时要突然讲一个范德蒙德(Vandermonde)行列式, 也就是这里的 \\[ \\left[ \\begin{aligned} 1\\quad &amp; x_0\\quad &amp; \\dots\\quad &amp; x_0^n \\\\ 1\\quad &amp; x_1\\quad &amp; \\dots\\quad &amp; x_1^n \\\\ \\vdots\\quad &amp; \\vdots\\quad &amp; \\quad &amp; \\vdots \\\\ 1\\quad &amp; x_n\\quad &amp; \\dots\\quad &amp; x_n^n \\end{aligned} \\right] \\] 将上述矩阵定义为我们最喜欢的字母\\(A\\). 好, 既然这东西是范德蒙德行列式, 那我们可以知道它行列式\\(|A|=\\prod_{0\\leq j&lt; i\\leq n}(x_i-x_j)\\)不为 0, 也就是说, 这个矩阵是可逆的, 也就是当我们取 \\(n+1\\) 个不同点时, 确实是可以使方程组有唯一解, 也就是 \\(n+1\\) 个点可以唯一表示一个 n 次多项式. 乘法 问题来了, 如何做乘法? 我们有 n 次多项式和 m 次多项式做乘法, 得到的是一个 \\(n+m\\) 次多项式, 那么我们只要找到 \\(n+m+1\\) 个点即可, 也就是只要在 n 次多项式和 m 次多项式中分别找 \\(n + m + 1\\) 个点, 这些点的横坐标 x 相等, 再将对应的函数值相乘即可. 进一步 现在, 我们知道了如何用点表示多项式, 以及如何用点表示进行乘法运算. 但是仔细一想, 这种方法需要求解线性方程组, 这里的计算复杂度并不低. 也就是从系数表示法到点表示法的转化过程带来的计算复杂度还是很高的. 有什么方法可以进行简化吗? 先等一等, 我们先来梳理我们用点表示求多项式乘法的思路: MainIdea 将 n 次多项式和 m 次多项式分别从系数表示转化为点表示 对应点相乘 将得到的 \\(n+m+1\\) 个点表示的多项式转化为系数表示 奇偶 先来考虑简单的情况: Question 2 多项式 $ p(x) = x^2 $ 和多项式 $ q(x)=x^3 $ 用点表示法相乘 那我们当然是按部就班地进行乘法啦~ - 由于结果是 5 次多项式, 因此对\\(p(x)\\)取 5 个点, 对\\(q(x)\\)取 5 个点. 取点, 说得轻巧, 做起来倒是挺犹豫的. 取什么样的点能满足要求呢? 或者得寸进尺地说, 什么样的点能让效率更高呢? 注意到二次函数是对称的, 那我们是不是只要取正的 2 个点, 就能知道负的 2 个点, 另外加一个原点? 确实如此. 那三次多项式呢? 照理来说, 我们同样也是只要取一半的点就能知道另一半点的值(这里的\"一半\"针对正负而言), 只不过要在函数值上添加负号, 何必呢? 还不如干脆 提出一个 x, 然后不也变成了二次函数? 事实上, 一般而言, 我们要用点表示法表示多项式, 可以用如下方法: Method1 \\[ p(x)=\\sum_{i=1}^n c_ix^i=P_e(x)+P_o(x)=P_{e1}(x)+xP_{e2}(x) \\] 其中, \\(P_{ei}(x)\\)表示只含偶次的多项式函数, \\(P_o(x)\\)表示只含奇次的多项式. 这样, 我们只要在非负轴上取值就可以确定整个多项式, 取点的个数是 原来的一半. 甚至, 这里形成了一个 递归 算法: 分解后的\\(P_{ei}(x)\\)不也是一个关于 x 的多项式吗?! 那我继续啊, 把\\(P_{ei}(x)\\)继续分解啊, 大事化小, 小事化了. 等等! 我们的\\(P_{ei}(x)\\)其实是\\(P_{ei}(x^2)\\), 这里每个\\(x^2\\)都是非负的啊. 未来我们只能在非负轴取值了, 也就是说, 分解为偶次多项式后, 递归停止了. 完蛋. 复数域分解 \"山重水复疑无路, 柳暗花明又一村\" 看到标题就已经知道要怎么做了. 既然在实数域上无法继续分解\\(P_{ei}(x^2)\\), 那为何不去复数域呢? 在复数域上我们可以快乐地进行递归. 如何个快乐法呢? 我们来细品: 偶次多项式在复平面上的根 为什么突然变成了 求根? 从第二节中\"奇偶\", 我们可以选取对称的点, 来减少选取点的个数(即原来的一半). 接着我们把任意 n 次多项式分解成两个偶次多项式, 偶次多项式的好处在于容易选取对称的点. 但是由于在实数范围内, 在对偶次多项式进行递归时会发生中断, 于是我们扩展至复数域讨论分解. 方便起见: 对于\\(x^0\\), 我们取\\(x=1\\)作为特征点, 对于\\(x^2\\), 我们取\\(x=1, x=-1, x=0\\)作为三个特征点, 那对于\\(x^4\\), 我们应该怎样取点, 抛开\\(x=0\\)不谈, 令\\(x^4=1\\), 由 代数基本定理, 该方程在复数域上有 4 个 根, 对于其它偶次多项式我们以此类推. 就这样, 我们找到了一个简单的方法寻找所有需要的点, 进行递归. 单位根 写到这里, 我也感觉有点吃力, 关键是为什么一定就取了令\\(x^{2k}=1\\)呢? 虽然但是, 确实是所谓的\"方便起见\", 这是因为, 取了\"1\", 我们可以在复平面上的单位圆上讨论这个问题. 在小学二年级我们就知道, \\(x^{n}=1\\)的根可以用我们熟悉的\\(\\omega\\)的幂来表示, 即 \\[ \\omega = e^{\\frac{2k\\pi}{n}i}\\qquad(k=0,1,\\dots,n-1) \\] 这些\\(n\\)个点在复平面单位圆上 对称分布. 每递归一次, 单位根的数量减少一半, 但保持对称性不变. 确实方便. 快速傅里叶变换(FFT) 终于能正式地介绍世界上最美丽的算法了: 快速傅里叶变换(FFT). FFT解决的是多项式从系数表示到点表示的过程中, 计算复杂度的问题. 框架 分解: \\[ p(x)=\\sum_{k=0}^nc_kx^k=P_{e1}(x^2)+xP_{e2}(x^2):=[ \\omega^0, \\omega^1, \\dots, \\omega^n] \\] 递归: \\[ P\\_{e1}(x^2) = P^{\\prime}\\_{e1}(x^4)+xP^{\\prime}\\_{e2}(x^4):=[\\omega^0, \\omega^1, \\dots, \\omega^{n-1}] \\] \\[ P\\_{e2}(x^2) = P^{\\prime}\\_{e1}(x^4)+xP^{\\prime}\\_{e2}(x^4):=[\\omega^0, \\omega^1, \\dots, \\omega^{n-1}] \\] 加和: \\[ P(\\omega^j)=P\\_{e1}(\\omega^{j})+\\omega^jP\\_{e2}(\\omega^j) \\] \\[ P(\\omega^{j+n/2})=P\\_{e1}(\\omega^{j+n/2})+\\omega^{j+n/2}P\\_{e2}(\\omega^{j+n/2}) \\] \\(j\\in[0,1,\\dots, n/2+1]\\) 返回\\(p(x)\\) 时间复杂度为: \\(O(nlog_2n)\\) 一些数学 对于 n 次多项式 \\(p(x)=\\sum_{k=0}^n c_kx^k\\), 我们给定\\(n+1\\)个点: \\(x_0, \\dots, x_n\\), 从而得到关于原多项式 \\(n+1\\) 个系数的线性方程组: \\[ \\left[ \\begin{aligned} p_0 \\\\ p_1 \\\\ \\vdots \\\\ p_n \\end{aligned}\\right] = \\left[ \\begin{aligned} 1\\quad &amp; x_0\\quad &amp; \\dots\\quad &amp; x_0^n \\\\ 1\\quad &amp; x_1\\quad &amp; \\dots\\quad &amp; x_1^n \\\\ \\vdots\\quad &amp; \\vdots\\quad &amp; \\quad &amp; \\vdots \\\\ 1\\quad &amp; x_n\\quad &amp; \\dots\\quad &amp; x_n^n \\end{aligned} \\right] \\left[ \\begin{aligned} c_0 \\\\ c_1 \\\\ \\vdots \\\\ c_n \\end{aligned}\\right] \\] 我们在复数域上考虑, 令 \\[ x_k=\\omega^k,\\quad where\\ \\ \\omega=e^{\\frac{2k\\pi}{n}} \\] (这是因为, 我们希望多项式在复数域上考虑时, 我们可以在单位圆周上讨论. 其中\\(x_k\\)表示我们取的第 k 个点, 刚好与 \\(\\omega^k\\)是对应的.) 则线性方程组可以化为: \\[ \\left[ \\begin{aligned} p_0 \\\\ p_1 \\\\ \\vdots \\\\ p_n \\end{aligned}\\right] = \\left[ \\begin{aligned}[c] 1\\quad &amp; 1\\quad &amp; 1\\quad &amp; \\dots\\quad &amp; 1 \\\\ 1\\quad &amp; \\omega\\quad &amp; \\omega^2\\quad &amp; \\dots\\quad &amp; \\omega^n \\\\ 1\\quad &amp; \\omega^2\\quad &amp; \\omega^4\\quad &amp; \\dots\\quad &amp; \\omega^{2n} \\\\ \\vdots\\quad &amp; \\vdots\\quad &amp; \\vdots\\quad &amp; &amp; \\vdots \\\\ 1\\quad &amp; \\omega^n\\quad &amp; \\omega^{2n}\\quad &amp; \\dots\\quad &amp; \\omega^{n\\times n} \\end{aligned} \\right] \\left[ \\begin{aligned} c_0 \\\\ c_1 \\\\ \\vdots \\\\ c_n \\end{aligned}\\right] \\] 其中 \\[ \\left[ \\begin{aligned}[c] 1\\quad &amp; 1\\quad &amp; 1\\quad &amp; \\dots\\quad &amp; 1 \\\\ 1\\quad &amp; \\omega\\quad &amp; \\omega^2\\quad &amp; \\dots\\quad &amp; \\omega^n \\\\ 1\\quad &amp; \\omega^2\\quad &amp; \\omega^4\\quad &amp; \\dots\\quad &amp; \\omega^{2n} \\\\ \\vdots\\quad &amp; \\vdots\\quad &amp; \\vdots\\quad &amp; &amp; \\vdots \\\\ 1\\quad &amp; \\omega^n\\quad &amp; \\omega^{2n}\\quad &amp; \\dots\\quad &amp; \\omega^{n\\times n} \\end{aligned} \\right] \\] 称为离散傅里叶变换矩阵(DFT)显然该矩阵是 对称的 且 可逆, 其逆矩阵为: \\[ \\frac{1}{n} \\left[ \\begin{aligned}[c] 1\\quad &amp; 1\\quad &amp; 1\\quad &amp; \\dots\\quad &amp; 1 \\\\ 1\\quad &amp; \\omega^{-1}\\quad &amp; \\omega^{-2}\\quad &amp; \\dots\\quad &amp; \\omega^{-n} \\\\ 1\\quad &amp; \\omega^{-2}\\quad &amp; \\omega^{-4}\\quad &amp; \\dots\\quad &amp; \\omega^{-2n} \\\\ \\vdots\\quad &amp; \\vdots\\quad &amp; \\vdots\\quad &amp; &amp; \\vdots \\\\ 1\\quad &amp; \\omega^{-n}\\quad &amp; \\omega^{-2n}\\quad &amp; \\dots\\quad &amp; \\omega^{-n\\times n} \\end{aligned} \\right] \\] 并且, 该逆矩阵看起来和原矩阵 一模一样! . 结束了? 当我们乐呵呵地把FFT转化为代码时, 开心的分解多项式, 然后选点, 相乘, 等等! 你还没告诉我, 怎么从点表示转化回系数表示呢! 这就是FFT对称的魅力了. 由点求系数, 不过是矩阵求逆的过程: \\[ \\left[ \\begin{aligned} c_0 \\\\ c_1 \\\\ \\vdots \\\\ c_n \\end{aligned}\\right] = \\left[ \\begin{aligned}[c] 1\\quad &amp; 1\\quad &amp; 1\\quad &amp; \\dots\\quad &amp; 1 \\\\ 1\\quad &amp; \\omega\\quad &amp; \\omega^2\\quad &amp; \\dots\\quad &amp; \\omega^n \\\\ 1\\quad &amp; \\omega^2\\quad &amp; \\omega^4\\quad &amp; \\dots\\quad &amp; \\omega^{2n} \\\\ \\vdots\\quad &amp; \\vdots\\quad &amp; \\vdots\\quad &amp; &amp; \\vdots \\\\ 1\\quad &amp; \\omega^n\\quad &amp; \\omega^{2n}\\quad &amp; \\dots\\quad &amp; \\omega^{n\\times n} \\end{aligned} \\right]^{-1} \\left[ \\begin{aligned} p_0 \\\\ p_1 \\\\ \\vdots \\\\ p_n \\end{aligned}\\right] \\\\ =\\frac{1}{n} \\left[ \\begin{aligned}[c] 1\\quad &amp; 1\\quad &amp; 1\\quad &amp; \\dots\\quad &amp; 1 \\\\ 1\\quad &amp; \\omega^{-1}\\quad &amp; \\omega^{-2}\\quad &amp; \\dots\\quad &amp; \\omega^{-n} \\\\ 1\\quad &amp; \\omega^{-2}\\quad &amp; \\omega^{-4}\\quad &amp; \\dots\\quad &amp; \\omega^{-2n} \\\\ \\vdots\\quad &amp; \\vdots\\quad &amp; \\vdots\\quad &amp; &amp; \\vdots \\\\ 1\\quad &amp; \\omega^{-n}\\quad &amp; \\omega^{-2n}\\quad &amp; \\dots\\quad &amp; \\omega^{-n\\times n} \\end{aligned} \\right] \\left[ \\begin{aligned} p_0 \\\\ p_1 \\\\ \\vdots \\\\ p_n \\end{aligned}\\right] \\] 显然, 由于DFT和DFT逆矩阵具有相似的形式, 我们完全可以用同一个函数完成快速傅里叶的正反变换! 后记-\"对称, 万变不离其宗\" 不会真有人会把这个没有图的文章看完吧? 相信我, 日后在这里补充图片的概率为 \\[ p=lim_{x\\rightarrow\\infty}xsin (1/x) \\] (糟糕, 好像出简单了) 另外, 在递归的地方, 觉得并没有讲清楚具体的步骤, 但是思想到位了. 日后也不想改了. 可能以后补一补应用场景之类的, 至于代码, 看情况吧.","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://andrew-rey.github.io/categories/Algorithm/"}],"tags":[]},{"title":"空间杂谈","slug":"Math/空间杂谈","date":"2022-03-19T17:20:10.000Z","updated":"2022-11-23T11:12:45.978Z","comments":true,"path":"2022/03/20/Math/空间杂谈/","link":"","permalink":"https://andrew-rey.github.io/2022/03/20/Math/%E7%A9%BA%E9%97%B4%E6%9D%82%E8%B0%88/","excerpt":"\"内积空间和度量空间有什么区别? Hilbert空间是什么? 它与线性空间的关系是什么?\" \"我已经晕了.\"","text":"\"内积空间和度量空间有什么区别? Hilbert空间是什么? 它与线性空间的关系是什么?\" \"我已经晕了.\" 数域 \\(P\\)是包含0, 1的数集, 且对 \\(P\\)中任意两个数的加减乘除运算封闭, 则称 \\(P\\)是一个数域. 线性空间 在数域的基础上, 我们提出线性空间的概念: 给定数域 \\(P\\) , 和集合 \\(V\\). 有如下映射: \\[ +:V\\times V\\rightarrow V \\] \\[ \\cdot:P\\times V\\rightarrow V \\] 且 (\\(V, P, +, \\)) 满足八条基本性质, 则\\(V\\)称为一个线性空间. 赋范空间 赋范空间是定义在线性空间之上的. 定义在数域 \\(P\\) 的线性空间 \\(V\\) 存在如下映射: \\[ ||\\cdot||: V\\rightarrow R \\] 且该映射满足: 正定, 齐次, 三角不等式. 则 \\(V\\) 是一个赋范空间, 其中映射 \\(||||\\) 称为范数. 内积空间 内积空间是定义在线性空间之上的. 定义在数域 \\(P\\) 的线性空间 \\(V\\) 存在如下映射: \\[ \\cdot: V\\times V\\rightarrow R \\] 则 \\(V\\) 是一个内积空间. 定义了内积后, 我们可以讨论向量 (即线性空间的元素) 间的长度和夹角, 并进一步讨论正交性等. 注意: 内积本身具有自然定义的范数, 即内积可以诱导出范数, \\(||x||=\\), 因此内积空间含于赋范空间. 度量空间 度量空间是某个具有距离函数的集合. 该函数定义的是集合内所有元素的距离, 即集合上的某种度量, 即: 给定集合\\(V\\), 有映射: \\[ d:V\\times V\\rightarrow \\mathbf{R} \\] 满足: [ \\[\\begin{aligned} &amp;d(x,y)\\geq0\\quad (d(x,y)=0\\Leftrightarrow x=0,y=0)\\\\ &amp;d(x,y)=d(y,x)\\\\ &amp;d(x,y)\\leq d(x,z)+d(z,y) \\end{aligned}\\] ] 注意: 此处并未要求线性结构. 注意: 赋范空间一定可以诱导出度量空间, 因此赋范空间含于度量空间 完备空间 完备空间又称 Cauchy 空间. 完备空间是定义在度量空间之上的. 若度量空间 \\(M\\) 中所有的柯西序列都收敛在 \\(M\\) 中的一点, 则 \\(M\\) 是一个完备空间. Hilbert空间 在内积空间的基础上增添完备性条件, 即得到Hilbert空间. 总结 范数运算+向量空间=(线性)赋范空间 (线性)赋范空间 + 内积运算=内积空间 (线性)赋范空间 + 完备性 = Banach 空间 内积空间 + 完备性 = Hilbert 空间 内积空间 + 完备性 + 有限维 = Euclidean 空间 References zhihu: https://www.zhihu.com/question/332144499/answer/731866608 https://www.zhihu.com/question/42312263/answer/699451330 wikipedia: https://en.wikipedia.org/wiki/Complete_metric_space https://en.wikipedia.org/wiki/Metric_space https://en.wikipedia.org/wiki/Cauchy_sequence https://en.wikipedia.org/wiki/Cauchy_sequence https://en.wikipedia.org/wiki/Cauchy_sequence https://en.wikipedia.org/wiki/Normed_vector_space","categories":[{"name":"Math","slug":"Math","permalink":"https://andrew-rey.github.io/categories/Math/"}],"tags":[]},{"title":"Pattern Recognition","slug":"ML/PatternRecognition","date":"2022-02-27T16:00:00.000Z","updated":"2022-11-23T11:12:45.976Z","comments":true,"path":"2022/02/28/ML/PatternRecognition/","link":"","permalink":"https://andrew-rey.github.io/2022/02/28/ML/PatternRecognition/","excerpt":"\"This is really a great lesson.\" \"If there are no such many homework.\"","text":"\"This is really a great lesson.\" \"If there are no such many homework.\" Introduction What is Patter Recognition? Pattern the opposite of choas Recognition Identification of a pattern as a member of a category Classification: category known \\(\\Rightarrow\\) assign proper class label for each pattern Clustering: category unknown \\(\\Rightarrow\\) learn categories and group patterns Pattern Recognition Perceive (理解): interact with the real-world Process (处理): learn to distinguish patterns of interest Prediction (预测): make sound and reasonable decisions about the categories preview:three classification ideas estimate the class conditional function estimate the posterior calculate the discriminant function directly Bayesian Decision Theory Basic Theory Bayesian Formula \\[ P(\\omega_i | \\mathbf{x}) = \\frac{P(\\omega_i)p(\\mathbf{x} | \\omega_i)}{p(\\mathbf{x})} \\] Where \\(\\omega_i(i = 1,\\dots, c)\\) is the category of research object. \\(\\mathbf{x}\\) is the feature vector, has \\(d\\) dimensions. We call \\(P(\\omega_i | \\mathbf{x})\\) posterior, \\(P(\\omega_i)\\) prior probability and \\(p(\\mathbf{x} | \\omega_i)\\) likelihood of \\(\\mathbf{x}\\) in category \\(\\omega_i\\). Note that \\(p(\\omega{x})\\) is a constant, we call it evidence coefficient. \\[ p(\\mathbf{x}) = \\sum_{i = 1}^c P(\\omega_i)p(\\mathbf{x} | \\omega_i) \\] Loss function We use \\[ \\lambda(\\alpha_i | \\omega_j) \\] to describe the loss or penetrate we get since we take action \\(\\alpha_i\\) while the true category is \\(\\omega_j\\). Class-Conditional Probability We define the class conditional probability relative to the action \\(\\alpha_i\\) \\[ R(\\alpha_i | \\mathbf{x}) = \\sum_{j=1}^c \\lambda(\\alpha_i | \\omega_j) P(\\omega_j | \\mathbf{x}) \\] So the total risk is defined as: \\[ R = \\int_{feature\\ space} R(\\alpha_i | \\mathbf{x}) p(\\mathbf{x}) d\\mathbf{x} \\] The Decision Theory Bayesian Decision Theory: In order to minimize the total risk \\(R\\), for \\(i = 1, \\dots, a\\) we calculate the class-conditional probability \\[ R(\\alpha_i | \\mathbf{x}) = \\sum_{j=1}^c \\lambda(\\alpha_i | \\omega_j) p(\\omega_j | \\mathbf{x}) \\] and choose a proper action \\(\\alpha_i\\) to make the \\(R(\\alpha_i | \\mathbf{x})\\) minimized. Two-class classification The loss function is \\[ \\lambda_{ij} \\doteq \\lambda(\\alpha_i | \\omega_j) \\] And our class conditional function are: \\[ \\begin{aligned} R(\\alpha_1 | \\mathbf{x}) &amp;= \\lambda_{11} p(\\omega_1 | \\mathbf{x}) + \\lambda_{12} p(\\omega_2 | \\mathbf{x})\\\\ R(\\alpha_2 | \\mathbf{x}) &amp;= \\lambda_{21} p(\\omega_1 | \\mathbf{x}) + \\lambda_{22} p(\\omega_2 | \\mathbf{x}) \\end{aligned} \\] The decision is: if \\(R(\\alpha_1 | \\mathbf{x}) &lt; R(\\alpha_2 | \\mathbf{x})\\), then it means \\(\\alpha_1\\) takes smaller risk, and so we choose the action \\(\\alpha_1\\). Using the posterior probability to describe is: \\[ (\\lambda_{21} - \\lambda_{11})P(\\omega_1 | \\mathbf{x}) &gt; (\\lambda_{12} - \\lambda_{22})P(\\omega_2 | \\mathbf{x}) \\] Using the Bayes' Formula, converting the prior probability to posterior probability: \\[ (\\lambda_{21} - \\lambda_{11})p(\\mathbf{x} | \\omega_1)P(\\omega_1) &gt; (\\lambda_{12} - \\lambda_{22})p(\\mathbf{x} | \\omega_2)P(\\omega_2) \\] Or writing with fraction form: \\[ \\frac{p(\\mathbf{x} | \\omega_1)}{p(\\mathbf{x} | \\omega_2)} &gt; \\frac{\\lambda_{12} - \\lambda_{22}}{\\lambda_{21} - \\lambda_{11}}\\frac{P(\\omega_2)}{P(\\omega_1)} \\] The Minimum-error Classification We define the minimum-error classification is a problem that uses the symmetric loss or \"0-1\" loss: \\[ \\lambda(\\alpha_i | \\omega_j) = \\left\\{\\begin{aligned} &amp;0&amp;\\ &amp;i=j,\\\\ &amp;1&amp;\\ &amp;i\\neq j \\end{aligned}\\right.\\ \\ \\ i,j = 1,\\dots,c \\] If you use this symmetric loss in a classification problem, you mean all the error decisions make the same consequence. Our decision is made based on conditional risk: \\[ \\begin{aligned} R(\\alpha_i | \\omega_j) &amp;= \\sum_{j = 1}^c \\lambda_{ij} P(\\omega_j | \\mathbf{x})\\\\ &amp;= \\sum_{i\\neq j} 1 \\cdot P(\\omega_j | \\mathbf{x})\\\\ &amp;= 1 - P(\\omega_i | \\mathbf{x}) \\end{aligned} \\] Minimax Rule I will not write this part until I make it clear... The Discriminant Function, Decision Surface Based on Gaussian Distribution Gaussian Distribution \\[ \\begin{aligned} \\varphi(\\mathbf{x}) = \\frac{1}{(2\\pi)^{\\frac{d}{2}}|\\Sigma|^{\\frac{1}{2}}}exp(-\\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu})^T\\Sigma^{-1}(\\mathbf{x} - \\mathbf{\\mu})) \\end{aligned} \\] Discriminant Function The discriminant function is defined as: we choose \\(i^{th}\\) class, if \\[ g_i(x)&gt;g_j(x) \\] for \\(\\forall j\\neq i\\). And \\(g_i(x)\\) is called discriminant function. Based on minimum-error classification, the discriminant function can be written as: \\[ \\begin{aligned} g_i(x)&amp;=-P(\\omega_i|x) \\\\ &amp;=P(\\omega_i|x) \\\\ &amp;=p(x|\\omega_i)P(\\omega_i)\\ (Bayes&#39; Formula) \\\\ &amp;=lnp(x|\\omega_i)+lnP(\\omega_i) \\end{aligned} \\] where the \"=\" means \"equivalent\" or \"the same to\". Specially, if it's a two-class classification: \\[ g(x)=g_1(x)-g_2(x) \\] or \\[ g(x)=P(\\omega_1|x)-P(\\omega_2|x) \\] or \\[ g(x)=ln\\frac{p(x|\\omega_1)}{p(x|\\omega_2)}+ln\\frac{P(\\omega_1)}{P(\\omega_2)} \\] Correspondingly, we have decision boundary and decision region. Minimum total risk based on Gaussian distribution: Discriminant Function, Discriminant Boundary On this section, we discuss the situation that the likelihood submits Gaussian distribution and the loss is \"0-1\" loss. \\[ p(x|\\omega_i)=\\frac{1}{(2\\pi)^{d/2} |\\Sigma_i| ^ {1/2}}exp(-\\frac{1}{2}(x-\\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i)) \\] \\[ \\lambda(\\alpha_i|\\omega_j) = I(i\\neq j) \\] \\[ g_i(x)=lnp(x|\\omega_i)+lnP(\\omega_i)=-\\frac{1}{2}(x-\\mu_i)^T \\Sigma_i^{-1}(x-\\mu_i)-\\frac{d}{2}ln2\\pi-\\frac{1}{2}ln|\\Sigma|+lnP(\\omega_i) \\] Minimum distance classifier case 1a: suppose all prior probabilities are the same \\[ P(\\omega_i)=1/c\\ \\ \\forall i \\in (1,c) \\] and all features have no relationships with others and all classes have the same covariance matrices \\[ \\Sigma_i=\\sigma^2I\\ \\ \\forall i \\in (1,c) \\] Discriminant function: \\[ \\begin{aligned} g_i(x)&amp;=-\\frac{1}{2}(x-\\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i)+constant \\\\ g_i(x)&amp;=-\\frac{1}{2\\sigma^2}(x-\\mu_i)^T(x-\\mu_i)\\ \\ \\ (Euclidean\\ distance) \\\\ g_i(x)&amp;=-\\frac{1}{2\\sigma^2}(x^Tx-2\\mu_i^Tx+\\mu_i^T\\mu_i) \\\\ \\end{aligned} \\] \\(x^Tx\\) is independent with \\(\\forall i\\), so \\(x^Tx\\) is a constant when considering \\(i\\). \\[ g_i(x)=\\frac{1}{\\sigma^2}\\mu_i^Tx-\\frac{1}{2\\sigma^2}\\mu_i^T\\mu_i \\] this is a linear discriminant machine. Discriminant boundary: \\[ g_i=g_j \\] \\[ \\begin{aligned} &amp;\\frac{1}{\\sigma^2}\\mu_i^Tx-\\frac{1}{2\\sigma^2}\\mu_i^T\\mu_i= \\frac{1}{\\sigma^2}\\mu_j^Tx-\\frac{1}{2\\sigma^2}\\mu_j^T\\mu_j \\\\ &amp;\\frac{1}{\\sigma^2}(\\mu_i^T-\\mu_j^T)x - \\frac{1}{2\\sigma^2}(\\mu_i^T + \\mu_j^T)(\\mu_i - \\mu_j)=0 \\\\ &amp;\\frac{1}{\\sigma^2}(\\mu_i-\\mu_j)^T(x-\\frac{1}{2}(\\mu_i + \\mu_j)) =0 \\\\ \\end{aligned} \\] so the discriminant boundary must pass the point \\(x=\\frac{1}{2}(\\mu_i + \\mu_j)\\), and is vertical with \\((\\mu_i-\\mu_j)\\) case 1b: suppose all prior probabilities are the same: \\[ P_i=1/c \\] and all covariance are the same, but features have relationships with each other: \\[ \\Sigma_i=\\Sigma \\] Discriminant function: \\[ \\begin{aligned} &amp;g_i(x)=-\\frac{1}{2}(x-\\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i)-\\frac{1}{2}ln|\\Sigma_i|+constant \\\\ &amp;g_i(x)=-\\frac{1}{2}(x-\\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i)-\\frac{1}{2}ln|\\Sigma| \\\\ &amp;g_i(x)=-\\frac{1}{2}(x-\\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i)\\ \\ \\ (Mahalanobis\\ distance) \\\\ &amp;g_i(x)=2\\mu_i^T\\Sigma^{-1}x-\\mu_i^T\\Sigma^{-1}\\mu_i \\\\ \\end{aligned} \\] this is also a linear discriminant machine. Discriminant boundary: \\[ (\\Sigma^{-1}(\\mu_i-\\mu_j))^T(x-\\frac{\\mu_i+\\mu_j}{2})=0 \\] the boundary crosses the middle point of \\(\\mu_i\\) and \\(\\mu_j\\), but is not vertical with \\(\\mu_i-\\mu_j\\) as \\(\\Sigma\\) provides a rotation with \\(\\mu_i-\\mu_j\\). case 2a: suppose \\(P(\\omega_i)\\) are not the same, while all features have no relationships with others and all classes have the same covariance matrices \\[ \\Sigma_i=\\sigma^2I\\ \\ \\forall i \\in (1,c) \\] Discriminant function: \\[ g_i(x)=2\\mu_i^Tx-\\mu_i^T\\mu_i+2\\sigma^2lnP(\\omega_i) \\] this is a linear discriminant machine Discriminant boundary: \\[ (\\mu_i-\\mu_j)^T(x-\\frac{\\mu_i+\\mu_j}{2}-\\frac{\\sigma^2}{||\\mu_i-\\mu_j||^2}ln\\frac{P(\\omega_i)}{P(\\omega_j)}(\\mu_i-\\mu_j)) \\] if \\(P(\\omega_i)&gt;P(\\omega_j)\\), then \\[ \\frac{\\sigma^2}{||\\mu_i-\\mu_j||^2}ln\\frac{P(\\omega_i)}{P(\\omega_j)}(\\mu_i-\\mu_j))&gt;0 \\] , it will cross a point that is closer to \\(\\mu_j\\). case 2b: suppose \\(P(\\omega_i)\\) are not the same, while covariance are the same, but features have relationships with each other: \\[ \\Sigma_i=\\Sigma \\] Discriminant function: \\[ g_i(x)=(\\Sigma\\mu_i)^Tx-\\frac{1}{2}\\mu_i^T\\Sigma^{-1}\\mu_i+lnP(\\omega_i) \\] this is a linear discriminant machine Discriminant boundary: \\[ (\\Sigma(\\mu_i-\\mu_j))^T(x-\\frac{1}{2}(\\mu_i+\\mu_j)-\\frac{ln[P(\\omega_i)/P(\\omega_j)]}{(\\mu_i-\\mu_j)^T\\Sigma(\\mu_i-\\mu_j)}(\\mu_i-\\mu_j)) \\] case 3: suppose that \\(P(\\omega_i)\\) are not the same as well as covariance matrices, then the discriminant function is a quadric function. The discriminant boundary will be more various. Maximum Likelihood estimation and Bayesian estimation In the chapter 2, we suppose the likelihood function \\(p(x|\\omega)\\) is known, but it impossible to know about it in the daily life or experiments, so we must estimate the likelihood function. Generally speaking, we have two methods to solve this problem: the one is parameter estimation and the other is non-parameter estimation. In parameter estimation, we will give a prior model of likelihood function of \\(x\\) with unknown parameters, and what we should do is estimating the parameters using the data set. Maximum Likelihood estimation Use the parameterized form of class-conditional density function (likelihood): \\[ p(x|\\omega_i, \\theta_i) \\] As we solve all classes' parameters respectively, we can simplify the denotation as: \\[ P(D|\\theta) \\] where \\(D\\) means the data set of class \\(\\omega_i\\). samples are i.i.d: \\[ p(D|\\theta_i)=\\prod_{k=1}^n p(x_k|\\theta) \\] and the ML estimation method asks we to find a suitable \\(\\theta\\) to maximize \\(p(D|\\theta)\\), which means: \\[ \\theta = argmax_{\\theta} p(D|\\theta) \\] if we know \\(\\theta\\), we will know \\(p(x|\\omega_i,\\theta_i)\\)(just to traverse all categories and calculate \\(\\theta_i\\)), and then we can train classifiers based on Bayesian decision thm. So how to solve \\(\\theta = argmax_{\\theta} p(D|\\theta)\\): log-likelihood function: \\[ \\ell(\\theta)=\\sum_{k=1}^n lnp(x_k|\\theta) \\] maximizing \\(p(D|\\theta)\\) is the same with maximizing log-likelihood. So, calculate the gradient of \\(\\theta\\): \\[ \\frac{\\partial}{\\partial \\theta}\\ell(\\theta) \\] we will discuss the Gaussian situation: ML Gaussian Case: \\(\\mu\\) is unknown As \\(\\Sigma\\) is know, so \\[ \\theta=\\mu \\] \\[ \\begin{aligned} \\ell(\\theta)&amp;=\\sum_{k=1}^n lnp(x_k|\\theta) \\\\ &amp;=\\sum_{k=1}^n -\\frac{1}{2}(x_k-\\mu)^T\\Sigma^{-1}(x_k-\\mu)-ln(2\\pi)^{d/2}|\\Sigma|^{1/2} \\\\ \\end{aligned} \\] Gradient: \\[ \\begin{aligned} \\ell^{\\prime}(\\theta)&amp;=\\sum_{k=1}^n 2\\Sigma^{-1}x_k-2\\Sigma^{-1}\\mu \\\\ \\end{aligned} \\] let \\[ \\ell(\\theta)=0 \\] we get: \\[ \\hat{\\mu} = \\frac{1}{n}\\sum_{k=1}^n x_k \\] ML Gaussian Case: \\(\\mu\\) and \\(\\Sigma\\) are unknown for only one feature (1-dim case): we have: \\[ \\hat{\\mu} = \\frac{1}{n}\\sum_{k=1}^n x_k \\] and \\[ \\hat{\\Sigma} = \\hat{\\sigma} = \\frac{1}{n}\\sum_{k=1}^n(x_k-\\hat{\\mu})^2 \\] for multi-feature (multi-dim case): \\[ \\hat{\\mu} = \\frac{1}{n}\\sum_{k=1}^n x_k \\] \\[ \\hat{\\Sigma} = \\frac{1}{n}\\sum_{k=1}^n(x_k-\\hat{\\mu})(x_k-\\hat{\\mu})^T \\] \\(\\hat{\\mu}\\) is unbiased estimation, \\(\\hat{\\Sigma}\\) is not. But \\(\\frac{n}{n-1}\\hat{\\Sigma}\\) is unbiased estimation. Bayesian estimation We suppose our parameter \\(\\theta\\) submits to a prior distribution, and our goal is to estimation \\(\\theta\\)'s distribution with given data set and prior distribution. Some notions: prior probability \\(P(\\theta)\\) posterior \\(p(\\theta|D)\\) likelihood \\(p(x|D)(i.e.p(x|\\omega))\\) Two important relations: \\[ p(x|D) = \\int p(x,\\theta|D)d\\theta = \\int p(x|\\theta)p(\\theta|D)d\\theta\\qquad(1) \\] \\[ \\begin{aligned} p(\\theta|D)&amp;=\\frac{p(D|\\theta)P(\\theta)}{\\int p(D|\\theta)P(\\theta)d\\theta} \\\\ &amp;=\\alpha p(D|\\theta)P(\\theta) \\\\ &amp;=\\alpha\\prod_{k=1}^n p(x_k|\\theta)P(\\theta)\\qquad(2) \\end{aligned} \\] Ongoing update...","categories":[{"name":"ML","slug":"ML","permalink":"https://andrew-rey.github.io/categories/ML/"}],"tags":[]},{"title":"BabyBlog","slug":"Life/BabyBlog","date":"2022-01-11T01:09:04.000Z","updated":"2022-11-23T11:12:45.975Z","comments":true,"path":"2022/01/11/Life/BabyBlog/","link":"","permalink":"https://andrew-rey.github.io/2022/01/11/Life/BabyBlog/","excerpt":"Finished! My First Blog! After a long time deploying my blog webpage and a lot of other borthering settings, I finally finished it! I mean, FINALLY!!! :laughing: :laughing: :laughing:","text":"Finished! My First Blog! After a long time deploying my blog webpage and a lot of other borthering settings, I finally finished it! I mean, FINALLY!!! :laughing: :laughing: :laughing: Original Intention Can a programmer has no personal blog? I have seen many blogers writing their own blogs no metter answering a question or just taking notes from time to time on websites such as zhihu and csdn, but among which I prefer is to establish a personal website where I can put my blogs on. So, at first I have no intention about what to do with my site, maybe I just feel that it's really cool to have such a lovely home for oneself to \"lie down and rest\". But when it was finally established by myself, experencing a lot of confusing problems and taking amount of time to debug, I must to say that, I love here, and I believe I will take after it like taking after a baby, a baby who are growing up. :blush: Thanks I would not finish my work without the help of JerryYang, whose helpful blog is the guidance of mine (though there are still some mistakes maybe? :dizzy_face:). Based on it, I have known some basic command with Linux, Git and Github, which is also beneficial for my lessons next term. Except him I want to link some videos there to thank for another ups from bilibili: using hexo to start blog how to writing blogs","categories":[{"name":"Life","slug":"Life","permalink":"https://andrew-rey.github.io/categories/Life/"}],"tags":[]}],"categories":[{"name":"CS","slug":"CS","permalink":"https://andrew-rey.github.io/categories/CS/"},{"name":"Life","slug":"Life","permalink":"https://andrew-rey.github.io/categories/Life/"},{"name":"Android","slug":"Android","permalink":"https://andrew-rey.github.io/categories/Android/"},{"name":"ML","slug":"ML","permalink":"https://andrew-rey.github.io/categories/ML/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://andrew-rey.github.io/categories/Algorithm/"},{"name":"Math","slug":"Math","permalink":"https://andrew-rey.github.io/categories/Math/"}],"tags":[]}