[{"title":"Compiler | Polyhedral Compilation-1","url":"/2024/04/09/Compiler/poly_intro/","content":"\r\n","categories":["Compiler"],"tags":["Compiler"]},{"title":"HPC | Introduction to Parallel Computation","url":"/2024/04/09/HPC/intro/","content":"Parallel Programming: Concepts and Pracitce - Chapter 1\r\n\r\n概念\r\n加速比\r\nSpeedup：衡量一个并行算法比串行算法快多少的指标。即使用单个处理器运行程序所花费的时间\r\n 与使用  个处理器运行程序所花费的时间  之比\r\n\r\n通常我们希望得到的加速比为线性加速比，即用  个处理器去运行程序，最大的加速比为\r\n\r\n效率\r\nEfficiency：定义为加速比和处理器数目之比，衡量了平均一个处理器带来的加速比。当效率为\r\n 时，此时为线性加速比\r\n\r\n可扩展性\r\nScalability：分为强可扩展性和弱可扩展性。\r\n\r\n强可扩展性 Strong\r\nScalability：测量效率时仅改变处理器的数目，输入数据的规模保持不变\r\n弱可扩展性 Weak\r\nScalability：处理器的数目随着输入数据规模共同变化（处理器数目翻倍时，测量效率时把数据规模也翻倍）\r\n\r\n计算通信比 Computation-to-communication\r\nRatio：定义为计算花费的时间和处理器间处理消息通信花费的时间之比。\r\n分布式内存系统：每个计算单元只能访问自己的本地内存，如果需要访问其它单元，需要通过一个显式的通信步骤（例如通信网络）实现。\r\n共享式内存系统：所有计算单元共享内存，除此之外，自己本身也有更小的内存（分级缓存）。\r\n并行程序设计时需要考虑划分（数据并行、任务并行、模型并行）、通信、同步和负载平衡等。\r\n求和的例子\r\n现在我们进行一组数据的加法求和操作，其中数据量为  ，处理器数量为  。设 \r\n为一次加法操作所需要的时长，  为一批数据的通信时长。则\r\n\r\n数据分发次数：\r\n每个处理器本地求和：\r\n每个处理器将结果传递给一个处理器（数据收集）：\r\n中间结果求和：\r\n\r\n总的求和运行时长为\r\n\r\n其加速比为\r\n\r\n对于固定的 ，加速比只与计算通信比 \r\n有关，并且有\r\n\r\n因此在固定数据规模和处理器数量时，要提高加速比，需要降低计算通信比。同时，加速比也可以是处理器数量的函数：\r\n\r\n令偏导为 ，解出最值条件 \r\n综上所述，有如下规律：\r\n\r\n当数据规模固定时，加速比依赖于采用的计算单元的数目和计算通信比\r\n\r\n通常情况下，加速比随着计算单元的增加达到局部最大，但使用更多计算单元时，加速比会降低\r\n最优的加速比依赖于计算通信比，通信时长占比越大，使用的计算单元数目应该越少\r\n\r\n\r\n前缀和的例子\r\n前缀和问题：现有  个数据和\r\n 个计算结点\r\n\r\n输入：一个二元可结合运算符 ； 个待运算的数据 \r\n输出： 个数据 ，其中对于 \r\n\r\n由于计算  需要依赖 ，在循环分析时带来了一定的困难，但该问题依然有并行的方式。\r\n\r\n数据划分：使用 分治 策略，将  个数据按顺序均分为  份，分别分给 \r\n个计算结点，每个结点计算本地内存的前缀和，花费的时间为 \r\n数据归并：递归\r\n合并相邻的结点数据，即左边结点将前缀和的 最后一个结果\r\n返回，传递给右边结点，右边结点接收左边的前缀和，并将其与自己结点结果求和\r\n所有线程将结果返回，计算完成\r\n\r\n\r\n\r\nperfix sum\r\n\r\n前缀和问题将在后续进行更加详细的讨论。\r\n","categories":["HPC"],"tags":["HPC"]},{"title":"HPC | Theory Backgroud","url":"/2024/04/11/HPC/theory/","content":"首先介绍并行随机访问机器（PRAM）模型是抽象的共享内存模型，其忽略了现实计算机中的开销，但可以帮助设计一些并行算法。其次是对于分布式内存模型，会介绍一些基础图论知识。接着介绍并行程序中的两大定律：Amdahl定律和Gustafson定律，用于推断并行程序加速比能达到的上限。最后以并行算法设计的Foster方法论结束。\r\n并行随机访问机器模型\r\n事实上，PRAM (Parallel Random Access Machine)\r\n模型架构十分简单，相比于操作系统课上的一个处理器而言，PRAM拥有多个独立的处理器，每个处理器分3个阶段执行一个指令周期：\r\n\r\n读阶段：每个处理器并发地从各自的共享内存中读取单条数据并保存到本地的寄存器中。\r\n计算阶段：每个处理器对本地数据执行一个基本操作，并将结果存储在寄存器中。\r\n写阶段：每个处理器并发写一条数据到共享内存中。\r\n\r\nPRAM中的通信通过处理器在共享内存中的读写实现，该类型的内存能够以统一的方式访问，即每个处理器对内存中任意位置的访问都使用统一的常数时间实现，这和现实计算机很不一样（访问大规模共享内存时耗费的时间不一致）。\r\nPRAM的变体\r\n在相同的指令中期中，多个处理器读写多个共享内存单元会发生冲突，为解决冲突，出现了如下的几种PRAM变体：ER\r\n(exclusive read)，EW (exclusive write)，CR (concurrent read)，CW\r\n(concurrent write)。常见的组合有三种：\r\n\r\nEREW：独占读、独占写。任意周期内，不允许多个处理器在相同的共享内存单元中进行读写。\r\nCREW：并发读、独占写。\r\nCRCW：并发读、并发写。对于并发写入，有常见的数据保留形式：\r\n\r\nPriority: 处理器本身的优先级决定\r\nArbitrary: 随机选取一个处理器的值写入\r\nCommon: 若所有的值都相等则写入，否则内存位置的值不变\r\nCombining: 通过某种运算组合所有的冲突值再写入\r\n\r\n\r\nPRAM上的前缀和算法\r\n问题描述：给定 \r\n个数据，和一个该数据的二元运算符，假设为加法运算。在一台拥有  个计算结点的PRAM上，并行计算前缀和。\r\n其中数据已经存储在了共享内存 A 中，每个计算结点的寄存器用\r\nreg 表示，目标是设计一个开销最优化的PRAM算法。\r\n串行分析：使用一个计算结点求解前缀和问题\r\nfor (int i = 1; i &lt; n; i += 1) A[i] += A[i-1];\r\n计算复杂度为 \r\n。\r\n并行分析：使用  个计算结点并行求解前缀和问题\r\n当 \r\n时，计算结点的数量和数据量相等，每个计算结点上处理一个数据。\r\n可以使用分治递归的方式，将计算结点逐一合并。\r\n//-- 算法 1 --//// load data for every node@parallelfor (int i = 0; i &lt; p; i += 1) {    reg[i] = A[i];}// total iteration num, merge by 2for (int i = 0; i &lt; ceil(log(p)); i += 1) {    // the left nodes have been calculated    int node_start_idx = pow(2, i);    @parallel    for (int j = node_start_idx; j &lt; p; j += 1) {        reg[j] += A[j - node_start_idx];        A[j] = reg[j];    }}\r\n总体的计算结构类似于二叉树：每一个结点都与左边相邻结点进行计算前缀和，第\r\n 次迭代中，每  个结点视为一个 merge 的结点，\r\n因此一共需要  次递归，即花费的时间为 ， 开销为\r\n，是对数线性的。\r\n如果需要继续减小开销 ，则要么减小 ，要么减小 ，降低运行时间比较困难，因此选择减少计算结点的数量\r\n，即  方法如下\r\n\r\n我们有  个计算结点，先将\r\n\r\n个数据均分到每个计算结点上，每个结点有  个数据\r\n每个计算结点对本地内存的数据求解前缀和，花费的时间为 \r\n每个结点返回本地前缀和的最后一位结果，得到一共  个数据\r\n对上述 \r\n个数据执行算法1，花费的时间为 ，计算完成后依然得到长度为  的前缀和 A_p\r\n将第4步得到的前缀和 A_p[j]，依次加到\r\nreg[j+1] 上，A_p\r\n的最后一位不用加，由于每个结点有  个数据，因此花费的时间为 \r\n\r\n综上所述，整个算法的时间为 ，开销为 ，\r\n当 \r\n时，计算时间为对数，且开销为线性的。\r\n//-- 算法 2 --//// stage 1-3// calculate prefix sum for every node// each node contains k = n/p = log(n) datak = n/p = log(n)@parallelfor (int i = 0; i &lt; p; i += 1) {    for (int j = 1; j &lt; k; j += 1) {        // data index: i * num + offsets        A[i*k+j] += A[i*k+j-1]    }}// stage 4// calculate prefix sum for rightmost values of every nodefor (int i = 0; i &lt; log(p); i += 1) {    int node_start_idx = pow(2, i);    @parallel    for (int j = node_start_idx + 1; j &lt; p; j += 1) {        A[j*k-1] += A[(j - node_start_idx)*k-1]    }}// stage 5// add results@parallelfor (int i = 1; i &lt; p; i += 1) {    // ignore the last value    for (int j = 0; j &lt; k-1; j += 1) {        A[i*k+j] += A[i*k-1]    }}\r\nPRAM上的稀疏矩阵压缩算法\r\n稀疏矩阵压缩算法可以利用前缀和算法。\r\n问题描述：稀疏数组 A 中多个元素为 ，希望能通过并行算法压缩为非零数组\r\nV 和对应的位置数组 C。\r\n\r\n构造和 A 等长的临时数组 temp，其中若\r\ntemp[i] = 1 if A[i]!=0 else temp[i]=0， 将数组\r\nA 和临时数组 temp 均分到 \r\n个计算结点上，并行生成临时数组和计算临时数组的前缀和\r\n求完前缀和的临时数组目前可以作为稀疏数组的\r\n地址列表，接下来根据临时数组，并行索引 A\r\n中对应地址，得到非零值和位置，写入 V,C 即可\r\n\r\n分析：\r\n网络拓扑\r\n互联网络的结点可能是交换机或处理器。几个概念：\r\n\r\n度(degree)：网络的度表示所有结点中邻居数目的最大值\r\n对分宽度(bw)：将网络分为二分图，两个分图间边的最小值\r\n直径(diam)：任意两个结点之间全部最短路径的最大值\r\n\r\n在设计互联网络时，经常关注以下 理想属性：\r\n\r\n常数度：网络的度是常数，即与网络的规模无关。这个属性允许网络扩大到更大的规模而无需增加过多的连接数\r\n小直径：可以支持任意进程之间的高效通信\r\n高对分宽度：对分宽度越低，大量聚合的通信操作会变得更慢，它隐含的是网络的内部带宽\r\n\r\n经典网络拓扑结构各属性的阶：\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\ntopology\r\ndegree\r\ndiam\r\nbw\r\n\r\n\r\n\r\n\r\n线性排列\r\n\r\n\r\n\r\n\r\n\r\n2D网面/环面\r\n\r\n\r\n\r\n\r\n\r\n3D网面/环面\r\n\r\n\r\n\r\n\r\n\r\n二叉树\r\n\r\n\r\n\r\n\r\n\r\n超立方体\r\n\r\n\r\n\r\n\r\n\r\n\r\n","categories":["HPC"],"tags":["HPC"]}]