<!DOCTYPE html>


  <html class="light page-post">


<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>DeepLearning | Image Semantic Segmentation based on UNet | Andrew-Rey</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="CS,Deep Learning," />
  

  <meta name="description" content="&quot;Semantic segmentation of images, use UNet model.&quot;">
<meta property="og:type" content="article">
<meta property="og:title" content="DeepLearning | Image Semantic Segmentation based on UNet">
<meta property="og:url" content="https://andrew-rey.github.io/2022/08/21/ML/UNet/index.html">
<meta property="og:site_name" content="Andrew-Rey">
<meta property="og:description" content="&quot;Semantic segmentation of images, use UNet model.&quot;">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://andrew-rey.github.io/2022/08/21/ML/UNet/unet-structure.png">
<meta property="og:image" content="https://andrew-rey.github.io/2022/08/21/ML/UNet/pic1-unet.png">
<meta property="og:image" content="https://andrew-rey.github.io/2022/08/21/ML/UNet/nested.png">
<meta property="og:image" content="https://andrew-rey.github.io/2022/08/21/ML/UNet/unet_loss.png">
<meta property="og:image" content="https://andrew-rey.github.io/2022/08/21/ML/UNet/unet_acc.png">
<meta property="og:image" content="https://andrew-rey.github.io/2022/08/21/ML/UNet/nested_loss.png">
<meta property="og:image" content="https://andrew-rey.github.io/2022/08/21/ML/UNet/nested_acc.png">
<meta property="article:published_time" content="2022-08-21T02:50:30.000Z">
<meta property="article:modified_time" content="2023-11-11T12:52:26.884Z">
<meta property="article:tag" content="CS">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://andrew-rey.github.io/2022/08/21/ML/UNet/unet-structure.png">

  

  
    <link rel="icon" href="/images/head_round.png">
  

  <link href="/css/styles.css?v=c114cbeddx" rel="stylesheet">


  
    
<link rel="stylesheet" href="/css/site.css">

  

  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-38189205-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?57e94d016e201fba3603a8a2b0263af0";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  
  <script type="text/javascript">
	(function(){
	    var bp = document.createElement('script');
	    var curProtocol = window.location.protocol.split(':')[0];
	    if (curProtocol === 'https') {
	        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
	    }
	    else {
	        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
	    }
	    var s = document.getElementsByTagName("script")[0];
	    s.parentNode.insertBefore(bp, s);
	})();
  </script>



  
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body>


  
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><span id="toolbox-mobile" class="toolbox-mobile">ðŸŒˆ</span>
  

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css"/>
<link rel="stylesheet" href="/css/prism.css">

<div class="post-header CENTER">
   
  <div class="toolbox">
    <a class="toolbox-entry" href="/">
      <span class="toolbox-entry-text">ðŸŒˆ</span>
      <i class="icon-angle-down"></i>
      <i class="icon-home"></i>
    </a>
    <ul class="list-toolbox">
      
        <li class="item-toolbox">
          <a
            class="ROUND_RECT"
            href="/archives/"
            rel="noopener noreferrer"
            target="_self"
            >
            Archives
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="ROUND_RECT"
            href="/categories/"
            rel="noopener noreferrer"
            target="_self"
            >
            Categories
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="ROUND_RECT"
            href="/tags/"
            rel="noopener noreferrer"
            target="_self"
            >
            Tags
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="ROUND_RECT"
            href="/about/"
            rel="noopener noreferrer"
            target="_self"
            >
            About
          </a>
        </li>
      
    </ul>
  </div>


</div>


  <div id="toc" class="toc-article">
    <strong class="toc-title">Posts List</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#unet-structure"><span class="toc-text">UNet Structure</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#operator-definitions"><span class="toc-text">Operator Definitions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#network-definition"><span class="toc-text">Network Definition</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#code"><span class="toc-text">Code</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#result"><span class="toc-text">Result</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#former-model"><span class="toc-text">Former Model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#model-upgrade"><span class="toc-text">Model Upgrade</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#analysis"><span class="toc-text">Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#u-net"><span class="toc-text">U-Net</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#nested-unet"><span class="toc-text">Nested UNet</span></a></li></ol></li></ol>
  </div>



<div class="content content-post CENTER">
   <article id="post-ML/UNet" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">DeepLearning | Image Semantic Segmentation based on UNet</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2022.08.21</span>
      </span>

      

      
  <span class="article-category">
    <i class="icon-list"></i>
    <a class="article-category-link" href="/categories/ML/">ML</a>
  </span>



      

      
      <i class="fa fa-eye"></i> 
        <span id="busuanzi_container_page_pv">
           &nbspçƒ­åº¦ <span id="busuanzi_value_page_pv">
           <i class="fa fa-spinner fa-spin"></i></span>â„ƒ
        </span>
      
      
    </div>
  </header>

  <div class="article-content">
    
      <p>"Semantic segmentation of images, use UNet model."</p>
<span id="more"></span>
<h1 id="abstract">Abstract</h1>
<p>In this project, we realize an basic UNet model and UNet++ model,
then we apply them on image semantic segmentation. We show our basic
theory of UNet and an improvement of it, and we provide main code of
this program. Finally, we give the result of segmentation images,
loss-curve and accuracy-curve on both training and validation set.</p>
<p>The copyright of this program is owned by our team mentioned on the
end of this blog.</p>
<h1 id="unet-structure">UNet Structure</h1>
<p>The <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1505.04597">paper</a> published in
2015 propose a noval network structure, whose shape is similar with the
captal "U". The idea comes from FCNN. U-Net is one of the classes of
"Encoder-Decoder" structure.</p>
<figure>
<img src="/2022/08/21/ML/UNet/unet-structure.png" alt="U-Net Structure">
<figcaption aria-hidden="true">U-Net Structure</figcaption>
</figure>
<p>The front half of the network is "encoder". The input image passes
covolutional kernel, and then passes the pooling layer (or other
dimension-decreasing layer). The opposite of that is the back part of
UNet, the "decoder". The input of decoder is a sequence of feature maps
with highly contracted pixels. The output of the decoder (or the whole
network) is an image with the same shape of input image, where each
pixel has its own class.</p>
<p>In this project, we decrease the number of convolutional layers so
that there are only two convolutional layers in each convolutional
kernel as the dataset includes images with shape <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="9.553ex" height="1.557ex" role="img" focusable="false" viewbox="0 -666 4222.4 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"/><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(1000,0)"/></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"/></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"/><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1000,0)"/></g></g></g></svg></mjx-container></span>.</p>
<h2 id="operator-definitions">Operator Definitions</h2>
<p><strong>Convolutional Kernel:</strong></p>
<p>We define the basic convolutional kernel as follow:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    <span class="token comment"># in_channel, out_channel, kernel_size, stride, padding</span>
    <span class="token comment"># batch size * channel * height * weight</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>C_in<span class="token punctuation">,</span> C_out<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 64 64 128 256</span>
    nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>C_out<span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>C_out<span class="token punctuation">,</span> C_out<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 64 64 128 256</span>
    nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>C_out<span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>It includes two convolution operations.</p>
<p><strong>Down Sampling Kernel:</strong></p>
<p>As for downsampling kernel, we replace conditional pooling layer to
convolutional layer with stride equaling to 2, which means the shape
will be shrunk to <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.781ex;" xmlns="http://www.w3.org/2000/svg" width="1.795ex" height="2.737ex" role="img" focusable="false" viewbox="0 -864.9 793.6 1209.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(220,394) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mn" transform="translate(220,-345) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/></g><rect width="553.6" height="60" x="120" y="220"/></g></g></g></svg></mjx-container></span> while
remaining the same channels.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>Down <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>C<span class="token punctuation">,</span> C<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 64 64 64 128</span>
    nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>Up Sampling Kernel:</strong></p>
<p>The basic structure of up-sampling contains only one convolutional
layer with <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="5.028ex" height="1.507ex" role="img" focusable="false" viewbox="0 -666 2222.4 666"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"/></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g></g></g></svg></mjx-container></span> convolutional
kernel size and half out-channel. The feature map should pass an
interpolation layer before getting into the convolutional layer.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>UpSampling<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># out-channel = 1/2 in-channel</span>
    self<span class="token punctuation">.</span>Up <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>C<span class="token punctuation">,</span> C <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> r<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># neighbor interpolation</span>
    up <span class="token operator">=</span> F<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span>x<span class="token punctuation">,</span> scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">"nearest"</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> self<span class="token punctuation">.</span>Up<span class="token punctuation">(</span>up<span class="token punctuation">)</span>
    <span class="token comment"># concatenate the feature map in encoder and </span>
    <span class="token comment"># the feature map in corrsponding decoder layer, in channel dimension</span>
    res <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> r<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> res<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>The interpolation mode we choose is "nearest". The function
<code>torch.cat(dim=1)</code> is used to concatenate two feature maps in
channel dimension.</p>
<h2 id="network-definition">Network Definition</h2>
<p>Based on the operators defined above, we link these blocks together
like UNet structure.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>UNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># down sampling</span>
    self<span class="token punctuation">.</span>C1 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>D1 <span class="token operator">=</span> DownSampling<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>C2 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>D2 <span class="token operator">=</span> DownSampling<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>C3 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>D3 <span class="token operator">=</span> DownSampling<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>C4 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>D4 <span class="token operator">=</span> DownSampling<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>C5 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span>

    <span class="token comment"># up sampling</span>
    self<span class="token punctuation">.</span>U1 <span class="token operator">=</span> UpSampling<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>C6 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>U2 <span class="token operator">=</span> UpSampling<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>C7 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>U3 <span class="token operator">=</span> UpSampling<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>C8 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>U4 <span class="token operator">=</span> UpSampling<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>C9 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>C10 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>pred <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>Th <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Like U-Net mentioned in that paper, we designed 4 layer deep
network.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># part 1: down sampling, decreasing dimension</span>
        R1 <span class="token operator">=</span> self<span class="token punctuation">.</span>C1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        R2 <span class="token operator">=</span> self<span class="token punctuation">.</span>C2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>D1<span class="token punctuation">(</span>R1<span class="token punctuation">)</span><span class="token punctuation">)</span>
        R3 <span class="token operator">=</span> self<span class="token punctuation">.</span>C3<span class="token punctuation">(</span>self<span class="token punctuation">.</span>D2<span class="token punctuation">(</span>R2<span class="token punctuation">)</span><span class="token punctuation">)</span>
        R4 <span class="token operator">=</span> self<span class="token punctuation">.</span>C4<span class="token punctuation">(</span>self<span class="token punctuation">.</span>D3<span class="token punctuation">(</span>R3<span class="token punctuation">)</span><span class="token punctuation">)</span>
        Y1 <span class="token operator">=</span> self<span class="token punctuation">.</span>C5<span class="token punctuation">(</span>self<span class="token punctuation">.</span>D4<span class="token punctuation">(</span>R4<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># part 2: up sampling, connect priori knowledge</span>
        O1 <span class="token operator">=</span> self<span class="token punctuation">.</span>C6<span class="token punctuation">(</span>self<span class="token punctuation">.</span>U1<span class="token punctuation">(</span>Y1<span class="token punctuation">,</span> R4<span class="token punctuation">)</span><span class="token punctuation">)</span>
        O2 <span class="token operator">=</span> self<span class="token punctuation">.</span>C7<span class="token punctuation">(</span>self<span class="token punctuation">.</span>U2<span class="token punctuation">(</span>O1<span class="token punctuation">,</span> R3<span class="token punctuation">)</span><span class="token punctuation">)</span>
        O3 <span class="token operator">=</span> self<span class="token punctuation">.</span>C8<span class="token punctuation">(</span>self<span class="token punctuation">.</span>U3<span class="token punctuation">(</span>O2<span class="token punctuation">,</span> R2<span class="token punctuation">)</span><span class="token punctuation">)</span>
        O4 <span class="token operator">=</span> self<span class="token punctuation">.</span>C9<span class="token punctuation">(</span>self<span class="token punctuation">.</span>U4<span class="token punctuation">(</span>O3<span class="token punctuation">,</span> R1<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># part 3: active function</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>Th<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pred<span class="token punctuation">(</span>self<span class="token punctuation">.</span>C10<span class="token punctuation">(</span>O4<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>As you can see, the difference between U-Net and other networks
before U-Net is that U-Net conbines the former information from encoder
and current information from decoder.</p>
<h1 id="code">Code</h1>
<p>During the training process, we want to keep some information of loss
values and accuracy values on training set and validation set so that we
can analyze the variance.</p>
<p>In the function named <code>train()</code>, we take
<code>optimizer</code> and <code>loss</code> as two parameters used in
training process. The outputs of this function are loss and accuracy on
both training set and validation set. If we get the data about training
set and validation set, we can draw the curves. If both training and
validation loss values decrease during training process, we can conclude
that our model converges and does not overfit on training set.</p>
<p>The training code is shown as follow:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> batch <span class="token keyword">in</span> self<span class="token punctuation">.</span>train_loader<span class="token punctuation">:</span>
    batch_num <span class="token operator">+=</span> <span class="token number">1</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    rgbs<span class="token punctuation">,</span> segs <span class="token operator">=</span> batch
    s<span class="token punctuation">,</span> _<span class="token punctuation">,</span> m<span class="token punctuation">,</span> n <span class="token operator">=</span> segs<span class="token punctuation">.</span>shape
    segs <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>segs<span class="token punctuation">,</span> <span class="token punctuation">(</span>s<span class="token punctuation">,</span> m<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">)</span>
    pred_segs <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>rgbs<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
    loss_val <span class="token operator">=</span> loss<span class="token punctuation">(</span>pred_segs<span class="token punctuation">,</span> segs<span class="token punctuation">)</span>
    loss_val<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>The data collecting code can be written as follow:</p>
<p><strong>Statistic data of training set</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">:</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> batch_num <span class="token operator">%</span> <span class="token number">5</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"batch num </span><span class="token interpolation"><span class="token punctuation">{</span>batch_num<span class="token punctuation">}</span></span><span class="token string">, loss </span><span class="token interpolation"><span class="token punctuation">{</span>loss_val<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token comment"># delete or add comments when needed</span>
        train_loss <span class="token operator">+=</span> loss_val
        <span class="token comment"># statistic valid classified samples</span>
        total_pix <span class="token operator">+=</span> s <span class="token operator">*</span> m <span class="token operator">*</span> n
        idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred_segs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        train_valid_pix <span class="token operator">+=</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>idx<span class="token punctuation">,</span> segs<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>empty_cache<span class="token punctuation">(</span><span class="token punctuation">)</span>
epoch_acc <span class="token operator">=</span> train_valid_pix <span class="token operator">/</span> total_pix
train_epoch_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_loss <span class="token operator">/</span> batch_num<span class="token punctuation">)</span>
train_epoch_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_acc<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>Statistic data of validation set</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> valid_batch <span class="token keyword">in</span> self<span class="token punctuation">.</span>valid_loader<span class="token punctuation">:</span>
        valid_batch_num <span class="token operator">+=</span> <span class="token number">1</span>
        rgbs<span class="token punctuation">,</span> segs <span class="token operator">=</span> valid_batch
        s<span class="token punctuation">,</span> _<span class="token punctuation">,</span> m<span class="token punctuation">,</span> n <span class="token operator">=</span> segs<span class="token punctuation">.</span>shape
        segs <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>segs<span class="token punctuation">,</span> <span class="token punctuation">(</span>s<span class="token punctuation">,</span> m<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">)</span>
        pred_segs <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>rgbs<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
        loss_val <span class="token operator">=</span> loss<span class="token punctuation">(</span>pred_segs<span class="token punctuation">,</span> segs<span class="token punctuation">)</span>
        valid_loss <span class="token operator">+=</span> loss_val
        valid_total_pix <span class="token operator">+=</span> s <span class="token operator">*</span> m <span class="token operator">*</span> n
        idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred_segs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        valid_valid_pix <span class="token operator">+=</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>idx<span class="token punctuation">,</span> segs<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
epoch_acc <span class="token operator">=</span> valid_valid_pix <span class="token operator">/</span> valid_total_pix
valid_epoch_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>valid_loss <span class="token operator">/</span> valid_batch_num<span class="token punctuation">)</span>
valid_epoch_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_acc<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>The point you should pay attention to is that you should use
<code>with torch.no_grad()</code> before you do some work that have no
relation with training process, otherwise your GPU memory will be full
or even overflow.</p>
<h1 id="result">Result</h1>
<p>After a long time training, we get the satisfying result with U-Net
model.</p>
<h2 id="former-model">Former Model</h2>
<p>The "former model" infers the U-Net model, and you will see we use
other upgraded model named "UNet++" which will be introduced later.</p>
<p>We output the segmentation results and their uncertainties.</p>
<figure>
<img src="/2022/08/21/ML/UNet/pic1-unet.png" alt="picture 1 result-UNet">
<figcaption aria-hidden="true">picture 1 result-UNet</figcaption>
</figure>
<h2 id="model-upgrade">Model Upgrade</h2>
<p>For some reasons, we try another U-Net-like model, Nested UNet,
namely UNet++. It has a nested convolutional blocks like a pyramid and
there is a chain passing connectivity between each convolutional block
every layer.</p>
<figure>
<img src="/2022/08/21/ML/UNet/nested.png" alt="Neseted UNet">
<figcaption aria-hidden="true">Neseted UNet</figcaption>
</figure>
<p>The black nodes are the same with U-Net model. The green nodes are
what Nested UNet newly added. Both green and blue lines are skip
pathways that pass connectivities from encoder to decoder.</p>
<p>The use of Nested UNet gives us a little improvement on final
results.</p>
<!-- ![pictrue 1 result-Nested UNet](pic1-nested.png) -->
<h1 id="analysis">Analysis</h1>
<h2 id="u-net">U-Net</h2>
<p>We analyze the loss value and accuracy on both training and
validation set:</p>
<figure>
<img src="/2022/08/21/ML/UNet/unet_loss.png" alt="unet loss">
<figcaption aria-hidden="true">unet loss</figcaption>
</figure>
<p>We find that after 100 epochs, the model has not convergenced yet,
but the loss on validation decreases to the bottom.</p>
<figure>
<img src="/2022/08/21/ML/UNet/unet_acc.png" alt="unet accuracy">
<figcaption aria-hidden="true">unet accuracy</figcaption>
</figure>
<p>From the accuracy curves, we find that both training set and
validation set have increasing accuracy, which means our model does not
overfit.</p>
<h2 id="nested-unet">Nested UNet</h2>
<p>Meanwhile, we analyze the loss and accuracy of Nested UNet model on
both training and validation set.</p>
<figure>
<img src="/2022/08/21/ML/UNet/nested_loss.png" alt="nested loss">
<figcaption aria-hidden="true">nested loss</figcaption>
</figure>
<p>We find that Nested UNet has a faster convergency speed than UNet. It
uses only about 60 epochs. But to our surprise, we find that Neseted
UNet overfit after about only 20 epochs because the validation loss does
not decrease anymore.</p>
<figure>
<img src="/2022/08/21/ML/UNet/nested_acc.png" alt="nested accuracy">
<figcaption aria-hidden="true">nested accuracy</figcaption>
</figure>
<p>The performance on validation accuracy stays the same with UNet
model.</p>

    
  </div>

</article>


   

   

   
  <div class="box-prev-next clearfix">
    <a class="show pull-left" href="/2022/08/10/CS/cmake/">
        <i class="icon icon-angle-left"></i>
    </a>
    <a class="show pull-right" href="/2023/02/28/CS/class-template/">
        <i class="icon icon-angle-right"></i>
    </a>
  </div>




</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>



<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js"></script>
<script>
    $(".article-content img").wrap(function() {
        return '<a data-fancybox href="' + $(this).attr("src") + '"/>';
    });
</script>


  <div class="modal" id="modal">
  <span id="cover" class="cover hide"></span>
  <div id="modal-dialog" class="modal-dialog hide-dialog">
    <div class="modal-header">
      <span id="close" class="btn-close">Close</span>
    </div>
    <hr>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a
              class="ROUND_RECT"
              href="/archives/"
              rel="noopener noreferrer"
              target="_self"
              >
              Archives
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="ROUND_RECT"
              href="/categories/"
              rel="noopener noreferrer"
              target="_self"
              >
              Categories
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="ROUND_RECT"
              href="/tags/"
              rel="noopener noreferrer"
              target="_self"
              >
              Tags
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="ROUND_RECT"
              href="/about/"
              rel="noopener noreferrer"
              target="_self"
              >
              About
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  
      <div class="fexo-comments comments-post">
    

    

    
    

    

    
    

    

<!-- Gitalkè¯„è®ºæ’ä»¶é€šç”¨ä»£ç  -->
<div id="gitalk-container"></div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js"></script>
<script>
const gitalk = new Gitalk({
  clientID: '277317290454635afa73',
  clientSecret: '78223c859304da5e8d71bfce136d436c6ff95c37',
  repo: 'blog-comment',
  owner: 'forsigner',
  // åœ¨è¿™é‡Œè®¾ç½®ä¸€ä¸‹æˆªå–å‰50ä¸ªå­—ç¬¦ä¸², è¿™æ˜¯å› ä¸º github å¯¹ label çš„é•¿åº¦æœ‰äº†è¦æ±‚, å¦‚æžœè¶…è¿‡
  // 50ä¸ªå­—ç¬¦ä¸²åˆ™ä¼šæŠ¥é”™.
  // id: location.pathname.split('/').pop().substring(0, 49),
  id: md5(location.pathname),
  admin: ['forsigner'],
  // facebook-like distraction free mode
  distractionFreeMode: false
})
gitalk.render('gitalk-container')
</script>
<!-- Gitalkä»£ç ç»“æŸ -->



  </div>

  

  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
