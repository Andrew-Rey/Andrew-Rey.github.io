<!DOCTYPE html>
<html lang="en">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Andrew-Rey">
    
    <title>
        
            【深度学习】Image Semantic Segmentation based on UNet |
        
        云边有个小卖部
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/head_round.png">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/fontawesome.min.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/regular.min.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/solid.min.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/brands.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"andrew-rey.github.io","root":"/","language":"en","path":"search.json"}
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":false,"init_open":false},"style":{"primary_color":"#a0c49d","logo":"/images/head_round.png","favicon":"/images/head_round.png","avatar":"/images/head_round.png","font_size":"16px","font_family":"Songti","hover":{"shadow":true,"scale":true},"first_screen":{"enable":true,"header_transparent":true,"background_img":"https://yuanxiapi.cn/api/bing/","description":"醒时相交欢，醉后各分散","font_color":"#faf0e4","hitokoto":false},"scroll":{"progress_bar":false,"percent":false}},"local_search":{"enable":true,"preload":false},"code_copy":{},"code_block":{"tools":{"enable":true,"style":"default"},"highlight_theme":"obsidian"},"side_tools":{},"pjax":{"enable":false},"lazyload":{"enable":true},"comment":{"enable":false,"use":"valine","valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":null,"github_admins":null,"repository":null,"client_id":null,"client_secret":null,"proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.8"},"waline":{"server_url":null,"reaction":false,"version":2}},"post":{"author_label":{"enable":true,"auto":false,"custom_label_list":["来自林邑的许先森❤"]},"word_count":{"enable":true,"wordcount":true,"min2read":true},"img_align":"center","copyright_info":true},"version":"3.6.1"}
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"}
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"}
    KEEP.language_copy_copyright = {"copy":"Copy copyright info","copied":"Copied","title":"Original article title","author":"Original article author","link":"Original article link"}
  </script>
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>


<body>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="progress-bar-container">
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/head_round.png">
                </a>
            
            <a class="logo-title" href="/">
               云边有个小卖部
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tags"
                            >
                                TAGS
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                ABOUT
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tags">TAGS</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">CATEGORIES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            <div class="article-title">
                <span class="title-hover-animation">【深度学习】Image Semantic Segmentation based on UNet</span>
            </div>

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/head_round.png">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">Andrew-Rey</span>
                            
                                <span class="author-label">来自林邑的许先森❤</span>
                            
                        </div>
                        <div class="meta-info">
                            
<div class="article-meta-info">
    <span class="article-date article-meta-item">
        
            <i class="fa-regular fa-calendar-plus"></i>&nbsp;
        
        <span class="pc">2022-08-21 10:50:30</span>
        <span class="mobile">2022-08-21 10:50</span>
    </span>
    
        <span class="article-update-date article-meta-item">
        <i class="fas fa-file-pen"></i>&nbsp;
        <span class="pc">2023-08-05 01:57:22</span>
    </span>
    
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/ML/">ML</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/CS/">CS</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/Deep-Learning/">Deep Learning</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>1.4k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>8 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content keep-markdown-body">
                

                <p>"Semantic segmentation of images, use UNet model."</p>
<span id="more"></span>
<h1 id="abstract">Abstract</h1>
<p>In this project, we realize an basic UNet model and UNet++ model,
then we apply them on image semantic segmentation. We show our basic
theory of UNet and an improvement of it, and we provide main code of
this program. Finally, we give the result of segmentation images,
loss-curve and accuracy-curve on both training and validation set.</p>
<p>The copyright of this program is owned by our team mentioned on the
end of this blog.</p>
<h1 id="unet-structure">UNet Structure</h1>
<p>The <a class="link" target="_blank" rel="noopener" href="https://arxiv.org/abs/1505.04597">paper<i class="fas fa-external-link-alt"></i></a> published in
2015 propose a noval network structure, whose shape is similar with the
captal "U". The idea comes from FCNN. U-Net is one of the classes of
"Encoder-Decoder" structure.</p>
<figure>
<img lazyload alt="U-Net Structure" data-src="unet-structure.png">
<figcaption aria-hidden="true">U-Net Structure</figcaption>
</figure>
<p>The front half of the network is "encoder". The input image passes
covolutional kernel, and then passes the pooling layer (or other
dimension-decreasing layer). The opposite of that is the back part of
UNet, the "decoder". The input of decoder is a sequence of feature maps
with highly contracted pixels. The output of the decoder (or the whole
network) is an image with the same shape of input image, where each
pixel has its own class.</p>
<p>In this project, we decrease the number of convolutional layers so
that there are only two convolutional layers in each convolutional
kernel as the dataset includes images with shape <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="9.553ex" height="1.557ex" role="img" focusable="false" viewbox="0 -666 4222.4 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"/><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(1000,0)"/></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"/></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"/><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1000,0)"/></g></g></g></svg></mjx-container></span>.</p>
<h2 id="operator-definitions">Operator Definitions</h2>
<p><strong>Convolutional Kernel:</strong></p>
<p>We define the basic convolutional kernel as follow:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">self.layer = nn.Sequential(</span><br><span class="line">    <span class="comment"># in_channel, out_channel, kernel_size, stride, padding</span></span><br><span class="line">    <span class="comment"># batch size * channel * height * weight</span></span><br><span class="line">    nn.Conv2d(C_in, C_out, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="number">1</span>),  <span class="comment"># 64 64 128 256</span></span><br><span class="line">    nn.BatchNorm2d(C_out),</span><br><span class="line">    nn.Dropout(<span class="number">0.2</span>),</span><br><span class="line">    nn.LeakyReLU(),</span><br><span class="line"></span><br><span class="line">    nn.Conv2d(C_out, C_out, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="number">1</span>),  <span class="comment"># 64 64 128 256</span></span><br><span class="line">    nn.BatchNorm2d(C_out),</span><br><span class="line">    nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    nn.LeakyReLU(),</span><br></pre></td></tr></table></figure>
<p>It includes two convolution operations.</p>
<p><strong>Down Sampling Kernel:</strong></p>
<p>As for downsampling kernel, we replace conditional pooling layer to
convolutional layer with stride equaling to 2, which means the shape
will be shrunk to <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.781ex;" xmlns="http://www.w3.org/2000/svg" width="1.795ex" height="2.737ex" role="img" focusable="false" viewbox="0 -864.9 793.6 1209.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(220,394) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mn" transform="translate(220,-345) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"/></g><rect width="553.6" height="60" x="120" y="220"/></g></g></g></svg></mjx-container></span> while
remaining the same channels.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">self.Down = nn.Sequential(</span><br><span class="line">    nn.Conv2d(C, C, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="number">1</span>),  <span class="comment"># 64 64 64 128</span></span><br><span class="line">    nn.LeakyReLU()</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p><strong>Up Sampling Kernel:</strong></p>
<p>The basic structure of up-sampling contains only one convolutional
layer with <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="5.028ex" height="1.507ex" role="img" focusable="false" viewbox="0 -666 2222.4 666"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"/></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g></g></g></svg></mjx-container></span> convolutional
kernel size and half out-channel. The feature map should pass an
interpolation layer before getting into the convolutional layer.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, C</span>):</span><br><span class="line">    <span class="built_in">super</span>(UpSampling, self).__init__()</span><br><span class="line">    <span class="comment"># out-channel = 1/2 in-channel</span></span><br><span class="line">    self.Up = nn.Conv2d(C, C // <span class="number">2</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, r</span>):</span><br><span class="line">    <span class="comment"># neighbor interpolation</span></span><br><span class="line">    up = F.interpolate(x, scale_factor=<span class="number">2</span>, mode=<span class="string">"nearest"</span>)</span><br><span class="line">    x = self.Up(up)</span><br><span class="line">    <span class="comment"># concatenate the feature map in encoder and </span></span><br><span class="line">    <span class="comment"># the feature map in corrsponding decoder layer, in channel dimension</span></span><br><span class="line">    res = torch.cat((x, r), <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>The interpolation mode we choose is "nearest". The function
<code>torch.cat(dim=1)</code> is used to concatenate two feature maps in
channel dimension.</p>
<h2 id="network-definition">Network Definition</h2>
<p>Based on the operators defined above, we link these blocks together
like UNet structure.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="built_in">super</span>(UNet, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># down sampling</span></span><br><span class="line">    self.C1 = Conv(<span class="number">3</span>, <span class="number">64</span>)</span><br><span class="line">    self.D1 = DownSampling(<span class="number">64</span>)</span><br><span class="line">    self.C2 = Conv(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">    self.D2 = DownSampling(<span class="number">128</span>)</span><br><span class="line">    self.C3 = Conv(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">    self.D3 = DownSampling(<span class="number">256</span>)</span><br><span class="line">    self.C4 = Conv(<span class="number">256</span>, <span class="number">512</span>)</span><br><span class="line">    self.D4 = DownSampling(<span class="number">512</span>)</span><br><span class="line">    self.C5 = Conv(<span class="number">512</span>, <span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># up sampling</span></span><br><span class="line">    self.U1 = UpSampling(<span class="number">1024</span>)</span><br><span class="line">    self.C6 = Conv(<span class="number">1024</span>, <span class="number">512</span>)</span><br><span class="line">    self.U2 = UpSampling(<span class="number">512</span>)</span><br><span class="line">    self.C7 = Conv(<span class="number">512</span>, <span class="number">256</span>)</span><br><span class="line">    self.U3 = UpSampling(<span class="number">256</span>)</span><br><span class="line">    self.C8 = Conv(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">    self.U4 = UpSampling(<span class="number">128</span>)</span><br><span class="line">    self.C9 = Conv(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">    self.C10 = torch.nn.Conv2d(<span class="number">64</span>, <span class="number">3</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="number">1</span>)</span><br><span class="line">    self.pred = torch.nn.Conv2d(<span class="number">3</span>, <span class="number">34</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    self.Th = torch.nn.Sigmoid()</span><br></pre></td></tr></table></figure>
<p>Like U-Net mentioned in that paper, we designed 4 layer deep
network.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># part 1: down sampling, decreasing dimension</span></span><br><span class="line">        R1 = self.C1(x)</span><br><span class="line">        R2 = self.C2(self.D1(R1))</span><br><span class="line">        R3 = self.C3(self.D2(R2))</span><br><span class="line">        R4 = self.C4(self.D3(R3))</span><br><span class="line">        Y1 = self.C5(self.D4(R4))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># part 2: up sampling, connect priori knowledge</span></span><br><span class="line">        O1 = self.C6(self.U1(Y1, R4))</span><br><span class="line">        O2 = self.C7(self.U2(O1, R3))</span><br><span class="line">        O3 = self.C8(self.U3(O2, R2))</span><br><span class="line">        O4 = self.C9(self.U4(O3, R1))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># part 3: active function</span></span><br><span class="line">        <span class="keyword">return</span> self.Th(self.pred(self.C10(O4)))</span><br></pre></td></tr></table></figure>
<p>As you can see, the difference between U-Net and other networks
before U-Net is that U-Net conbines the former information from encoder
and current information from decoder.</p>
<h1 id="code">Code</h1>
<p>During the training process, we want to keep some information of loss
values and accuracy values on training set and validation set so that we
can analyze the variance.</p>
<p>In the function named <code>train()</code>, we take
<code>optimizer</code> and <code>loss</code> as two parameters used in
training process. The outputs of this function are loss and accuracy on
both training set and validation set. If we get the data about training
set and validation set, we can draw the curves. If both training and
validation loss values decrease during training process, we can conclude
that our model converges and does not overfit on training set.</p>
<p>The training code is shown as follow:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">self.model.train()</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> self.train_loader:</span><br><span class="line">    batch_num += <span class="number">1</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    rgbs, segs = batch</span><br><span class="line">    s, _, m, n = segs.shape</span><br><span class="line">    segs = torch.reshape(segs, (s, m, n))</span><br><span class="line">    pred_segs = self.model(rgbs).to(self.device)</span><br><span class="line">    loss_val = loss(pred_segs, segs)</span><br><span class="line">    loss_val.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
<p>The data collecting code can be written as follow:</p>
<p><strong>Statistic data of training set</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ... :</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">if</span> batch_num % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            logging.info(<span class="string">f"batch num <span class="subst">{batch_num}</span>, loss <span class="subst">{loss_val}</span>"</span>)</span><br><span class="line">        <span class="comment"># delete or add comments when needed</span></span><br><span class="line">        train_loss += loss_val</span><br><span class="line">        <span class="comment"># statistic valid classified samples</span></span><br><span class="line">        total_pix += s * m * n</span><br><span class="line">        idx = torch.argmax(pred_segs, dim=<span class="number">1</span>)</span><br><span class="line">        train_valid_pix += torch.eq(idx, segs).<span class="built_in">sum</span>().<span class="built_in">float</span>().item()</span><br><span class="line">torch.cuda.empty_cache()</span><br><span class="line">epoch_acc = train_valid_pix / total_pix</span><br><span class="line">train_epoch_loss.append(train_loss / batch_num)</span><br><span class="line">train_epoch_acc.append(epoch_acc)</span><br></pre></td></tr></table></figure>
<p><strong>Statistic data of validation set</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">self.model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> valid_batch <span class="keyword">in</span> self.valid_loader:</span><br><span class="line">        valid_batch_num += <span class="number">1</span></span><br><span class="line">        rgbs, segs = valid_batch</span><br><span class="line">        s, _, m, n = segs.shape</span><br><span class="line">        segs = torch.reshape(segs, (s, m, n))</span><br><span class="line">        pred_segs = self.model(rgbs).to(self.device)</span><br><span class="line">        loss_val = loss(pred_segs, segs)</span><br><span class="line">        valid_loss += loss_val</span><br><span class="line">        valid_total_pix += s * m * n</span><br><span class="line">        idx = torch.argmax(pred_segs, dim=<span class="number">1</span>)</span><br><span class="line">        valid_valid_pix += torch.eq(idx, segs).<span class="built_in">sum</span>().<span class="built_in">float</span>().item()</span><br><span class="line">epoch_acc = valid_valid_pix / valid_total_pix</span><br><span class="line">valid_epoch_loss.append(valid_loss / valid_batch_num)</span><br><span class="line">valid_epoch_acc.append(epoch_acc)</span><br></pre></td></tr></table></figure>
<p>The point you should pay attention to is that you should use
<code>with torch.no_grad()</code> before you do some work that have no
relation with training process, otherwise your GPU memory will be full
or even overflow.</p>
<h1 id="result">Result</h1>
<p>After a long time training, we get the satisfying result with U-Net
model.</p>
<h2 id="former-model">Former Model</h2>
<p>The "former model" infers the U-Net model, and you will see we use
other upgraded model named "UNet++" which will be introduced later.</p>
<p>We output the segmentation results and their uncertainties.</p>
<figure>
<img lazyload alt="picture 1 result-UNet" data-src="pic1-unet.png">
<figcaption aria-hidden="true">picture 1 result-UNet</figcaption>
</figure>
<h2 id="model-upgrade">Model Upgrade</h2>
<p>For some reasons, we try another U-Net-like model, Nested UNet,
namely UNet++. It has a nested convolutional blocks like a pyramid and
there is a chain passing connectivity between each convolutional block
every layer.</p>
<figure>
<img lazyload alt="Neseted UNet" data-src="nested.png">
<figcaption aria-hidden="true">Neseted UNet</figcaption>
</figure>
<p>The black nodes are the same with U-Net model. The green nodes are
what Nested UNet newly added. Both green and blue lines are skip
pathways that pass connectivities from encoder to decoder.</p>
<p>The use of Nested UNet gives us a little improvement on final
results.</p>
<!-- ![pictrue 1 result-Nested UNet](pic1-nested.png) -->
<h1 id="analysis">Analysis</h1>
<h2 id="u-net">U-Net</h2>
<p>We analyze the loss value and accuracy on both training and
validation set:</p>
<figure>
<img lazyload alt="unet loss" data-src="unet_loss.png">
<figcaption aria-hidden="true">unet loss</figcaption>
</figure>
<p>We find that after 100 epochs, the model has not convergenced yet,
but the loss on validation decreases to the bottom.</p>
<figure>
<img lazyload alt="unet accuracy" data-src="unet_acc.png">
<figcaption aria-hidden="true">unet accuracy</figcaption>
</figure>
<p>From the accuracy curves, we find that both training set and
validation set have increasing accuracy, which means our model does not
overfit.</p>
<h2 id="nested-unet">Nested UNet</h2>
<p>Meanwhile, we analyze the loss and accuracy of Nested UNet model on
both training and validation set.</p>
<figure>
<img lazyload alt="nested loss" data-src="nested_loss.png">
<figcaption aria-hidden="true">nested loss</figcaption>
</figure>
<p>We find that Nested UNet has a faster convergency speed than UNet. It
uses only about 60 epochs. But to our surprise, we find that Neseted
UNet overfit after about only 20 epochs because the validation loss does
not decrease anymore.</p>
<figure>
<img lazyload alt="nested accuracy" data-src="nested_acc.png">
<figcaption aria-hidden="true">nested accuracy</figcaption>
</figure>
<p>The performance on validation accuracy stays the same with UNet
model.</p>

            </div>

            
                <div class="post-copyright-info">
                    
<div class="article-copyright-info-container">
    <ul class="copyright-info-content">
        <li class="post-title">
            <span class="type">Post title</span>: <span class="content">【深度学习】Image Semantic Segmentation based on UNet</span>
        </li>
        <li class="post-author">
            <span class="type">Post author</span>: <span class="content">Andrew-Rey</span>
        </li>
        <li class="post-time">
            <span class="type">Create time</span>: <span class="content">2022-08-21 10:50:30</span>
        </li>
        <li class="post-link">
            <span class="type">Post link</span>: <span class="content">2022/08/21/ML/UNet/</span>
        </li>
        <li class="post-license">
            <span class="type">Copyright notice</span>: <span class="content">All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.</span>
        </li>
    </ul>
    <div class="copy-copyright-info flex-center tooltip" data-content="Copy copyright info" data-offset-y="-2px">
        <i class="fa-solid fa-copy"></i>
    </div>
</div>

                </div>
            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/CS/">#CS</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/Deep-Learning/">#Deep Learning</a>&nbsp;
                        </li>
                    
                </ul>
            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                               rel="prev"
                               href="/2023/02/28/CS/class-template/"
                            >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                                <span class="title flex-center">
                                <span class="post-nav-title-item">【C++编程】类模板</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                               rel="next"
                               href="/2022/08/10/CS/cmake/"
                            >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">【C++】CMake Tutorial</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                                <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                            </a>
                        </div>
                    
                </div>
            

            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#abstract"><span class="nav-number">1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#unet-structure"><span class="nav-number">2.</span> <span class="nav-text">UNet Structure</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#operator-definitions"><span class="nav-number">2.1.</span> <span class="nav-text">Operator Definitions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#network-definition"><span class="nav-number">2.2.</span> <span class="nav-text">Network Definition</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#code"><span class="nav-number">3.</span> <span class="nav-text">Code</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#result"><span class="nav-number">4.</span> <span class="nav-text">Result</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#former-model"><span class="nav-number">4.1.</span> <span class="nav-text">Former Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#model-upgrade"><span class="nav-number">4.2.</span> <span class="nav-text">Model Upgrade</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#analysis"><span class="nav-number">5.</span> <span class="nav-text">Analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#u-net"><span class="nav-number">5.1.</span> <span class="nav-text">U-Net</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#nested-unet"><span class="nav-number">5.2.</span> <span class="nav-text">Nested UNet</span></a></li></ol></li></ol>
    </div>
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            
<footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
                <span>2022</span> -
            
            2023
            
                &nbsp;<i class="fas fa-heart icon-animate"></i>
                &nbsp;<a href="/">Andrew-Rey</a>
            
        </div>
        
            <script async 
                    src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                
                
                    Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.6.1</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item flex-center toggle-show-toc">
                <i class="fas fa-list"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/dark-light-toggle.js"></script>




    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/local-search.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/code-block.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/lazyload.js"></script>


<div class="post-scripts">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/post-helper.js"></script>
        
            <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/libs/anime.min.js"></script>
        
        
            <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/toc.js"></script>
        
    
</div>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
