<!DOCTYPE html>
<html lang="en">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Andrew-Rey">
    
    <title>
        
            【深度学习】Image Semantic Segmentation based on UNet |
        
        Notes
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/head_round.png">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/fontawesome.min.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/regular.min.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/solid.min.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/font/css/brands.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"andrew-rey.github.io","root":"/","language":"en","path":"search.json"}
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":false,"init_open":false},"style":{"primary_color":"#a0c49d","logo":"/images/head_round.png","favicon":"/images/head_round.png","avatar":"/images/head_round.png","font_size":"16px","font_family":"Songti","hover":{"shadow":true,"scale":true},"first_screen":{"enable":true,"header_transparent":true,"background_img":"https://yuanxiapi.cn/api/bing/","description":"在世间，本就是各人下雪，各人有各人的隐晦与皎洁","font_color":"#faf0e4","hitokoto":false},"scroll":{"progress_bar":false,"percent":false}},"local_search":{"enable":true,"preload":false},"code_copy":{},"code_block":{"tools":{"enable":true,"style":"default"},"highlight_theme":"obsidian"},"side_tools":{},"pjax":{"enable":false},"lazyload":{"enable":true},"comment":{"enable":false,"use":"valine","valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":null,"github_admins":null,"repository":null,"client_id":null,"client_secret":null,"proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.8"},"waline":{"server_url":null,"reaction":false,"version":2}},"post":{"author_label":{"enable":true,"auto":false,"custom_label_list":["来自林邑的许先森❤"]},"word_count":{"enable":true,"wordcount":true,"min2read":true},"img_align":"center","copyright_info":true},"version":"3.6.1"}
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"}
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"}
    KEEP.language_copy_copyright = {"copy":"Copy copyright info","copied":"Copied","title":"Original article title","author":"Original article author","link":"Original article link"}
  </script>
<meta name="generator" content="Hexo 6.1.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>


<body>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="progress-bar-container">
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/head_round.png">
                </a>
            
            <a class="logo-title" href="/">
               Notes
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tags"
                            >
                                TAGS
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                CATEGORIES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                ABOUT
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tags">TAGS</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">CATEGORIES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            <div class="article-title">
                <span class="title-hover-animation">【深度学习】Image Semantic Segmentation based on UNet</span>
            </div>

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/head_round.png">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">Andrew-Rey</span>
                            
                                <span class="author-label">来自林邑的许先森❤</span>
                            
                        </div>
                        <div class="meta-info">
                            
<div class="article-meta-info">
    <span class="article-date article-meta-item">
        
            <i class="fa-regular fa-calendar-plus"></i>&nbsp;
        
        <span class="pc">2022-08-21 10:50:30</span>
        <span class="mobile">2022-08-21 10:50</span>
    </span>
    
        <span class="article-update-date article-meta-item">
        <i class="fas fa-file-pen"></i>&nbsp;
        <span class="pc">2023-06-11 13:46:00</span>
    </span>
    
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/ML/">ML</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/CS/">CS</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/Deep-Learning/">Deep Learning</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content keep-markdown-body">
                

                <p>"Semantic segmentation of images, use UNet model."</p>
<span id="more"></span>
<h1 id="abstract">Abstract</h1>
<p>In this project, we realize an basic UNet model and UNet++ model,
then we apply them on image semantic segmentation. We show our basic
theory of UNet and an improvement of it, and we provide main code of
this program. Finally, we give the result of segmentation images,
loss-curve and accuracy-curve on both training and validation set.</p>
<p>The copyright of this program is owned by our team mentioned on the
end of this blog.</p>
<h1 id="unet-structure">UNet Structure</h1>
<p>The <a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/abs/1505.04597" >paper<i class="fas fa-external-link-alt"></i></a> published in
2015 propose a noval network structure, whose shape is similar with the
captal "U". The idea comes from FCNN. U-Net is one of the classes of
"Encoder-Decoder" structure.</p>
<figure>
<img  
                     lazyload
                     alt="image"
                     data-src="unet-structure.png"
                      alt="U-Net Structure" 
                >
<figcaption aria-hidden="true">U-Net Structure</figcaption>
</figure>
<p>The front half of the network is "encoder". The input image passes
covolutional kernel, and then passes the pooling layer (or other
dimension-decreasing layer). The opposite of that is the back part of
UNet, the "decoder". The input of decoder is a sequence of feature maps
with highly contracted pixels. The output of the decoder (or the whole
network) is an image with the same shape of input image, where each
pixel has its own class.</p>
<p>In this project, we decrease the number of convolutional layers so
that there are only two convolutional layers in each convolutional
kernel as the dataset includes images with shape <span
class="math inline">\(128\times 256\)</span>.</p>
<h2 id="operator-definitions">Operator Definitions</h2>
<p><strong>Convolutional Kernel:</strong></p>
<p>We define the basic convolutional kernel as follow:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">self.layer = nn.Sequential(</span><br><span class="line">    <span class="comment"># in_channel, out_channel, kernel_size, stride, padding</span></span><br><span class="line">    <span class="comment"># batch size * channel * height * weight</span></span><br><span class="line">    nn.Conv2d(C_in, C_out, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="number">1</span>),  <span class="comment"># 64 64 128 256</span></span><br><span class="line">    nn.BatchNorm2d(C_out),</span><br><span class="line">    nn.Dropout(<span class="number">0.2</span>),</span><br><span class="line">    nn.LeakyReLU(),</span><br><span class="line"></span><br><span class="line">    nn.Conv2d(C_out, C_out, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="number">1</span>),  <span class="comment"># 64 64 128 256</span></span><br><span class="line">    nn.BatchNorm2d(C_out),</span><br><span class="line">    nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    nn.LeakyReLU(),</span><br></pre></td></tr></table></figure>
<p>It includes two convolution operations.</p>
<p><strong>Down Sampling Kernel:</strong></p>
<p>As for downsampling kernel, we replace conditional pooling layer to
convolutional layer with stride equaling to 2, which means the shape
will be shrunk to <span class="math inline">\(\frac{1}{2}\)</span> while
remaining the same channels.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">self.Down = nn.Sequential(</span><br><span class="line">    nn.Conv2d(C, C, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="number">1</span>),  <span class="comment"># 64 64 64 128</span></span><br><span class="line">    nn.LeakyReLU()</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p><strong>Up Sampling Kernel:</strong></p>
<p>The basic structure of up-sampling contains only one convolutional
layer with <span class="math inline">\(1\times 1\)</span> convolutional
kernel size and half out-channel. The feature map should pass an
interpolation layer before getting into the convolutional layer.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, C</span>):</span><br><span class="line">    <span class="built_in">super</span>(UpSampling, self).__init__()</span><br><span class="line">    <span class="comment"># out-channel = 1/2 in-channel</span></span><br><span class="line">    self.Up = nn.Conv2d(C, C // <span class="number">2</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, r</span>):</span><br><span class="line">    <span class="comment"># neighbor interpolation</span></span><br><span class="line">    up = F.interpolate(x, scale_factor=<span class="number">2</span>, mode=<span class="string">&quot;nearest&quot;</span>)</span><br><span class="line">    x = self.Up(up)</span><br><span class="line">    <span class="comment"># concatenate the feature map in encoder and </span></span><br><span class="line">    <span class="comment"># the feature map in corrsponding decoder layer, in channel dimension</span></span><br><span class="line">    res = torch.cat((x, r), <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>The interpolation mode we choose is "nearest". The function
<code>torch.cat(dim=1)</code> is used to concatenate two feature maps in
channel dimension.</p>
<h2 id="network-definition">Network Definition</h2>
<p>Based on the operators defined above, we link these blocks together
like UNet structure.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="built_in">super</span>(UNet, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># down sampling</span></span><br><span class="line">    self.C1 = Conv(<span class="number">3</span>, <span class="number">64</span>)</span><br><span class="line">    self.D1 = DownSampling(<span class="number">64</span>)</span><br><span class="line">    self.C2 = Conv(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">    self.D2 = DownSampling(<span class="number">128</span>)</span><br><span class="line">    self.C3 = Conv(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">    self.D3 = DownSampling(<span class="number">256</span>)</span><br><span class="line">    self.C4 = Conv(<span class="number">256</span>, <span class="number">512</span>)</span><br><span class="line">    self.D4 = DownSampling(<span class="number">512</span>)</span><br><span class="line">    self.C5 = Conv(<span class="number">512</span>, <span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># up sampling</span></span><br><span class="line">    self.U1 = UpSampling(<span class="number">1024</span>)</span><br><span class="line">    self.C6 = Conv(<span class="number">1024</span>, <span class="number">512</span>)</span><br><span class="line">    self.U2 = UpSampling(<span class="number">512</span>)</span><br><span class="line">    self.C7 = Conv(<span class="number">512</span>, <span class="number">256</span>)</span><br><span class="line">    self.U3 = UpSampling(<span class="number">256</span>)</span><br><span class="line">    self.C8 = Conv(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">    self.U4 = UpSampling(<span class="number">128</span>)</span><br><span class="line">    self.C9 = Conv(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">    self.C10 = torch.nn.Conv2d(<span class="number">64</span>, <span class="number">3</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="number">1</span>)</span><br><span class="line">    self.pred = torch.nn.Conv2d(<span class="number">3</span>, <span class="number">34</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    self.Th = torch.nn.Sigmoid()</span><br></pre></td></tr></table></figure>
<p>Like U-Net mentioned in that paper, we designed 4 layer deep
network.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># part 1: down sampling, decreasing dimension</span></span><br><span class="line">        R1 = self.C1(x)</span><br><span class="line">        R2 = self.C2(self.D1(R1))</span><br><span class="line">        R3 = self.C3(self.D2(R2))</span><br><span class="line">        R4 = self.C4(self.D3(R3))</span><br><span class="line">        Y1 = self.C5(self.D4(R4))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># part 2: up sampling, connect priori knowledge</span></span><br><span class="line">        O1 = self.C6(self.U1(Y1, R4))</span><br><span class="line">        O2 = self.C7(self.U2(O1, R3))</span><br><span class="line">        O3 = self.C8(self.U3(O2, R2))</span><br><span class="line">        O4 = self.C9(self.U4(O3, R1))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># part 3: active function</span></span><br><span class="line">        <span class="keyword">return</span> self.Th(self.pred(self.C10(O4)))</span><br></pre></td></tr></table></figure>
<p>As you can see, the difference between U-Net and other networks
before U-Net is that U-Net conbines the former information from encoder
and current information from decoder.</p>
<h1 id="code">Code</h1>
<p>During the training process, we want to keep some information of loss
values and accuracy values on training set and validation set so that we
can analyze the variance.</p>
<p>In the function named <code>train()</code>, we take
<code>optimizer</code> and <code>loss</code> as two parameters used in
training process. The outputs of this function are loss and accuracy on
both training set and validation set. If we get the data about training
set and validation set, we can draw the curves. If both training and
validation loss values decrease during training process, we can conclude
that our model converges and does not overfit on training set.</p>
<p>The training code is shown as follow:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">self.model.train()</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> self.train_loader:</span><br><span class="line">    batch_num += <span class="number">1</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    rgbs, segs = batch</span><br><span class="line">    s, _, m, n = segs.shape</span><br><span class="line">    segs = torch.reshape(segs, (s, m, n))</span><br><span class="line">    pred_segs = self.model(rgbs).to(self.device)</span><br><span class="line">    loss_val = loss(pred_segs, segs)</span><br><span class="line">    loss_val.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
<p>The data collecting code can be written as follow:</p>
<p><strong>Statistic data of training set</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ... :</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">if</span> batch_num % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            logging.info(<span class="string">f&quot;batch num <span class="subst">&#123;batch_num&#125;</span>, loss <span class="subst">&#123;loss_val&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment"># delete or add comments when needed</span></span><br><span class="line">        train_loss += loss_val</span><br><span class="line">        <span class="comment"># statistic valid classified samples</span></span><br><span class="line">        total_pix += s * m * n</span><br><span class="line">        idx = torch.argmax(pred_segs, dim=<span class="number">1</span>)</span><br><span class="line">        train_valid_pix += torch.eq(idx, segs).<span class="built_in">sum</span>().<span class="built_in">float</span>().item()</span><br><span class="line">torch.cuda.empty_cache()</span><br><span class="line">epoch_acc = train_valid_pix / total_pix</span><br><span class="line">train_epoch_loss.append(train_loss / batch_num)</span><br><span class="line">train_epoch_acc.append(epoch_acc)</span><br></pre></td></tr></table></figure>
<p><strong>Statistic data of validation set</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">self.model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> valid_batch <span class="keyword">in</span> self.valid_loader:</span><br><span class="line">        valid_batch_num += <span class="number">1</span></span><br><span class="line">        rgbs, segs = valid_batch</span><br><span class="line">        s, _, m, n = segs.shape</span><br><span class="line">        segs = torch.reshape(segs, (s, m, n))</span><br><span class="line">        pred_segs = self.model(rgbs).to(self.device)</span><br><span class="line">        loss_val = loss(pred_segs, segs)</span><br><span class="line">        valid_loss += loss_val</span><br><span class="line">        valid_total_pix += s * m * n</span><br><span class="line">        idx = torch.argmax(pred_segs, dim=<span class="number">1</span>)</span><br><span class="line">        valid_valid_pix += torch.eq(idx, segs).<span class="built_in">sum</span>().<span class="built_in">float</span>().item()</span><br><span class="line">epoch_acc = valid_valid_pix / valid_total_pix</span><br><span class="line">valid_epoch_loss.append(valid_loss / valid_batch_num)</span><br><span class="line">valid_epoch_acc.append(epoch_acc)</span><br></pre></td></tr></table></figure>
<p>The point you should pay attention to is that you should use
<code>with torch.no_grad()</code> before you do some work that have no
relation with training process, otherwise your GPU memory will be full
or even overflow.</p>
<h1 id="result">Result</h1>
<p>After a long time training, we get the satisfying result with U-Net
model.</p>
<h2 id="former-model">Former Model</h2>
<p>The "former model" infers the U-Net model, and you will see we use
other upgraded model named "UNet++" which will be introduced later.</p>
<p>We output the segmentation results and their uncertainties.</p>
<figure>
<img  
                     lazyload
                     alt="image"
                     data-src="pic1-unet.png"
                      alt="picture 1 result-UNet" 
                >
<figcaption aria-hidden="true">picture 1 result-UNet</figcaption>
</figure>
<h2 id="model-upgrade">Model Upgrade</h2>
<p>For some reasons, we try another U-Net-like model, Nested UNet,
namely UNet++. It has a nested convolutional blocks like a pyramid and
there is a chain passing connectivity between each convolutional block
every layer.</p>
<figure>
<img  
                     lazyload
                     alt="image"
                     data-src="nested.png"
                      alt="Neseted UNet" 
                >
<figcaption aria-hidden="true">Neseted UNet</figcaption>
</figure>
<p>The black nodes are the same with U-Net model. The green nodes are
what Nested UNet newly added. Both green and blue lines are skip
pathways that pass connectivities from encoder to decoder.</p>
<p>The use of Nested UNet gives us a little improvement on final
results.</p>
<!-- ![pictrue 1 result-Nested UNet](pic1-nested.png) -->
<h1 id="analysis">Analysis</h1>
<h2 id="u-net">U-Net</h2>
<p>We analyze the loss value and accuracy on both training and
validation set:</p>
<figure>
<img  
                     lazyload
                     alt="image"
                     data-src="unet_loss.png"
                      alt="unet loss" 
                >
<figcaption aria-hidden="true">unet loss</figcaption>
</figure>
<p>We find that after 100 epochs, the model has not convergenced yet,
but the loss on validation decreases to the bottom.</p>
<figure>
<img  
                     lazyload
                     alt="image"
                     data-src="unet_acc.png"
                      alt="unet accuracy" 
                >
<figcaption aria-hidden="true">unet accuracy</figcaption>
</figure>
<p>From the accuracy curves, we find that both training set and
validation set have increasing accuracy, which means our model does not
overfit.</p>
<h2 id="nested-unet">Nested UNet</h2>
<p>Meanwhile, we analyze the loss and accuracy of Nested UNet model on
both training and validation set.</p>
<figure>
<img  
                     lazyload
                     alt="image"
                     data-src="nested_loss.png"
                      alt="nested loss" 
                >
<figcaption aria-hidden="true">nested loss</figcaption>
</figure>
<p>We find that Nested UNet has a faster convergency speed than UNet. It
uses only about 60 epochs. But to our surprise, we find that Neseted
UNet overfit after about only 20 epochs because the validation loss does
not decrease anymore.</p>
<figure>
<img  
                     lazyload
                     alt="image"
                     data-src="nested_acc.png"
                      alt="nested accuracy" 
                >
<figcaption aria-hidden="true">nested accuracy</figcaption>
</figure>
<p>The performance on validation accuracy stays the same with UNet
model.</p>

            </div>

            
                <div class="post-copyright-info">
                    
<div class="article-copyright-info-container">
    <ul class="copyright-info-content">
        <li class="post-title">
            <span class="type">Post title</span>: <span class="content">【深度学习】Image Semantic Segmentation based on UNet</span>
        </li>
        <li class="post-author">
            <span class="type">Post author</span>: <span class="content">Andrew-Rey</span>
        </li>
        <li class="post-time">
            <span class="type">Create time</span>: <span class="content">2022-08-21 10:50:30</span>
        </li>
        <li class="post-link">
            <span class="type">Post link</span>: <span class="content">2022/08/21/ML/UNet/</span>
        </li>
        <li class="post-license">
            <span class="type">Copyright notice</span>: <span class="content">All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.</span>
        </li>
    </ul>
    <div class="copy-copyright-info flex-center tooltip" data-content="Copy copyright info" data-offset-y="-2px">
        <i class="fa-solid fa-copy"></i>
    </div>
</div>

                </div>
            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/CS/">#CS</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/Deep-Learning/">#Deep Learning</a>&nbsp;
                        </li>
                    
                </ul>
            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                               rel="prev"
                               href="/2023/02/28/CS/class-template/"
                            >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                                <span class="title flex-center">
                                <span class="post-nav-title-item">【C++编程】类模板</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                               rel="next"
                               href="/2022/08/10/CS/cmake/"
                            >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">【C++】CMake Tutorial</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                                <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                            </a>
                        </div>
                    
                </div>
            

            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#abstract"><span class="nav-number">1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#unet-structure"><span class="nav-number">2.</span> <span class="nav-text">UNet Structure</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#operator-definitions"><span class="nav-number">2.1.</span> <span class="nav-text">Operator Definitions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#network-definition"><span class="nav-number">2.2.</span> <span class="nav-text">Network Definition</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#code"><span class="nav-number">3.</span> <span class="nav-text">Code</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#result"><span class="nav-number">4.</span> <span class="nav-text">Result</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#former-model"><span class="nav-number">4.1.</span> <span class="nav-text">Former Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#model-upgrade"><span class="nav-number">4.2.</span> <span class="nav-text">Model Upgrade</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#analysis"><span class="nav-number">5.</span> <span class="nav-text">Analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#u-net"><span class="nav-number">5.1.</span> <span class="nav-text">U-Net</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#nested-unet"><span class="nav-number">5.2.</span> <span class="nav-text">Nested UNet</span></a></li></ol></li></ol>
    </div>
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            
<footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
                <span>2022</span> -
            
            2023
            
                &nbsp;<i class="fas fa-heart icon-animate"></i>
                &nbsp;<a href="/">Andrew-Rey</a>
            
        </div>
        
            <script async 
                    src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                
                
                    Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.6.1</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item flex-center toggle-show-toc">
                <i class="fas fa-list"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/dark-light-toggle.js"></script>




    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/local-search.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/code-block.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/lazyload.js"></script>


<div class="post-scripts">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/post-helper.js"></script>
        
            <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/libs/anime.min.js"></script>
        
        
            <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.6.1/source/js/toc.js"></script>
        
    
</div>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
